{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Getting started # Interoperability tests guide # This guide will walk you through the LwM2M protocol interoperability tests module available as part of Coiote IoT Device Management platform. Interoperability tests guide Azure IoT integration guide # With Coiote IoT Device Management platform, you can integrate your LwM2M devices with the Microsoft Azure IoT Hub and Azure IoT Central. This guide will take you on a step-by-step journey through the integration process to make it seamless and efficient. Here\u2019s how you can get started with the Coiote DM \u2013 Azure IoT integration: Configure integration with Azure IoT Central Configure integration with Azure IoT Hub AWS integration guide # Integrate Coiote DM with the Amazon Web Services and gain new opportunities to leverage your IoT data. Configure integration with AWS","title":"Getting started"},{"location":"index.html#getting-started","text":"","title":"Getting started"},{"location":"index.html#interoperability-tests-guide","text":"This guide will walk you through the LwM2M protocol interoperability tests module available as part of Coiote IoT Device Management platform. Interoperability tests guide","title":"Interoperability tests guide"},{"location":"index.html#azure-iot-integration-guide","text":"With Coiote IoT Device Management platform, you can integrate your LwM2M devices with the Microsoft Azure IoT Hub and Azure IoT Central. This guide will take you on a step-by-step journey through the integration process to make it seamless and efficient. Here\u2019s how you can get started with the Coiote DM \u2013 Azure IoT integration: Configure integration with Azure IoT Central Configure integration with Azure IoT Hub","title":"Azure IoT integration guide"},{"location":"index.html#aws-integration-guide","text":"Integrate Coiote DM with the Amazon Web Services and gain new opportunities to leverage your IoT data. Configure integration with AWS","title":"AWS integration guide"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html","text":"Configuring the integration # Follow this section to integrate your AWS services with Coiote DM. Prerequisites # An active AWS subscription. A Coiote DM user account with the Cloud admin role. The Git tool ( https://git-scm.com/book/en/v2/Getting-Started-Installing-Git ). The AWS CLI ( https://aws.amazon.com/cli/ ). Terraform CLI ( https://learn.hashicorp.com/tutorials/terraform/install-cli ). Create a Coiote DM REST user # To start integrating AWS with Coiote DM, you first need to create a user account that will be used to authorize and authenticate API calls from AWS in Coiote DM. To do that: Go to your Coiote DM account and from the Administration menu, select Users management . Select Add user and in fill in the form: Provide Email for new user (which will be its user name) and select your domain from the Domain path drop-down list. Remember to switch on the User Verified and User Enabled toggle buttons. In the Client Roles field, pick the admin-cli role. Click Save . Go to the Credentials tab, type a password for your user (twice), select Set password , then confirm by clicking Set password in the pop-up. Copy tasks and provide credentials for your device group in Coiote DM # The Coiote DM-side configuration of the integration is located in the dedicated AWSiotCore device group. To complete this side of the integration, log in as the user with the Cloud admin role and follow the steps below: Go to the Device groups panel and select a group: For the default setting, select the AWSiotCore group which already contains all the necessary tasks and setting values. Alternatively, create a new group and migrate the required tasks and setting values: Select the Add button, name your group and click Add . Migrate all the six tasks that have the AWS prefix in their task name: Select the AWSiotCore group and go to Group tasks , select the first AWS task and click Copy . In the pop-up window, click Select group in the Task target field and choose your custom integration group from the list. In the Actions field, select Add new task . Repeat the action for the remaining five tasks. Migrate all the five setting values that have the AWS prefix in their task name: Select your custom integration group and go to Profiles , then select Copy from . In the pop-up window, click Select group and select the AWSiotCore group. Pick all the five AWS setting values from the list by checking them in the Selected column, then click Copy . Enter your AWS subscription credentials in Coiote DM: Go to Device groups , select your custom integration group (or the AWSiotCore group, depending on the previous step) and go to Profiles . Complete the AWS setting values with your AWS credentials: For AWSaccessKeyID and AWSsecretAccessKey : Go to AWS Identity and Access Management , click Users and select your user name from the list. Select the Security credentials tab and, under the Access keys section, click Create access key . Copy the generated Access key ID and Secret access key . In Coiote DM, go to the Profiles tab of your integration group and paste the credentials as values for AWSaccessKeyID and AWSsecretAccessKey . Click Save . For AWSregion : While in AWS IoT Core, click on your region name in the top navigation bar to expand the list of regions. Then, copy the hyphenated region name (e.g. us-east-1 ). In Coiote DM, go to the Profiles tab of your integration group and paste the region name as the value for AWSregion . Click Save . For AWScontrolPlaneEndpointAddress : Go to AWS documentation : https://docs.aws.amazon.com/general/latest/gr/iot-core.html . From the Control Plane API Endpoints section, find the endpoint that matches your region (e.g. iot.us-east-1.amazonaws.com ) and copy it. In Coiote DM, go to the Profiles tab of your integration group and paste the credentials as the value for AWScontrolPlaneEndpointAddress . Click Save . For AWSdataPlaneEndpointAddress : Open your command line and run the following command: aws iot describe-endpoint --endpoint-type iot:Data-ATS Copy the returned result. In Coiote DM, go to the Profiles tab of your integration group and paste the result as the value for AWSdataPlaneEndpointAddress . Click Save . Optionally, you may now add your LwM2M devices to the integration device group so that they are ready once the integration setup is complete. Add AWS resources using the integration repository # All the AWS-side configuration needed for the integration to work is stored in a publicly available git repository ( https://github.com/AVSystem/iot-examples/tree/main/coiote-aws-iot-terraform ). To add the resources needed for the integration to your AWS services: Clone the repository into your local drive and check out on the coiote-aws-iot-terraform branch: Run your command line and paste the following commands: git clone --no-checkout https://github.com/AVSystem/iot-examples.git cd iot-examples git sparse-checkout set coiote-aws-iot-terraform git checkout main cd coiote-aws-iot-terraform Insert your REST user credentials into the vars.py file: In the catalog of your local repository, find the vars.py file and open it using a program that enables file edition. Change the default values of the variables to the credentials of your REST user created in a previous step. For coioteDMrestURL , provide the URL address and port of your Coiote DM installation. By default, it's https://lwm2m-test.avsystem.io:8087. For coioteDMrestPassword , provide the password set for your Coiote DM REST user. For coioteDMrestUsername , provide your Coiote DM REST user login (email address). Save the file. Run Terraform: Go back to your command line and paste the following: terraform init terraform apply Run the command. It will copy all the 16 resources contained in the main.tf file from the repository into your AWS services. Among the key resources that enable the integration, there are: the iam_for_lambda role, the lwm2mOperation Lambda function, and the operationRequest and operationResponse rules. See the contents of the main.tf file below or refer to the Concepts chapter for more details. resource \"aws_iam_role\" \"iam_for_lambda\" { na me = \"iam_for_lambda\" assume_role_policy = <<EOF { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Action\" : \"sts:AssumeRole\" , \"Principal\" : { \"Service\" : \"lambda.amazonaws.com\" }, \"Effect\" : \"Allow\" } ] } EOF } resource \"aws_iam_policy_attachment\" \"policy_attachment\" { na me = \"attachment\" roles = [ aws_iam_role.iam_ f or_lambda. na me ] policy_ar n = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\" } resource \"random_string\" \"r\" { le n g t h = 16 special = false } da ta \"archive_file\" \"lambda_zip\" { t ype = \"zip\" source_dir = \"lwm2mOperation\" ou t pu t _pa t h = \"lwm2mOperation.zip\" depe n ds_o n = [ ra n dom_s tr i n g.r ] } resource \"aws_lambda_function\" \"lwm2mOperation\" { f ile na me = \"lwm2mOperation.zip\" fun c t io n _ na me = \"lwm2mOperation\" role = aws_iam_role.iam_ f or_lambda.ar n ha n dler = \"lambda_function.lambda_handler\" source_code_hash = da ta .archive_ f ile.lambda_zip.ou t pu t _base 64 sha 256 ru nt ime = \"python3.8\" e n viro n me nt { variables = { coio te DMres t Password = var.coio te DMres t Password coio te DMres t Uri = var.coio te DMres t URL coio te DMres t User na me = var.coio te DMres t User na me } } } module \"iot_rule_1\" { na me = \"operationRequest\" sql_query = \"SELECT state.desired.operation AS operation, state.desired.keys AS keys, state.desired.values AS values, state.desired.attributes AS attributes, state.desired.arguments AS arguments, topic(3) AS thingName FROM '$aws/things/+/shadow/name/operation/update/accepted' WHERE isUndefined(state.desired.operation) = false\" source = \"git::https://github.com/Passarinho4/terraform-aws-iot-topic-rule.git?ref=master\" lambda = [ \"lwm2mOperation\" ] depe n ds_o n = [ aws_lambda_ fun c t io n .lwm 2 mOpera t io n ] } module \"iot_rule_2\" { na me = \"operationResponse\" sql_query = \"SELECT state.reported.result AS state.reported FROM '$aws/things/+/shadow/name/operation/update/accepted' WHERE (CASE isUndefined(state.reported.operation) WHEN true THEN false ELSE CASE state.reported.operation = 'read' OR state.reported.operation = 'write' OR state.reported.operation = 'readComposite' when true THEN true ELSE false END END) = true\" source = \"git::https://github.com/Passarinho4/terraform-aws-iot-topic-rule.git?ref=master\" republish = [{ t opic = \"$$aws/things/$${topic(3)}/shadow/name/datamodel/update\" }] Once the Terraform command is executed successfully, the devices in your integration group will be automatically migrated to the AWS IoT Core. To check if your integration works correctly, go to AWS IoT Core, and from the menu, select Manage > Things , then see if your devices are listed as in here: Next steps # To learn how to perform operations on your devices, please see the Performing LwM2M operations chapter.","title":"Configuring the integration"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#configuring-the-integration","text":"Follow this section to integrate your AWS services with Coiote DM.","title":"Configuring the integration"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#prerequisites","text":"An active AWS subscription. A Coiote DM user account with the Cloud admin role. The Git tool ( https://git-scm.com/book/en/v2/Getting-Started-Installing-Git ). The AWS CLI ( https://aws.amazon.com/cli/ ). Terraform CLI ( https://learn.hashicorp.com/tutorials/terraform/install-cli ).","title":"Prerequisites"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#create-a-coiote-dm-rest-user","text":"To start integrating AWS with Coiote DM, you first need to create a user account that will be used to authorize and authenticate API calls from AWS in Coiote DM. To do that: Go to your Coiote DM account and from the Administration menu, select Users management . Select Add user and in fill in the form: Provide Email for new user (which will be its user name) and select your domain from the Domain path drop-down list. Remember to switch on the User Verified and User Enabled toggle buttons. In the Client Roles field, pick the admin-cli role. Click Save . Go to the Credentials tab, type a password for your user (twice), select Set password , then confirm by clicking Set password in the pop-up.","title":"Create a Coiote DM REST user"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#copy-tasks-and-provide-credentials-for-your-device-group-in-coiote-dm","text":"The Coiote DM-side configuration of the integration is located in the dedicated AWSiotCore device group. To complete this side of the integration, log in as the user with the Cloud admin role and follow the steps below: Go to the Device groups panel and select a group: For the default setting, select the AWSiotCore group which already contains all the necessary tasks and setting values. Alternatively, create a new group and migrate the required tasks and setting values: Select the Add button, name your group and click Add . Migrate all the six tasks that have the AWS prefix in their task name: Select the AWSiotCore group and go to Group tasks , select the first AWS task and click Copy . In the pop-up window, click Select group in the Task target field and choose your custom integration group from the list. In the Actions field, select Add new task . Repeat the action for the remaining five tasks. Migrate all the five setting values that have the AWS prefix in their task name: Select your custom integration group and go to Profiles , then select Copy from . In the pop-up window, click Select group and select the AWSiotCore group. Pick all the five AWS setting values from the list by checking them in the Selected column, then click Copy . Enter your AWS subscription credentials in Coiote DM: Go to Device groups , select your custom integration group (or the AWSiotCore group, depending on the previous step) and go to Profiles . Complete the AWS setting values with your AWS credentials: For AWSaccessKeyID and AWSsecretAccessKey : Go to AWS Identity and Access Management , click Users and select your user name from the list. Select the Security credentials tab and, under the Access keys section, click Create access key . Copy the generated Access key ID and Secret access key . In Coiote DM, go to the Profiles tab of your integration group and paste the credentials as values for AWSaccessKeyID and AWSsecretAccessKey . Click Save . For AWSregion : While in AWS IoT Core, click on your region name in the top navigation bar to expand the list of regions. Then, copy the hyphenated region name (e.g. us-east-1 ). In Coiote DM, go to the Profiles tab of your integration group and paste the region name as the value for AWSregion . Click Save . For AWScontrolPlaneEndpointAddress : Go to AWS documentation : https://docs.aws.amazon.com/general/latest/gr/iot-core.html . From the Control Plane API Endpoints section, find the endpoint that matches your region (e.g. iot.us-east-1.amazonaws.com ) and copy it. In Coiote DM, go to the Profiles tab of your integration group and paste the credentials as the value for AWScontrolPlaneEndpointAddress . Click Save . For AWSdataPlaneEndpointAddress : Open your command line and run the following command: aws iot describe-endpoint --endpoint-type iot:Data-ATS Copy the returned result. In Coiote DM, go to the Profiles tab of your integration group and paste the result as the value for AWSdataPlaneEndpointAddress . Click Save . Optionally, you may now add your LwM2M devices to the integration device group so that they are ready once the integration setup is complete.","title":"Copy tasks and provide credentials for your device group in Coiote DM"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#add-aws-resources-using-the-integration-repository","text":"All the AWS-side configuration needed for the integration to work is stored in a publicly available git repository ( https://github.com/AVSystem/iot-examples/tree/main/coiote-aws-iot-terraform ). To add the resources needed for the integration to your AWS services: Clone the repository into your local drive and check out on the coiote-aws-iot-terraform branch: Run your command line and paste the following commands: git clone --no-checkout https://github.com/AVSystem/iot-examples.git cd iot-examples git sparse-checkout set coiote-aws-iot-terraform git checkout main cd coiote-aws-iot-terraform Insert your REST user credentials into the vars.py file: In the catalog of your local repository, find the vars.py file and open it using a program that enables file edition. Change the default values of the variables to the credentials of your REST user created in a previous step. For coioteDMrestURL , provide the URL address and port of your Coiote DM installation. By default, it's https://lwm2m-test.avsystem.io:8087. For coioteDMrestPassword , provide the password set for your Coiote DM REST user. For coioteDMrestUsername , provide your Coiote DM REST user login (email address). Save the file. Run Terraform: Go back to your command line and paste the following: terraform init terraform apply Run the command. It will copy all the 16 resources contained in the main.tf file from the repository into your AWS services. Among the key resources that enable the integration, there are: the iam_for_lambda role, the lwm2mOperation Lambda function, and the operationRequest and operationResponse rules. See the contents of the main.tf file below or refer to the Concepts chapter for more details. resource \"aws_iam_role\" \"iam_for_lambda\" { na me = \"iam_for_lambda\" assume_role_policy = <<EOF { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Action\" : \"sts:AssumeRole\" , \"Principal\" : { \"Service\" : \"lambda.amazonaws.com\" }, \"Effect\" : \"Allow\" } ] } EOF } resource \"aws_iam_policy_attachment\" \"policy_attachment\" { na me = \"attachment\" roles = [ aws_iam_role.iam_ f or_lambda. na me ] policy_ar n = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\" } resource \"random_string\" \"r\" { le n g t h = 16 special = false } da ta \"archive_file\" \"lambda_zip\" { t ype = \"zip\" source_dir = \"lwm2mOperation\" ou t pu t _pa t h = \"lwm2mOperation.zip\" depe n ds_o n = [ ra n dom_s tr i n g.r ] } resource \"aws_lambda_function\" \"lwm2mOperation\" { f ile na me = \"lwm2mOperation.zip\" fun c t io n _ na me = \"lwm2mOperation\" role = aws_iam_role.iam_ f or_lambda.ar n ha n dler = \"lambda_function.lambda_handler\" source_code_hash = da ta .archive_ f ile.lambda_zip.ou t pu t _base 64 sha 256 ru nt ime = \"python3.8\" e n viro n me nt { variables = { coio te DMres t Password = var.coio te DMres t Password coio te DMres t Uri = var.coio te DMres t URL coio te DMres t User na me = var.coio te DMres t User na me } } } module \"iot_rule_1\" { na me = \"operationRequest\" sql_query = \"SELECT state.desired.operation AS operation, state.desired.keys AS keys, state.desired.values AS values, state.desired.attributes AS attributes, state.desired.arguments AS arguments, topic(3) AS thingName FROM '$aws/things/+/shadow/name/operation/update/accepted' WHERE isUndefined(state.desired.operation) = false\" source = \"git::https://github.com/Passarinho4/terraform-aws-iot-topic-rule.git?ref=master\" lambda = [ \"lwm2mOperation\" ] depe n ds_o n = [ aws_lambda_ fun c t io n .lwm 2 mOpera t io n ] } module \"iot_rule_2\" { na me = \"operationResponse\" sql_query = \"SELECT state.reported.result AS state.reported FROM '$aws/things/+/shadow/name/operation/update/accepted' WHERE (CASE isUndefined(state.reported.operation) WHEN true THEN false ELSE CASE state.reported.operation = 'read' OR state.reported.operation = 'write' OR state.reported.operation = 'readComposite' when true THEN true ELSE false END END) = true\" source = \"git::https://github.com/Passarinho4/terraform-aws-iot-topic-rule.git?ref=master\" republish = [{ t opic = \"$$aws/things/$${topic(3)}/shadow/name/datamodel/update\" }] Once the Terraform command is executed successfully, the devices in your integration group will be automatically migrated to the AWS IoT Core. To check if your integration works correctly, go to AWS IoT Core, and from the menu, select Manage > Things , then see if your devices are listed as in here:","title":"Add AWS resources using the integration repository"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#next-steps","text":"To learn how to perform operations on your devices, please see the Performing LwM2M operations chapter.","title":"Next steps"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html","text":"How AWS integration works # Here's a walkthrough of the main concepts related to the AWS IoT Core - Coiote DM integration that will help you understand the role of each of the integration components and how they are employed for the benefit of LwM2M device management via the AWS services. Things # Within the AWS IoT Core - Coiote DM integration, things are the AWS representations of LwM2M device entities managed by the Coiote DM platform. They are used to mirror device state, as well as collect, process and act upon device data on the fly using a connection protocol of your choice. Note Things are automatically added to AWS IoT Core upon completing the integration setup and successful device connection. Thing types # Thing types are containers that store configuration and other device-related information shared by all Things of the same type to simplify their bulk management. Within the integration, they are created automatically when a new device is added to AWS from Coiote DM and they are based on device Manufacturer and Model name . In case a new device with a specific Manufacturer and model name pair can be matched with an existing thing type, then it will be associated with it automatically. Note Note that you cannot modify a once created thing type, but you can deprecate (allowing no new devices to be associated with it) or delete it when there are no things associated with a given Thing type. Device Shadows # A device shadow is a structure that stores the device state and represents it in the form of a JSON file, making the device data available to applications and services regardless of device connection to Coiote DM. To synchronize device state information between the Coiote DM and AWS IoT Core, shadows feature the mechanism of reported and desired values. Reported values section - presents the current device state as reported by the device itself (and mediated by Coiote DM) in a JSON file structure within a device shadow. Desired values section - used for requesting changes in the reported section of the device Operation shadow . For the purposes of the integration, a default of three different shadows is established for each connected thing: an unnamed shadow, a datamodel shadow and an operation shadow. Classic Shadow # The Classic shadow (also unnamed shadow) is used for storing connectivity parameters of a LwM2M device (such as registered lifetime, last lifetime refresh, queue mode, LwM2M URI, device registration status etc.). The reported state refreshes upon each change in these parameters that is reported by Coiote DM ( Register or Update message from device). Operation Shadow # The Operation Shadow is where you request your LwM2M operations to be executed. To this end, the desired values of the device state are used. Thus, you can perform any LwM2M 1.0 operation on the device by defining it inside the desired values section. Also, to check if the operation execution was successful, the reported values section of the Operation Shadow is used (but only in case of the READ, WRITE and READ COMPOSITE operations). Communication flow # A value change using the desired device state is formulated as the one below: { \"state\" : { \"desired\" : { \"operation\" : \"write\" , \"keys\" : [ \"LwM2M Server.1.Lifetime\" , \"Device.0.UTC Offset\" ], \"values\" : [ 68 , \"+02:00\" ] } } } Once a value change in the desired section of the operation shadow is saved, a chain of events starts: A change in the desired section triggers the operationRequest rule. The operationRequest rule sends a request to AWS Lambda . AWS Lambda validates the request and forwards it as an event to Coiote DM, making it schedule a task and initiate a device session. Coiote DM communicates with the device. The device responds to Coiote DM with the operation result. Coiote DM forwards the device response back to the Operation Shadow and the results are published in the reported section. The change in the reported section triggers the operationResponse rule. The results are then republished using the operationResponse rule to the Datamodel shadow (but only in case of the READ, WRITE and READ COMPOSITE operations). Datamodel Shadow # The Datamodel Shadow is the place where the cashed data model of the LwM2M device is stored. What this means is that it is a \"read-only shadow\" that keeps the most recent record of the device state as it has been reported by Coiote DM - no device operations can be performed from here. The Datamodel Shadow is updated in case of the following events: Device Register message that comes from Coiote DM, Device Notify and Send messages, Republishing operation results from the Operation shadow to the Datamodel shadow using the operationResponse rule. CloudWatch logs # CloudWatch collects and keeps a record of all the logs generated on the AWS-side of the integration. You can use these data for analysis and troubleshooting in case of all the AWS integration components: Device Shadows (the data plane), Things and Thing types (the control plane), The Rules mechanism, AWS Lambda.","title":"How AWS integration works"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#how-aws-integration-works","text":"Here's a walkthrough of the main concepts related to the AWS IoT Core - Coiote DM integration that will help you understand the role of each of the integration components and how they are employed for the benefit of LwM2M device management via the AWS services.","title":"How AWS integration works"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#things","text":"Within the AWS IoT Core - Coiote DM integration, things are the AWS representations of LwM2M device entities managed by the Coiote DM platform. They are used to mirror device state, as well as collect, process and act upon device data on the fly using a connection protocol of your choice. Note Things are automatically added to AWS IoT Core upon completing the integration setup and successful device connection.","title":"Things"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#thing-types","text":"Thing types are containers that store configuration and other device-related information shared by all Things of the same type to simplify their bulk management. Within the integration, they are created automatically when a new device is added to AWS from Coiote DM and they are based on device Manufacturer and Model name . In case a new device with a specific Manufacturer and model name pair can be matched with an existing thing type, then it will be associated with it automatically. Note Note that you cannot modify a once created thing type, but you can deprecate (allowing no new devices to be associated with it) or delete it when there are no things associated with a given Thing type.","title":"Thing types"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#device-shadows","text":"A device shadow is a structure that stores the device state and represents it in the form of a JSON file, making the device data available to applications and services regardless of device connection to Coiote DM. To synchronize device state information between the Coiote DM and AWS IoT Core, shadows feature the mechanism of reported and desired values. Reported values section - presents the current device state as reported by the device itself (and mediated by Coiote DM) in a JSON file structure within a device shadow. Desired values section - used for requesting changes in the reported section of the device Operation shadow . For the purposes of the integration, a default of three different shadows is established for each connected thing: an unnamed shadow, a datamodel shadow and an operation shadow.","title":"Device Shadows"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#classic-shadow","text":"The Classic shadow (also unnamed shadow) is used for storing connectivity parameters of a LwM2M device (such as registered lifetime, last lifetime refresh, queue mode, LwM2M URI, device registration status etc.). The reported state refreshes upon each change in these parameters that is reported by Coiote DM ( Register or Update message from device).","title":"Classic Shadow"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#operation-shadow","text":"The Operation Shadow is where you request your LwM2M operations to be executed. To this end, the desired values of the device state are used. Thus, you can perform any LwM2M 1.0 operation on the device by defining it inside the desired values section. Also, to check if the operation execution was successful, the reported values section of the Operation Shadow is used (but only in case of the READ, WRITE and READ COMPOSITE operations).","title":"Operation Shadow"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#communication-flow","text":"A value change using the desired device state is formulated as the one below: { \"state\" : { \"desired\" : { \"operation\" : \"write\" , \"keys\" : [ \"LwM2M Server.1.Lifetime\" , \"Device.0.UTC Offset\" ], \"values\" : [ 68 , \"+02:00\" ] } } } Once a value change in the desired section of the operation shadow is saved, a chain of events starts: A change in the desired section triggers the operationRequest rule. The operationRequest rule sends a request to AWS Lambda . AWS Lambda validates the request and forwards it as an event to Coiote DM, making it schedule a task and initiate a device session. Coiote DM communicates with the device. The device responds to Coiote DM with the operation result. Coiote DM forwards the device response back to the Operation Shadow and the results are published in the reported section. The change in the reported section triggers the operationResponse rule. The results are then republished using the operationResponse rule to the Datamodel shadow (but only in case of the READ, WRITE and READ COMPOSITE operations).","title":"Communication flow"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#datamodel-shadow","text":"The Datamodel Shadow is the place where the cashed data model of the LwM2M device is stored. What this means is that it is a \"read-only shadow\" that keeps the most recent record of the device state as it has been reported by Coiote DM - no device operations can be performed from here. The Datamodel Shadow is updated in case of the following events: Device Register message that comes from Coiote DM, Device Notify and Send messages, Republishing operation results from the Operation shadow to the Datamodel shadow using the operationResponse rule.","title":"Datamodel Shadow"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#cloudwatch-logs","text":"CloudWatch collects and keeps a record of all the logs generated on the AWS-side of the integration. You can use these data for analysis and troubleshooting in case of all the AWS integration components: Device Shadows (the data plane), Things and Thing types (the control plane), The Rules mechanism, AWS Lambda.","title":"CloudWatch logs"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html","text":"Performing LwM2M operations # This section will give you an overview of how to perform LwM2M operations on devices in AWS IoT Core and check AWS CloudWatch logs. Prerequisites # A configured AWS integration. An active LwM2M device already migrated to AWS IoT Core. Execute LwM2M operations on device # Within the AWS - Coiote DM integration, LwM2M operations on devices are triggered by modifying the desired section of a device Operation Shadow . The changes, upon successful execution, are then reported back by Coiote DM and repopulated to the reported section of a device Datamodel Shadow . The integration supports the following LwM2M operations: READ # To send a request for a READ operation to a device: Enter AWS IoT Core and go to Manage > Things . From the list, select your device. Go to the Device Shadows section and select the operation Shadow. Click Edit and formulate the request inside the Device Shadow state field based on the example input given below: In the operation section, type the operation name In the keys section, type the LwM2M object and resource paths for which you want to execute the operation. In the values section, type the values for the specified keys (only for some operations). Read_request { \"state\": { \"desired\": { \"operation\": \"read\", \"keys\": [ \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array.4\" ] } } } Click Save . To see the operation results, check the reported section of the operation Shadow. An example response looks like this: Read_result { \"reported\": { \"operation\": \"read\", \"failedKeys\": [ \"\" ], \"result\": { \"Device\": { \"0\": { \"UTC Offset\": \"+02:00\" } }, \"LwM2M Server\": { \"1\": { \"Lifetime\": \"68\" } }, \"Portfolio\": { \"5\": { \"Identity\": { \"1\": \"AVS\" } }, \"11\": { \"Identity\": { \"1\": \"your_ID\" } } }, \"Test object\": { \"0\": { \"Integer array\": { \"4\": \"256\" } } } } } } Note To execute a READ operation on all the readable resources, enter \"\"/\"\" or \"\"all\"\" as the value in the keys section of the request. WRITE # To request a WRITE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Write_request { \"state\": { \"desired\": { \"operation\": \"write\", \"keys\": [ \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array.4\" ], \"values\": [ 68, \"your_ID\", \"random_value\", \"+02:00\", 256 ] } } } OBSERVE # To request a OBSERVE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Observe_request { \"state\": { \"desired\": { \"operation\": \"observe\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ {\"epmin\":5,\"gt\":-65.5,\"lt\":-105.5,\"st\":4.0}, {\"pmin\":30,\"pmax\":35}, {}, {\"epmax\":40}, {}, {\"pmax\":20} ] } } } Note In the attributes section, you need to specify the full attribute list with their corresponding values for a given key, as the attributes that are left out will be overwritten with null (except for the con attribute). Alternatively, you can provide an empty value {} so that no attribute values are changed. On the other hand, if you only specify the con attribute for a given key, it will not affect any other attributes and their existing values won't be changed also. To check the results of the OBSERVE operation, go to the datamodel Shadow of your device and see the reported section. EXECUTE # To request an EXECUTE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Execute_request { \"state\": { \"desired\": { \"operation\": \"execute\", \"keys\": [ \"Device.0.Reboot\" ] } } } Note With the EXECUTE operation, you can specify only one key for each request. Other operations # Here are example inputs for other operations supported by the integration: READ COMPOSITE, OBSERVE COMPOSITE, WRITE ATTRIBUTES, CANCEL OBSERVE, CANCEL OBSERVE COMPOSITE. Cancel Observe # Cancel_observe { \"state\": { \"desired\": { \"operation\": \"cancelObserve\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } } Note To cancel all the current OBSERVE requests, type \"all\" in the keys section. Write Attributes # Write_attributes { \"state\": { \"desired\": { \"operation\": \"writeAttributes\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ { \"epmin\": 5, \"gt\": -65.5, \"lt\": -105.5, \"st\": 4, \"con\": 1 }, { \"pmin\": 30, \"pmax\": 35, \"con\": \"\" }, {}, { \"epmax\": 40 }, { \"con\": null }, { \"pmax\": 20 } ] } } } Observe-Composite # Observe_composite { \"state\": { \"desired\": { \"operation\": \"observeComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ { \"epmin\": 5, \"gt\": -65.5, \"lt\": -105.5, \"st\": 4, \"con\": 1 }, { \"pmin\": 30, \"pmax\": 35, \"con\": \"\" }, {}, { \"epmax\": 40 }, { \"con\": null }, { \"pmax\": 20 } ] } } } Read-Composite # Read_composite { \"state\": { \"desired\": { \"operation\": \"readComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } } Cancel Observe-Composite # Cancelobserve_composite { \"state\": { \"desired\": { \"operation\": \"cancelObserveComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } } Check logs in CloudWatch # If you encounter difficulties when forwarding your requests to Coiote DM, it may be helpful to check the logs collected by AWS CloudWatch for all the components of the integration. To check logs for AWS Lambda: Go to AWS CloudWatch and select Logs > Log groups . From the Log groups list, select the /aws/lambda/lwm2mOperation group. To check logs for all integration components in one place: Go to AWS CloudWatch and select Logs > Log groups . From the Log groups list, select the AWSIotLogsV2 group. Select all the logs from the list by checking the box next to Log stream and click Search all . Expand a log stream to see its details by clicking the arrow icon > .","title":"Performing LwM2M operations"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#performing-lwm2m-operations","text":"This section will give you an overview of how to perform LwM2M operations on devices in AWS IoT Core and check AWS CloudWatch logs.","title":"Performing LwM2M operations"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#prerequisites","text":"A configured AWS integration. An active LwM2M device already migrated to AWS IoT Core.","title":"Prerequisites"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#execute-lwm2m-operations-on-device","text":"Within the AWS - Coiote DM integration, LwM2M operations on devices are triggered by modifying the desired section of a device Operation Shadow . The changes, upon successful execution, are then reported back by Coiote DM and repopulated to the reported section of a device Datamodel Shadow . The integration supports the following LwM2M operations:","title":"Execute LwM2M operations on device"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#read","text":"To send a request for a READ operation to a device: Enter AWS IoT Core and go to Manage > Things . From the list, select your device. Go to the Device Shadows section and select the operation Shadow. Click Edit and formulate the request inside the Device Shadow state field based on the example input given below: In the operation section, type the operation name In the keys section, type the LwM2M object and resource paths for which you want to execute the operation. In the values section, type the values for the specified keys (only for some operations). Read_request { \"state\": { \"desired\": { \"operation\": \"read\", \"keys\": [ \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array.4\" ] } } } Click Save . To see the operation results, check the reported section of the operation Shadow. An example response looks like this: Read_result { \"reported\": { \"operation\": \"read\", \"failedKeys\": [ \"\" ], \"result\": { \"Device\": { \"0\": { \"UTC Offset\": \"+02:00\" } }, \"LwM2M Server\": { \"1\": { \"Lifetime\": \"68\" } }, \"Portfolio\": { \"5\": { \"Identity\": { \"1\": \"AVS\" } }, \"11\": { \"Identity\": { \"1\": \"your_ID\" } } }, \"Test object\": { \"0\": { \"Integer array\": { \"4\": \"256\" } } } } } } Note To execute a READ operation on all the readable resources, enter \"\"/\"\" or \"\"all\"\" as the value in the keys section of the request.","title":"READ"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#write","text":"To request a WRITE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Write_request { \"state\": { \"desired\": { \"operation\": \"write\", \"keys\": [ \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array.4\" ], \"values\": [ 68, \"your_ID\", \"random_value\", \"+02:00\", 256 ] } } }","title":"WRITE"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#observe","text":"To request a OBSERVE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Observe_request { \"state\": { \"desired\": { \"operation\": \"observe\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ {\"epmin\":5,\"gt\":-65.5,\"lt\":-105.5,\"st\":4.0}, {\"pmin\":30,\"pmax\":35}, {}, {\"epmax\":40}, {}, {\"pmax\":20} ] } } } Note In the attributes section, you need to specify the full attribute list with their corresponding values for a given key, as the attributes that are left out will be overwritten with null (except for the con attribute). Alternatively, you can provide an empty value {} so that no attribute values are changed. On the other hand, if you only specify the con attribute for a given key, it will not affect any other attributes and their existing values won't be changed also. To check the results of the OBSERVE operation, go to the datamodel Shadow of your device and see the reported section.","title":"OBSERVE"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#execute","text":"To request an EXECUTE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Execute_request { \"state\": { \"desired\": { \"operation\": \"execute\", \"keys\": [ \"Device.0.Reboot\" ] } } } Note With the EXECUTE operation, you can specify only one key for each request.","title":"EXECUTE"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#other-operations","text":"Here are example inputs for other operations supported by the integration: READ COMPOSITE, OBSERVE COMPOSITE, WRITE ATTRIBUTES, CANCEL OBSERVE, CANCEL OBSERVE COMPOSITE.","title":"Other operations"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#cancel-observe","text":"Cancel_observe { \"state\": { \"desired\": { \"operation\": \"cancelObserve\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } } Note To cancel all the current OBSERVE requests, type \"all\" in the keys section.","title":"Cancel Observe"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#write-attributes","text":"Write_attributes { \"state\": { \"desired\": { \"operation\": \"writeAttributes\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ { \"epmin\": 5, \"gt\": -65.5, \"lt\": -105.5, \"st\": 4, \"con\": 1 }, { \"pmin\": 30, \"pmax\": 35, \"con\": \"\" }, {}, { \"epmax\": 40 }, { \"con\": null }, { \"pmax\": 20 } ] } } }","title":"Write Attributes"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#observe-composite","text":"Observe_composite { \"state\": { \"desired\": { \"operation\": \"observeComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ { \"epmin\": 5, \"gt\": -65.5, \"lt\": -105.5, \"st\": 4, \"con\": 1 }, { \"pmin\": 30, \"pmax\": 35, \"con\": \"\" }, {}, { \"epmax\": 40 }, { \"con\": null }, { \"pmax\": 20 } ] } } }","title":"Observe-Composite"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#read-composite","text":"Read_composite { \"state\": { \"desired\": { \"operation\": \"readComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } }","title":"Read-Composite"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#cancel-observe-composite","text":"Cancelobserve_composite { \"state\": { \"desired\": { \"operation\": \"cancelObserveComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } }","title":"Cancel Observe-Composite"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#check-logs-in-cloudwatch","text":"If you encounter difficulties when forwarding your requests to Coiote DM, it may be helpful to check the logs collected by AWS CloudWatch for all the components of the integration. To check logs for AWS Lambda: Go to AWS CloudWatch and select Logs > Log groups . From the Log groups list, select the /aws/lambda/lwm2mOperation group. To check logs for all integration components in one place: Go to AWS CloudWatch and select Logs > Log groups . From the Log groups list, select the AWSIotLogsV2 group. Select all the logs from the list by checking the box next to Log stream and click Search all . Expand a log stream to see its details by clicking the arrow icon > .","title":"Check logs in CloudWatch"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html","text":"Configuring integration extension # To enable communication and data flow between the Azure IoT Central and Coiote DM platforms, you first need to integrate them using the dedicated extension module in Coiote DM. Follow the instruction below to learn how to do it. Prerequisites: # An active IoT Central with hub owner access permissions. A Coiote DM user account with permissions to use the integration extension. Get the Azure IoT Central integration credentials # In your Azure IoT Central account view, go to Administration : Under Your application , copy the full Application URL (along with '.azureiotcentral.com') into Notepad or other place to keep it for later. From the Administration menu, select API tokens and click generate token . In the pop-up window that appears, click the copy icon for the newly generated token. Now you need to use the obtained credentials in the Coiote DM platform. Set up the Azure IoT Hub Extension using credentials. # In your Coiote DM user account, go to Administration \u2192 Extensions . Find the Azure IoT Central tab and click Setup . Inside the tab: paste the previously copied Azure IoT Central Application URL , provide the API token and, if needed, enter your Device Provisioning Service hostname (however, the default address provided is sufficient in most cases). use Test connection to see if the connection can be established correctly. click Save to keep the setting. Next steps # Importing devices to Coiote DM Exporting devices to Azure IoT Central","title":"Configuring integration extension"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html#configuring-integration-extension","text":"To enable communication and data flow between the Azure IoT Central and Coiote DM platforms, you first need to integrate them using the dedicated extension module in Coiote DM. Follow the instruction below to learn how to do it.","title":"Configuring integration extension"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html#prerequisites","text":"An active IoT Central with hub owner access permissions. A Coiote DM user account with permissions to use the integration extension.","title":"Prerequisites:"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html#get-the-azure-iot-central-integration-credentials","text":"In your Azure IoT Central account view, go to Administration : Under Your application , copy the full Application URL (along with '.azureiotcentral.com') into Notepad or other place to keep it for later. From the Administration menu, select API tokens and click generate token . In the pop-up window that appears, click the copy icon for the newly generated token. Now you need to use the obtained credentials in the Coiote DM platform.","title":"Get the Azure IoT Central integration credentials"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html#set-up-the-azure-iot-hub-extension-using-credentials","text":"In your Coiote DM user account, go to Administration \u2192 Extensions . Find the Azure IoT Central tab and click Setup . Inside the tab: paste the previously copied Azure IoT Central Application URL , provide the API token and, if needed, enter your Device Provisioning Service hostname (however, the default address provided is sufficient in most cases). use Test connection to see if the connection can be established correctly. click Save to keep the setting.","title":"Set up the Azure IoT Hub Extension using credentials."},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html#next-steps","text":"Importing devices to Coiote DM Exporting devices to Azure IoT Central","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html","text":"Exporting devices to Azure IoT Central # If you have device entities in Coiote DM that you would like to manage via the Azure IoT Central, you may use the export functionality. Follow the instruction below to learn how to do it in four basic steps: Create a device Create a group of devices for export Export your Coiote DM devices to CSV Import the CSV file to Azure IoT Central Create a device entity in Coiote DM # If you don't have any devices in your Coiote DM Device Inventory , follow these instructions to add one or more devices. In the Coiote DM Device Inventory , select Device Creator . In the next screen, choose the Connect your LwM2M device directly via the Management server . In the Device credentials step, provide a name for your device, then select NoSec from the Security mode list and click Add device . In the pop-up window, click Confirm to add your device entity. Now it should be listed in Device Inventory . Create a group of devices for export # Now that you have some devices added, you need to insert all the devices to be exported into a common group for ease of configuration. In Coiote DM, go to Device Inventory , filter the devices you would like to export and use the Add to group action. In the pop-up window that appears, select Add to new group , provide a name for the group and click Confirm . Export your devices to CSV # You are now ready to export your devices. In the Device groups panel, select your group of devices for export and click the Actions tab. Under Management , select the Export devices to Azure IoT Central . In the pop-up window: mark Skip already exported devices optionally if you have already exported some of the devices belonging to this group. select Export to CSV . After a moment, the export operation should finish and a CSV file should start downloading. Import the CSV file to Azure IoT Central # Once you have the CSV file downloaded, you can use it to import the devices into Azure IoT Central. From the left pane of your Azure IoT Central account, choose Devices and select a device template into which you want to import the devices. Select Import . In the pop-up that appears, select the previously downloaded CSV file. The import process should start. Its status can be tracked in the Device Operations panel in the top right-hand corner. Once the import process is complete, a success message should appear. If there are any errors, a log file will be generated in Device Operations that you can download. Note To learn more about importing device entities to Azure IoT Central, click here . Next steps #","title":"Exporting devices to Azure IoT Central"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#exporting-devices-to-azure-iot-central","text":"If you have device entities in Coiote DM that you would like to manage via the Azure IoT Central, you may use the export functionality. Follow the instruction below to learn how to do it in four basic steps: Create a device Create a group of devices for export Export your Coiote DM devices to CSV Import the CSV file to Azure IoT Central","title":"Exporting devices to Azure IoT Central"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#create-a-device-entity-in-coiote-dm","text":"If you don't have any devices in your Coiote DM Device Inventory , follow these instructions to add one or more devices. In the Coiote DM Device Inventory , select Device Creator . In the next screen, choose the Connect your LwM2M device directly via the Management server . In the Device credentials step, provide a name for your device, then select NoSec from the Security mode list and click Add device . In the pop-up window, click Confirm to add your device entity. Now it should be listed in Device Inventory .","title":"Create a device entity in Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#create-a-group-of-devices-for-export","text":"Now that you have some devices added, you need to insert all the devices to be exported into a common group for ease of configuration. In Coiote DM, go to Device Inventory , filter the devices you would like to export and use the Add to group action. In the pop-up window that appears, select Add to new group , provide a name for the group and click Confirm .","title":"Create a group of devices for export"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#export-your-devices-to-csv","text":"You are now ready to export your devices. In the Device groups panel, select your group of devices for export and click the Actions tab. Under Management , select the Export devices to Azure IoT Central . In the pop-up window: mark Skip already exported devices optionally if you have already exported some of the devices belonging to this group. select Export to CSV . After a moment, the export operation should finish and a CSV file should start downloading.","title":"Export your devices to CSV"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#import-the-csv-file-to-azure-iot-central","text":"Once you have the CSV file downloaded, you can use it to import the devices into Azure IoT Central. From the left pane of your Azure IoT Central account, choose Devices and select a device template into which you want to import the devices. Select Import . In the pop-up that appears, select the previously downloaded CSV file. The import process should start. Its status can be tracked in the Device Operations panel in the top right-hand corner. Once the import process is complete, a success message should appear. If there are any errors, a log file will be generated in Device Operations that you can download. Note To learn more about importing device entities to Azure IoT Central, click here .","title":"Import the CSV file to Azure IoT Central"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#next-steps","text":"","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html","text":"Importing devices to Coiote DM # If you would like to migrate any device entities from your Azure IoT Central to the Coiote DM platform for full management possibilities, follow the instruction below. Prerequisites # Configured and working Azure IoT Hub integration extension (see Configuring the Azure IoT Central integration extension for details). Add devices to Azure IoT Central # If you don't have any device entities added in your Azure IoT Central, follow these steps to learn how to do it: In your Azure IoT Central account, go to Devices , select All Devices and click +New . In the panel, click +New . Provide your device name and ID in the relevant field and click Create . Sync your devices # In order to establish communication and data flow between device entities in Azure IoT Central and their Coiote DM counterparts, you need to sync them. Go to Device inventory , click the Sync with IoT platform button and select Azure IoT Central . In the pop-up window: from the list, select the devices for synchronization. click Sync devices to start the synchronization. After a successful sync, the devices should be listed in Device inventory . Next steps #","title":"Importing devices to Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html#importing-devices-to-coiote-dm","text":"If you would like to migrate any device entities from your Azure IoT Central to the Coiote DM platform for full management possibilities, follow the instruction below.","title":"Importing devices to Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html#prerequisites","text":"Configured and working Azure IoT Hub integration extension (see Configuring the Azure IoT Central integration extension for details).","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html#add-devices-to-azure-iot-central","text":"If you don't have any device entities added in your Azure IoT Central, follow these steps to learn how to do it: In your Azure IoT Central account, go to Devices , select All Devices and click +New . In the panel, click +New . Provide your device name and ID in the relevant field and click Create .","title":"Add devices to Azure IoT Central"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html#sync-your-devices","text":"In order to establish communication and data flow between device entities in Azure IoT Central and their Coiote DM counterparts, you need to sync them. Go to Device inventory , click the Sync with IoT platform button and select Azure IoT Central . In the pop-up window: from the list, select the devices for synchronization. click Sync devices to start the synchronization. After a successful sync, the devices should be listed in Device inventory .","title":"Sync your devices"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html#next-steps","text":"","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Overview.html","text":"Overview # How synchronization works # Coiote DM provides zero-touch provisioning for synchronized devices from Azure IoT Central. This means that device entities are automatically created within Coiote DM upon synchronization with the Azure IoT Central and this is repeated periodically for any new devices that appear. Therefore, after one successful synchronization, you can be sure that any devices that have been added to Azure IoT Central at a later time will also be migrated to Coiote DM.","title":"Overview"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Overview.html#overview","text":"","title":"Overview"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Overview.html#how-synchronization-works","text":"Coiote DM provides zero-touch provisioning for synchronized devices from Azure IoT Central. This means that device entities are automatically created within Coiote DM upon synchronization with the Azure IoT Central and this is repeated periodically for any new devices that appear. Therefore, after one successful synchronization, you can be sure that any devices that have been added to Azure IoT Central at a later time will also be migrated to Coiote DM.","title":"How synchronization works"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html","text":"Configuring integration extension # To enable communication and data flow between the Azure IoT Hub and Coiote DM platforms, you first need to integrate them using the dedicated extension module in Coiote DM. Follow the instruction below to learn how to do it. Prerequisites # An active IoT Hub with hub owner access permissions. Check here how to create a hub. A Coiote DM user account with permissions to use the integration extension. Optionally, an active Azure Blob Storage account. Get the IoT Hub connection string # In your IoT Hub general view, go to Shared access policies : From the list of policies, select the iothubowner policy. Under Shared access keys , click the copy icon for the Connection string -- primary key to save the value. Info For detailed information about the IoT Hub permissions, please visit the Control access to IoT Hub section of the Azure IoT Hub documentation. Now you need to use the credential in the Coiote DM platform. Set up the Azure IoT Hub Extension using credentials # In your Coiote DM user account, go to Administration \u2192 Extensions . Find the Azure IoT Hub tab and click Setup . In the tab, paste the previously copied IoT Hub connection string. check Enable automatic synchronization to periodically synchronize any new devices that appear in the Azure IoT Hub. use Test connection to see if the connection can be established correctly. click Save to keep the setting. Optionally, you can also provide the Azure Blob Storage connection string that will be required in case you would like to export devices from Coiote DM to Azure IoT Hub. Click here to learn how to obtain and apply it. Next steps # Importing Azure IoT Hub devices to Coiote DM Exporting devices to Azure IoT Hub","title":"Configuring integration extension"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html#configuring-integration-extension","text":"To enable communication and data flow between the Azure IoT Hub and Coiote DM platforms, you first need to integrate them using the dedicated extension module in Coiote DM. Follow the instruction below to learn how to do it.","title":"Configuring integration extension"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html#prerequisites","text":"An active IoT Hub with hub owner access permissions. Check here how to create a hub. A Coiote DM user account with permissions to use the integration extension. Optionally, an active Azure Blob Storage account.","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html#get-the-iot-hub-connection-string","text":"In your IoT Hub general view, go to Shared access policies : From the list of policies, select the iothubowner policy. Under Shared access keys , click the copy icon for the Connection string -- primary key to save the value. Info For detailed information about the IoT Hub permissions, please visit the Control access to IoT Hub section of the Azure IoT Hub documentation. Now you need to use the credential in the Coiote DM platform.","title":"Get the IoT Hub connection string"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html#set-up-the-azure-iot-hub-extension-using-credentials","text":"In your Coiote DM user account, go to Administration \u2192 Extensions . Find the Azure IoT Hub tab and click Setup . In the tab, paste the previously copied IoT Hub connection string. check Enable automatic synchronization to periodically synchronize any new devices that appear in the Azure IoT Hub. use Test connection to see if the connection can be established correctly. click Save to keep the setting. Optionally, you can also provide the Azure Blob Storage connection string that will be required in case you would like to export devices from Coiote DM to Azure IoT Hub. Click here to learn how to obtain and apply it.","title":"Set up the Azure IoT Hub Extension using credentials"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html#next-steps","text":"Importing Azure IoT Hub devices to Coiote DM Exporting devices to Azure IoT Hub","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html","text":"Exporting devices to Azure IoT Hub # If you have device entities in Coiote DM that you would like to manage via the Azure IoT Hub, you may use the export functionality. Follow the instruction below to learn how to do it in four basic steps: Create a device Create a group of devices for export Get the Azure Blob storage connection string Export your devices Prerequisites # An active Azure Blob Storage account. Click here to learn more. Create a device entity in Coiote DM # If you don't have any devices in your Coiote DM Device Inventory , follow these instructions to add one or more devices. In the Coiote DM Device Inventory , select Device Creator . In the next screen, choose the Connect your LwM2M device directly via the Management server . In the Device credentials step, provide a name for your device, then select NoSec from the Security mode list and click Add device . In the pop-up window, click Confirm to add your device entity. Now it should be listed in Device Inventory . Create a group of devices for export # Now that you have some devices added, you need to insert all the devices to be exported into a common group for ease of configuration. In Coiote DM, go to Device Inventory , filter the devices you would like to export and use the Add to group action. In the pop-up window that appears, select Add to new group , provide a name for the group and click Confirm . Get the Azure Blob storage connection string # An Azure Blob storage connection string is required in the export process. Here is how to obtain it: In your Azure Blob storage account, go to Access keys . Click Show keys and copy the connection string to your clipboard. In your Coiote DM user account, go to Administration \u2192 Extensions Find the Azure IoT Hub tab and click Setup . In the tab, paste the previously copied Azure Blob storage connection string. use Test connection to see if the connection can be established correctly. click Save to keep the setting. Export your devices # Now you are ready to export your devices. In the Device groups panel, select your group of devices for export and click the Actions tab. Under Management , select the Export devices to Azure IoT Hub . In the pop-up window: mark Skip already exported devices optionally if you have already exported some of the devices belonging to this group. select Start export . After a moment, the export operation should finish successfully. If there are any errors, you can check the credentials that you provided in the Azure IoT Hub extension setup. Next steps #","title":"Exporting devices to Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#exporting-devices-to-azure-iot-hub","text":"If you have device entities in Coiote DM that you would like to manage via the Azure IoT Hub, you may use the export functionality. Follow the instruction below to learn how to do it in four basic steps: Create a device Create a group of devices for export Get the Azure Blob storage connection string Export your devices","title":"Exporting devices to Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#prerequisites","text":"An active Azure Blob Storage account. Click here to learn more.","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#create-a-device-entity-in-coiote-dm","text":"If you don't have any devices in your Coiote DM Device Inventory , follow these instructions to add one or more devices. In the Coiote DM Device Inventory , select Device Creator . In the next screen, choose the Connect your LwM2M device directly via the Management server . In the Device credentials step, provide a name for your device, then select NoSec from the Security mode list and click Add device . In the pop-up window, click Confirm to add your device entity. Now it should be listed in Device Inventory .","title":"Create a device entity in Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#create-a-group-of-devices-for-export","text":"Now that you have some devices added, you need to insert all the devices to be exported into a common group for ease of configuration. In Coiote DM, go to Device Inventory , filter the devices you would like to export and use the Add to group action. In the pop-up window that appears, select Add to new group , provide a name for the group and click Confirm .","title":"Create a group of devices for export"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#get-the-azure-blob-storage-connection-string","text":"An Azure Blob storage connection string is required in the export process. Here is how to obtain it: In your Azure Blob storage account, go to Access keys . Click Show keys and copy the connection string to your clipboard. In your Coiote DM user account, go to Administration \u2192 Extensions Find the Azure IoT Hub tab and click Setup . In the tab, paste the previously copied Azure Blob storage connection string. use Test connection to see if the connection can be established correctly. click Save to keep the setting.","title":"Get the Azure Blob storage connection string"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#export-your-devices","text":"Now you are ready to export your devices. In the Device groups panel, select your group of devices for export and click the Actions tab. Under Management , select the Export devices to Azure IoT Hub . In the pop-up window: mark Skip already exported devices optionally if you have already exported some of the devices belonging to this group. select Start export . After a moment, the export operation should finish successfully. If there are any errors, you can check the credentials that you provided in the Azure IoT Hub extension setup.","title":"Export your devices"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#next-steps","text":"","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html","text":"Importing devices to Coiote DM # If you would like to migrate any device entities from your Azure IoT to the Coiote DM platform for full management possibilities, follow the instruction below. Prerequisites # Configured and working Azure IoT Hub integration extension (see Configuring the Azure IoT Hub integration extension for details). Add devices to Azure IoT Hub # If you don't have any device entities added in your Azure IoT Hub, follow these steps to learn how to do it: In your Azure IoT Hub account, under Explorers , select IoT devices . In the panel, click +New . Provide device ID in the relevant field and click Save . Your added devices should be visible in IoT devices under Explorers : Sync your devices # In order to establish communication and data flow between device entities in Azure IoT Hub and their Coiote DM counterparts, you need to sync them. Go to Device inventory , click the Sync with IoT platform button and select Azure IoT Hub . In the pop-up window: provide the WHERE clause of the device twin SQL query to filter your devices using chosen tags and properties (to read more about SQL query, check the IoT Hub query language section of Azure IoT Hub documentation. For instance, you can filter by device location region and device status with the following clause: tags.location.region = 'US' AND status = 'enabled' click Count queried devices to check the number of devices that meet the specified conditions (the number is shown inside the Sync devices button) to skip filtering and synchronize all the available devices, leave the WHERE clause input field empty. click Sync devices to start the synchronization. After successful import, the devices should be listed in Device inventory . Now that your devices are synchronized, after their successful connection to the Coiote DM platform, you should be able to see the updated device twin properties in Azure IoT Hub. Tip If the device twin parameters are not up-to-date after syncing, try the refresh data model action on the device. Next steps #","title":"Importing devices to Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html#importing-devices-to-coiote-dm","text":"If you would like to migrate any device entities from your Azure IoT to the Coiote DM platform for full management possibilities, follow the instruction below.","title":"Importing devices to Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html#prerequisites","text":"Configured and working Azure IoT Hub integration extension (see Configuring the Azure IoT Hub integration extension for details).","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html#add-devices-to-azure-iot-hub","text":"If you don't have any device entities added in your Azure IoT Hub, follow these steps to learn how to do it: In your Azure IoT Hub account, under Explorers , select IoT devices . In the panel, click +New . Provide device ID in the relevant field and click Save . Your added devices should be visible in IoT devices under Explorers :","title":"Add devices to Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html#sync-your-devices","text":"In order to establish communication and data flow between device entities in Azure IoT Hub and their Coiote DM counterparts, you need to sync them. Go to Device inventory , click the Sync with IoT platform button and select Azure IoT Hub . In the pop-up window: provide the WHERE clause of the device twin SQL query to filter your devices using chosen tags and properties (to read more about SQL query, check the IoT Hub query language section of Azure IoT Hub documentation. For instance, you can filter by device location region and device status with the following clause: tags.location.region = 'US' AND status = 'enabled' click Count queried devices to check the number of devices that meet the specified conditions (the number is shown inside the Sync devices button) to skip filtering and synchronize all the available devices, leave the WHERE clause input field empty. click Sync devices to start the synchronization. After successful import, the devices should be listed in Device inventory . Now that your devices are synchronized, after their successful connection to the Coiote DM platform, you should be able to see the updated device twin properties in Azure IoT Hub. Tip If the device twin parameters are not up-to-date after syncing, try the refresh data model action on the device.","title":"Sync your devices"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html#next-steps","text":"","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Overview.html","text":"Overview # How synchronization works # Coiote DM provides zero-touch provisioning for synchronized devices from Azure IoT Hub. This means that device entities are automatically created within Coiote DM upon synchronization with the Azure IoT Hub and this is repeated periodically for any new devices that appear. Therefore, after one successful synchronization, you can be sure that any devices that have been added to Azure IoT Hub at a later time will also be migrated to Coiote DM.","title":"Overview"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Overview.html#overview","text":"","title":"Overview"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Overview.html#how-synchronization-works","text":"Coiote DM provides zero-touch provisioning for synchronized devices from Azure IoT Hub. This means that device entities are automatically created within Coiote DM upon synchronization with the Azure IoT Hub and this is repeated periodically for any new devices that appear. Therefore, after one successful synchronization, you can be sure that any devices that have been added to Azure IoT Hub at a later time will also be migrated to Coiote DM.","title":"How synchronization works"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html","text":"Upgrading device firmware # If you would like to upgrade the firmware of devices using the Azure IoT Hub, follow the instruction below. Prerequisites # At least one device with active Coiote DM - Azure IoT Hub synchronization . A firmware file hosted on an HTTP server that is reachable by the Coiote DM server. Note In this stage of integration, no authentication method is supported for this endpoint - it is required that the firmware is publicly available (or hosted in a private network but with access granted for the Coiote DM server). Scheduling a firmware upgrade # Introduction # The process of upgrading device firmware for Azure IoT Hub devices synchronized with Coiote DM is based on two main elements: the Azure Direct Method mechanism and the Coiote DM Firmware Upgrade task. In the process, the Azure scheduleFirmwareUpdate direct method is invoked, enabling the Coiote DM to download the specified firmware file and add it to its resources. Then, an XML task is scheduled in Coiote DM and the upgrade is performed on the device. Info For firmware file recognition in Coiote, global identifiers are used. This means that it is recommended to name your firmware files using the format: yourdomainName + randomized value. If the same firmware file name is used again, then Coiote DM will be able to utilize the once downloaded resource without the need to download it again. Step 1: Invoking the Azure scheduleFirmwareUpdate direct method # To initiate the firmware upgrade procedure for your device: Go to your Azure hub account and under Explorers , select IoT devices . From the list, choose the device for which you want to upgrade the firmware. In the device view, select the Direct Method tab. Provide data for the following fields: Method Name - paste the scheduleFirmwareUpdate direct method name here. Payload - use the following payload with firmware upgrade parameters (remember to replace the example values where needed): { \"name\": \"anjay-firmware\", \"firmwareUrl\": \"https://example.repository.com/artifactory/gitlfs/demo.fw-pkg\", // optional - default=\"1200s\", any valid duration in format \"<length><unit>\" \"timeout\": \"1200s\", // optional - default=\"COAP\" \"protocolType\": \"COAP\", // optional - default=null <-> keep firmware file forever, any valid duration in format \"<length><unit>\" or null \"retentionPeriod\": \"300s\", // optional - default=\"\" \"description\": \"This is anjay demo firmware\", // optional - default=false \"useQuota\": false, // optional - default=false \"useCachedData\": false, // optional - default=false \"resumeAfterDownlinkFailure\": false, // optional - default=\"pull\", possible values = [\"pull\", \"push\"] \"imageDeliveryMethod\": \"pull\", // optional - default=\"WithoutObservations\", possible values = [\"ObservationTrigger\", \"WithoutObservations\", \"ObservationBased\", \"SendBased\"] \"upgradeStrategy\": \"WithoutObservations\", // optional - default=\"always\", possible values = [\"always\", \"weekends\", \"nights-home\", \"nights-enterprise-weekends\", \"nights-enterprise\", user-defined schedules] \"schedule\": \"always\" } Connection timeout - specify a timeout for the Azure - Coiote DM connection (the recommended value is not less than 5 seconds). Method timeout - specify a timeout for direct method result notification. Once you have provided the required data, click Invoke method . After a short moment, you should be able to see the direct method result in the Result field. The 200 as the \"status\" parameter value means that the firmware upgrade task was completed successfully. Importantly, the result \"payload\" value will be needed for other FOTA actions like status check or cancellation, so be sure to copy it to your clipboard if needed. Tip Out of all the parameters provided in Firmware upgrade direct method payload, only two are mandatory: name - the unique file name used for firmware identification. firmwareUrl - the URL used by Coiote DM to download the firmware file and include it as a resource. Therefore it is correct to include only those two in the payload, as in here: { \"name\": \"anjay-firmware\", \"firmwareUrl\": \"https://example.repository.com/artifactory/gitlfs/demo.fw-pkg\", } Step 2: Checking the firmware upgrade result # To check the status of a scheduled firmware upgrade, follow these steps: In the Direct Method tab of your device, provide data for the following fields: Method Name - paste the checkFirmwareUpdateStatus direct method name here. Payload - use the payload displayed in the Firmware upgrade result field (remember to replace the placeholder value with your copied value): { \"fotaId\": \"fotaIdReturnedByScheduleOperation\" } Click Invoke method . Check the direct method status in the Result field: Step 3: Checking Coiote DM FOTA task execution # Once you have executed the Azure-side steps of the procedure, you can check its status from the side of Coiote DM. Go to your Coiote DM account and in the Device Inventory , select your device. In the Device Management Center, enter the LwM2M firmware tab. Check the status of the FOTA task execution for your device: In the Current firmware section, check if the device firmware is updated to the newest version. In the Installation history section, check if the lwm2mFirmwareUpdate task invoked earlier by the Azure scheduleFirmwareUpdate direct method has been completed with success. Cancelling the firmware upgrade procedure # To cancel the firmware upgrade procedure, follow these steps: In the Direct Method tab of your device, provide data for the following fields: Method Name - paste the cancelFirmwareUpdate direct method name here. Payload - use the payload displayed in the Firmware upgrade result field (remember to replace the placeholder value with your copied value): { \"fotaId\": \"fotaIdReturnedByScheduleOperation\" } Click Invoke method . Check the direct method status in the Result field: See also # See the relevant section of LwM2M mappings to learn the details of how Azure IoT Hub Direct Methods are mapped in Coiote DM.","title":"Upgrading device firmware"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#upgrading-device-firmware","text":"If you would like to upgrade the firmware of devices using the Azure IoT Hub, follow the instruction below.","title":"Upgrading device firmware"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#prerequisites","text":"At least one device with active Coiote DM - Azure IoT Hub synchronization . A firmware file hosted on an HTTP server that is reachable by the Coiote DM server. Note In this stage of integration, no authentication method is supported for this endpoint - it is required that the firmware is publicly available (or hosted in a private network but with access granted for the Coiote DM server).","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#scheduling-a-firmware-upgrade","text":"","title":"Scheduling a firmware upgrade"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#introduction","text":"The process of upgrading device firmware for Azure IoT Hub devices synchronized with Coiote DM is based on two main elements: the Azure Direct Method mechanism and the Coiote DM Firmware Upgrade task. In the process, the Azure scheduleFirmwareUpdate direct method is invoked, enabling the Coiote DM to download the specified firmware file and add it to its resources. Then, an XML task is scheduled in Coiote DM and the upgrade is performed on the device. Info For firmware file recognition in Coiote, global identifiers are used. This means that it is recommended to name your firmware files using the format: yourdomainName + randomized value. If the same firmware file name is used again, then Coiote DM will be able to utilize the once downloaded resource without the need to download it again.","title":"Introduction"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#step-1-invoking-the-azure-schedulefirmwareupdate-direct-method","text":"To initiate the firmware upgrade procedure for your device: Go to your Azure hub account and under Explorers , select IoT devices . From the list, choose the device for which you want to upgrade the firmware. In the device view, select the Direct Method tab. Provide data for the following fields: Method Name - paste the scheduleFirmwareUpdate direct method name here. Payload - use the following payload with firmware upgrade parameters (remember to replace the example values where needed): { \"name\": \"anjay-firmware\", \"firmwareUrl\": \"https://example.repository.com/artifactory/gitlfs/demo.fw-pkg\", // optional - default=\"1200s\", any valid duration in format \"<length><unit>\" \"timeout\": \"1200s\", // optional - default=\"COAP\" \"protocolType\": \"COAP\", // optional - default=null <-> keep firmware file forever, any valid duration in format \"<length><unit>\" or null \"retentionPeriod\": \"300s\", // optional - default=\"\" \"description\": \"This is anjay demo firmware\", // optional - default=false \"useQuota\": false, // optional - default=false \"useCachedData\": false, // optional - default=false \"resumeAfterDownlinkFailure\": false, // optional - default=\"pull\", possible values = [\"pull\", \"push\"] \"imageDeliveryMethod\": \"pull\", // optional - default=\"WithoutObservations\", possible values = [\"ObservationTrigger\", \"WithoutObservations\", \"ObservationBased\", \"SendBased\"] \"upgradeStrategy\": \"WithoutObservations\", // optional - default=\"always\", possible values = [\"always\", \"weekends\", \"nights-home\", \"nights-enterprise-weekends\", \"nights-enterprise\", user-defined schedules] \"schedule\": \"always\" } Connection timeout - specify a timeout for the Azure - Coiote DM connection (the recommended value is not less than 5 seconds). Method timeout - specify a timeout for direct method result notification. Once you have provided the required data, click Invoke method . After a short moment, you should be able to see the direct method result in the Result field. The 200 as the \"status\" parameter value means that the firmware upgrade task was completed successfully. Importantly, the result \"payload\" value will be needed for other FOTA actions like status check or cancellation, so be sure to copy it to your clipboard if needed. Tip Out of all the parameters provided in Firmware upgrade direct method payload, only two are mandatory: name - the unique file name used for firmware identification. firmwareUrl - the URL used by Coiote DM to download the firmware file and include it as a resource. Therefore it is correct to include only those two in the payload, as in here: { \"name\": \"anjay-firmware\", \"firmwareUrl\": \"https://example.repository.com/artifactory/gitlfs/demo.fw-pkg\", }","title":"Step 1: Invoking the Azure scheduleFirmwareUpdate direct method"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#step-2-checking-the-firmware-upgrade-result","text":"To check the status of a scheduled firmware upgrade, follow these steps: In the Direct Method tab of your device, provide data for the following fields: Method Name - paste the checkFirmwareUpdateStatus direct method name here. Payload - use the payload displayed in the Firmware upgrade result field (remember to replace the placeholder value with your copied value): { \"fotaId\": \"fotaIdReturnedByScheduleOperation\" } Click Invoke method . Check the direct method status in the Result field:","title":"Step 2: Checking the firmware upgrade result"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#step-3-checking-coiote-dm-fota-task-execution","text":"Once you have executed the Azure-side steps of the procedure, you can check its status from the side of Coiote DM. Go to your Coiote DM account and in the Device Inventory , select your device. In the Device Management Center, enter the LwM2M firmware tab. Check the status of the FOTA task execution for your device: In the Current firmware section, check if the device firmware is updated to the newest version. In the Installation history section, check if the lwm2mFirmwareUpdate task invoked earlier by the Azure scheduleFirmwareUpdate direct method has been completed with success.","title":"Step 3: Checking Coiote DM FOTA task execution"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#cancelling-the-firmware-upgrade-procedure","text":"To cancel the firmware upgrade procedure, follow these steps: In the Direct Method tab of your device, provide data for the following fields: Method Name - paste the cancelFirmwareUpdate direct method name here. Payload - use the payload displayed in the Firmware upgrade result field (remember to replace the placeholder value with your copied value): { \"fotaId\": \"fotaIdReturnedByScheduleOperation\" } Click Invoke method . Check the direct method status in the Result field:","title":"Cancelling the firmware upgrade procedure"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#see-also","text":"See the relevant section of LwM2M mappings to learn the details of how Azure IoT Hub Direct Methods are mapped in Coiote DM.","title":"See also"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html","text":"LwM2M mappings # In this section you'll get to know how the mappings are arranged between the LwM2M protocol as used in Coiote DM and the data retrieval and processing mechanisms of the Azure IoT Hub, such as Device Twins, Direct Method and Device-to-cloud messaging. Introduction # The LwM2M protocol data model is organized as a three-level tree that has the following structure: object (e.g. a 'temperature sensor') object instance (e.g. 'temperature sensor #1', 'temperature sensor #2' etc.) resource (e.g. 'current temperature value') In terms of operations that can be performed on an LwM2M Client, an LwM2M Server can READ all of the data model entities, and, depending on their characteristics, may also WRITE to some of them, and EXECUTE some of them. Additionally, an LwM2M Server can also OBSERVE selected resources. Info If you would like to dive deeper into the details of the Lightweight M2M protocol, please refer to our brief introduction to LwM2M . This division into readable, writable, executable and observable data model entities is the basis for the mapping of LwM2M resources (as interpreted by Coiote DM) into Azure IoT Hub data processing mechanisms. LwM2M readable and writable resources # Within the Coiote DM - Azure IoT Hub integration, readable and writable resources are usually interpreted as part of Azure Device twin data structure. Note To learn more about Device twins, go to the Understand and use Device twins section of the Azure IoT Hub documentation. For instance, the sample JSON snippet below is a tree with nested resources to represent a fragment of the LwM2M data model with path /3/1/1 : { \"deviceId\": \"airquality-0\", ... \"properties\": { \"reported\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 90 }, \"4\": {}, \"6\": {}, \"7\": {}, \"8\": {} } }, \"3\": { \"1\": { \"1\": { \"value\": \"airquality-0-Valparaiso\" } } }, ... READ - Communication flow # Data model resources that are read-only, such as Manufacturer (with ID 3/0/0 ) will be mapped into the Device twin as a reported property. WRITE - Communication flow # On the other hand, a writable resource, such as Lifetime (with ID 1/0/1 ), apart from being represented as a reported property, can be additionally mapped as a desired property. This enables you to synchronize the device data model and configuration between Azure and Coiote DM. Changing the value of a writable resource involves creating a properly formatted JSON snippet in the desired property field within the Device twin that introduces a value change: ... \"properties\": { \"desired\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 30 } } } }, ... After JSON is saved, Azure notifies Coiote DM of the desired change which is then transferred to the device in form of a WRITE command. Once the value is changed on the device, Coiote DM reports back to Azure that the value of the corresponding reported property should be updated in the Device twin JSON structure. LwM2M executable resources # As a rule, LwM2M resources that can be executable translate into Direct methods in Azure IoT Hub. This means that by invoking a direct method from Azure, you can trigger an EXECUTE operation on a chosen resource available for your device and the request will be transferred immediately by the LwM2M Server to the device. Note To learn more about Direct methods, go to the Understand Direct methods section of the Azure IoT Hub documentation. An executable LwM2M resource ID is mapped to a direct method in the following way: method name: execute { path: \"object.objectInstance.resource\", [args: \"optional arguments to execute\"] } Thus, for instance, to execute a factory reset on a device, you need to invoke a direct method with the execute name and the following payload: { path: \"3.0.5\" } EXECUTE - Communication flow # Invoking a direct method from Azure IoT Hub and handling it by Coiote DM in the form of an EXECUTE operation passed to the device has the following flow: LwM2M observable resources # In Coiote DM, some of the resources within the device data model can be observed for changes in value. These are generally resources related to telemetry data or other measurements. Their value changes can be monitored by Coiote DM and reported to the Azure IoT Hub Device-to-cloud mechanism. Note To learn more about the Azure Device-to-cloud, go to sending device-to-cloud messages section of the Azure IoT Hub documentation. Observe - Communication flow # Setting an Observe operation on a resource in Coiote DM, for instance a temperature reading, will result in a Notify message sent by the device upon value change that Coiote DM will transfer to the Device-to-cloud mechanism of Azure IoT Hub. What is more, you can set observations on LwM2M resources from the Azure IoT Hub level by adding appropriate attributes to the resource as a Device twin desired property. For instance, an Observe operation on resource ID 3303/1/5700 is set in the following way: ... \"properties\": { \"desired\": { \"lwm2m\": { \"3303\": { \"1\": { \"5700\": { \"observed\": true, \"attributes\": { \"pmin\": 60 } } } } } ... After JSON is saved, Azure notifies Coiote DM of the desired attribute setting which is then transferred to the device in form of an Observe operation. Once Coiote DM is notified of a value change, it is reported to the Azure Device-to-cloud mechanism.","title":"LwM2M mappings"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#lwm2m-mappings","text":"In this section you'll get to know how the mappings are arranged between the LwM2M protocol as used in Coiote DM and the data retrieval and processing mechanisms of the Azure IoT Hub, such as Device Twins, Direct Method and Device-to-cloud messaging.","title":"LwM2M mappings"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#introduction","text":"The LwM2M protocol data model is organized as a three-level tree that has the following structure: object (e.g. a 'temperature sensor') object instance (e.g. 'temperature sensor #1', 'temperature sensor #2' etc.) resource (e.g. 'current temperature value') In terms of operations that can be performed on an LwM2M Client, an LwM2M Server can READ all of the data model entities, and, depending on their characteristics, may also WRITE to some of them, and EXECUTE some of them. Additionally, an LwM2M Server can also OBSERVE selected resources. Info If you would like to dive deeper into the details of the Lightweight M2M protocol, please refer to our brief introduction to LwM2M . This division into readable, writable, executable and observable data model entities is the basis for the mapping of LwM2M resources (as interpreted by Coiote DM) into Azure IoT Hub data processing mechanisms.","title":"Introduction"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#lwm2m-readable-and-writable-resources","text":"Within the Coiote DM - Azure IoT Hub integration, readable and writable resources are usually interpreted as part of Azure Device twin data structure. Note To learn more about Device twins, go to the Understand and use Device twins section of the Azure IoT Hub documentation. For instance, the sample JSON snippet below is a tree with nested resources to represent a fragment of the LwM2M data model with path /3/1/1 : { \"deviceId\": \"airquality-0\", ... \"properties\": { \"reported\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 90 }, \"4\": {}, \"6\": {}, \"7\": {}, \"8\": {} } }, \"3\": { \"1\": { \"1\": { \"value\": \"airquality-0-Valparaiso\" } } }, ...","title":"LwM2M readable and writable resources"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#read-communication-flow","text":"Data model resources that are read-only, such as Manufacturer (with ID 3/0/0 ) will be mapped into the Device twin as a reported property.","title":"READ - Communication flow"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#write-communication-flow","text":"On the other hand, a writable resource, such as Lifetime (with ID 1/0/1 ), apart from being represented as a reported property, can be additionally mapped as a desired property. This enables you to synchronize the device data model and configuration between Azure and Coiote DM. Changing the value of a writable resource involves creating a properly formatted JSON snippet in the desired property field within the Device twin that introduces a value change: ... \"properties\": { \"desired\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 30 } } } }, ... After JSON is saved, Azure notifies Coiote DM of the desired change which is then transferred to the device in form of a WRITE command. Once the value is changed on the device, Coiote DM reports back to Azure that the value of the corresponding reported property should be updated in the Device twin JSON structure.","title":"WRITE - Communication flow"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#lwm2m-executable-resources","text":"As a rule, LwM2M resources that can be executable translate into Direct methods in Azure IoT Hub. This means that by invoking a direct method from Azure, you can trigger an EXECUTE operation on a chosen resource available for your device and the request will be transferred immediately by the LwM2M Server to the device. Note To learn more about Direct methods, go to the Understand Direct methods section of the Azure IoT Hub documentation. An executable LwM2M resource ID is mapped to a direct method in the following way: method name: execute { path: \"object.objectInstance.resource\", [args: \"optional arguments to execute\"] } Thus, for instance, to execute a factory reset on a device, you need to invoke a direct method with the execute name and the following payload: { path: \"3.0.5\" }","title":"LwM2M executable resources"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#execute-communication-flow","text":"Invoking a direct method from Azure IoT Hub and handling it by Coiote DM in the form of an EXECUTE operation passed to the device has the following flow:","title":"EXECUTE - Communication flow"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#lwm2m-observable-resources","text":"In Coiote DM, some of the resources within the device data model can be observed for changes in value. These are generally resources related to telemetry data or other measurements. Their value changes can be monitored by Coiote DM and reported to the Azure IoT Hub Device-to-cloud mechanism. Note To learn more about the Azure Device-to-cloud, go to sending device-to-cloud messages section of the Azure IoT Hub documentation.","title":"LwM2M observable resources"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#observe-communication-flow","text":"Setting an Observe operation on a resource in Coiote DM, for instance a temperature reading, will result in a Notify message sent by the device upon value change that Coiote DM will transfer to the Device-to-cloud mechanism of Azure IoT Hub. What is more, you can set observations on LwM2M resources from the Azure IoT Hub level by adding appropriate attributes to the resource as a Device twin desired property. For instance, an Observe operation on resource ID 3303/1/5700 is set in the following way: ... \"properties\": { \"desired\": { \"lwm2m\": { \"3303\": { \"1\": { \"5700\": { \"observed\": true, \"attributes\": { \"pmin\": 60 } } } } } ... After JSON is saved, Azure notifies Coiote DM of the desired attribute setting which is then transferred to the device in form of an Observe operation. Once Coiote DM is notified of a value change, it is reported to the Azure Device-to-cloud mechanism.","title":"Observe - Communication flow"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html","text":"Air quality monitoring - tutorial # The Coiote DM and Azure IoT Hub integration lets you create custom use cases with data visualization. See the video and have a sneak peek at the possibilities that the Coiote DM - Azure IoT Hub integration offers you. In the tutorial, you will see how to leverage the integration to create an air quality monitoring in just a few steps. The text version of the tutorial, complete with the necessary steps and code snippets, is available below: Prerequisites # An active Azure subscription. An active Coiote DM account. Please refer to Coiote DM home page for details on how to get it. An active Microsoft Power BI account. An OpenWeatherMap account with a free API token. An active and configured Azure CLI - please refer to the Azure CLI installation guide for details. Creating and configuring an Azure IoT hub and storage account # First you need to add a new IoT hub and a storage account in Azure. Here's how to do it: Creating an IoT hub # In your Azure portal home view, go to IoT Hub and select Add . In the Basics tab: select your subscription and resource group, pick your region, provide a name for your IoT hub. In the Management tab: in Pricing and scale tier select, optionally, turn off Defender for IoT . In the Review + create tab, click Create . Creating a storage account # While your new IoT hub is deploying, you can add a new storage account: In the Azure portal, go to Storage accounts and select Add . In the Basics tab: select your subscription and resource group, provide a name for your storage account, pick your location. In the Review + create tab, click Create . Configuring the Azure IoT Hub integration extension # Once the deployments are complete, go to Coiote DM to set up the Azure IoT Hub extension. If you haven't done this yet, please follow the instruction for the Azure IoT Hub integration configuration . Adding and connecting LwM2M air quality meter simulators to Coiote DM and Azure IoT Hub # Go to your Azure IoT Hub and add new devices: Under Explorers , select IoT Devices and click + New . Provide the name for your first device: air-quality-meter-example-0 . Click Save . Repeat the procedure for the other 5 devices (increase the number included in the device name). Go to Coiote DM and sync the previously added devices: In Device inventory , select Sync with IoT platform -> Azure IoT Hub . In the pop-up, click Sync devices . Devices should then be visible in Device inventory Go to your command line and register the device simulators: Paste and run the following command to create a container group: az container create -g coiote-dm-experiments --name air-quality-meter-example-0 --image avsystemcom/air-quality-meter-example --environment-variables DEVICEID=air-quality-meter-example-0 SERVER_ADDRESS=eu.iot.avsystem.cloud OPEN_WEATHER_API_TOKEN=exampletoken Note Remember to change the command parameters accordingly so that they are in line with your naming and credentials. once the command is executed, you should see a JSON payload that describes the content of the container instance. Go back to Coiote DM and in Device inventory , check if the devices have registered to the platform and if their data model has been updated. Click the Refresh data icon if needed. Click on a device and in the Device Management Center , select the Actions panel. Select the Refresh data model from device link and confirm by clicking Yes, execute task now . Go to the Objects panel to see if the data model for the device has been updated. You should be able to see objects such as 3 Device (along with the Model number resource which shows the name of the city of the temperature reading), 3303 Temperature , and 3428 Air quality . Bidirectional communication using Device Twin # From Coiote DM to Azure IoT Hub # In your Coiote DM account, go to Device inventory , select a device. In the Device Management Center , go to the Objects panel. In the 1 LwM2M Server object, find the Lifetime resource. Click the pen icon next to it, change the lifetime value and click the Apply link. Go to your Azure IoT hub, select IoT devices , click your device and select the Device Twin panel. Click Refresh and check in the JSON payload if the reported property for the 1/0/1 (Lifetime) resource has changed. From Azure IoT Hub to Coiote DM # Note To read more about how the Device Twins work in the Coiote DM - Azure IoT Hub integration, please refer to the LwM2M Mappings section . In your Azure IoT hub, select IoT devices , click one of your added devices and select the Device Twin panel. To change the Lifetime resource in Coiote DM, you need to modify the relevant Device Twin desired property. under the properties tag in the Device Twin JSON payload, paste the following nested structure: \"reported\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 45 } } } } }, - Click Save and Refresh . The value of the resource should now be changed in the Device Twin reported properties as well as in the Coiote DM Objects panel, in the Lifetime resource of the 1 LwM2M Server object. Passing telemetry to Azure IoT Hub # Setting group value tracking on resources in Coiote DM # In Coiote DM, go to Device inventory and use the search option to display your air quality meter devices. Then, click the Add to group icon. In the pop-up, click Add to new group , provide a name for your group (following the pattern root.iothubexample.airqualitymeter), click Confirm and Yes . Go to the Group management panel, select your group and click Devices to see if all of your devices are added to the group. Go to the Value tracking panel and click Add new . In the pop-up: Add value tracking for the Temperature resource: Provide the resource path: Temperature.1.Sensor Value . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Add value tracking for the Air quality PM10 resource: Provide the resource path: Air quality.1.PM10 . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Add value tracking for the Air quality PM2.5 resource: Provide the resource path: Air quality.1.PM2_5 . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Go back to Device inventory and select a device of your group. In the Dashboard view , you should be able to see the value tracking parameters as in the picture below: Configuring message routing for sending telemetry data in Azure IoT Hub # Go to your Azure IoT hub and add message routing: Under Messaging , select Message routing and click + Add . Provide a name for your event, for example EventRoute . From the Endpoint drop-down list, select events . In the Routing query , paste the following: IS_DEFINED($body.lwm2m.3303.1.5700.value) OR IS_DEFINED($body.lwm2m.3428.1.1.value) OR IS_DEFINED($body.lwm2m.3428.1.3.value) Click Save . While in the Message routing panel, go to the Enrich messages tab to set up location tracking: For latitude: Name - type lat Value - copy and paste $twin.properties.reported.lwm2m.6.1.0.value Endpoint(s) - select events For longitude: Name - type lon Value - copy and paste $twin.properties.reported.lwm2m.6.1.1.value Endpoint(s) - select events For longitude: Name - type deviceId Value - copy and paste $twin.properties.reported.lwm2m.3.1.1.value Endpoint(s) - select events Use search to go to Stream analytics jobs and create a job for transferring the gathered data to Power BI. Click + Add and provide the following: Job name - e.g. avsystem-iot-hub-to-powerbi . Resource group - pick your resource group. Click Create . Once your deployment is complete, click Go to resource . While in your Stream Analytics job panel, add a stream input and output and write a query: Under Job topology , select Inputs . From the + Add stream input drop-down list, select Iot Hub and provide the following: Input alias - e.g. avsystem-iot-hub-input . Consumer group - pick the $Default group. Click Save . Under Job topology , select Outputs . From the + Add drop-down list, select Power BI and click Authorize . Log in to Power BI using your Azure account. In the Power BI right-hand side panel, provide the following: Output alias - e.g. avsystem-iot-hub-output Dataset name - e.g. AVSystemIoTHubDataSet Table name - e.g. Data Click Save . Under Job topology , select Query . Paste the following query into the query input field (remember to adjust your naming inside the query if needed): SELECT CAST(lwm2m.\"3303.\"1\".\"5700\".value as float) as temperature, CAST(lwm2m.\"3428.\"1\".\"1\".value as float) as pm10, CAST(lwm2m.\"3428.\"1\".\"3\".value as float) as pm25, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User].[lat]') as lat, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User],[lon]') as lon, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User],[deviceId]') as deviceId2, EventProcessedUtcTime as processedTimestamp, IoTHub.EnqueuedTime as iotHubTimestamp, IoTHub.ConnectionDeviceId as deviceId INTO \"avsystem-iot-hub-output\" FROM \"avsystem-iot-hub-input\" Click Save query . In your Stream analytics job, go to Overview and click Start and confirm by clicking Start in the Start job window to run the created query. Data visualization using Power BI # Once the query is finished, you can go to Power BI to create a visualization for the data you have gathered. Go to https://powerbi.microsoft.com/ and sign in to your account. Go to My workspace and find your recently created dataset. Click the more options icon and select Create report From the Visualizations menu, select the table icon and drag and drop it to the work space. From the Fields menu, select the deviceId2 , temperature , pm10 and pm25 parameters. In the Values submenu, expand the drop-down list for the temperature , pm10 and pm25 parameters and select Average for each. Create a map with air quality indicators: From the Visualizations menu, click the get more visuals icon and select Get more visuals . Use search to find the Heatmap and click Add . From the Visualizations menu, click the Heatmap icon. Add the relevant parameters to the map data fields: To the Latitude data field, drag and drop the lat parameter from the Fields menu. To the Longitude data field, drag and drop the lon parameter from the Fields menu. To the Value data field, drag and drop the pm10 parameter from the Fields menu. In the Value data field, expand the drop-down list and select Average . To refresh the displayed data, click the Refresh button located in the upper navigation bar.","title":"Air quality monitoring - tutorial"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#air-quality-monitoring-tutorial","text":"The Coiote DM and Azure IoT Hub integration lets you create custom use cases with data visualization. See the video and have a sneak peek at the possibilities that the Coiote DM - Azure IoT Hub integration offers you. In the tutorial, you will see how to leverage the integration to create an air quality monitoring in just a few steps. The text version of the tutorial, complete with the necessary steps and code snippets, is available below:","title":"Air quality monitoring - tutorial"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#prerequisites","text":"An active Azure subscription. An active Coiote DM account. Please refer to Coiote DM home page for details on how to get it. An active Microsoft Power BI account. An OpenWeatherMap account with a free API token. An active and configured Azure CLI - please refer to the Azure CLI installation guide for details.","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#creating-and-configuring-an-azure-iot-hub-and-storage-account","text":"First you need to add a new IoT hub and a storage account in Azure. Here's how to do it:","title":"Creating and configuring an Azure IoT hub and storage account"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#creating-an-iot-hub","text":"In your Azure portal home view, go to IoT Hub and select Add . In the Basics tab: select your subscription and resource group, pick your region, provide a name for your IoT hub. In the Management tab: in Pricing and scale tier select, optionally, turn off Defender for IoT . In the Review + create tab, click Create .","title":"Creating an IoT hub"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#creating-a-storage-account","text":"While your new IoT hub is deploying, you can add a new storage account: In the Azure portal, go to Storage accounts and select Add . In the Basics tab: select your subscription and resource group, provide a name for your storage account, pick your location. In the Review + create tab, click Create .","title":"Creating a storage account"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#configuring-the-azure-iot-hub-integration-extension","text":"Once the deployments are complete, go to Coiote DM to set up the Azure IoT Hub extension. If you haven't done this yet, please follow the instruction for the Azure IoT Hub integration configuration .","title":"Configuring the Azure IoT Hub integration extension"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#adding-and-connecting-lwm2m-air-quality-meter-simulators-to-coiote-dm-and-azure-iot-hub","text":"Go to your Azure IoT Hub and add new devices: Under Explorers , select IoT Devices and click + New . Provide the name for your first device: air-quality-meter-example-0 . Click Save . Repeat the procedure for the other 5 devices (increase the number included in the device name). Go to Coiote DM and sync the previously added devices: In Device inventory , select Sync with IoT platform -> Azure IoT Hub . In the pop-up, click Sync devices . Devices should then be visible in Device inventory Go to your command line and register the device simulators: Paste and run the following command to create a container group: az container create -g coiote-dm-experiments --name air-quality-meter-example-0 --image avsystemcom/air-quality-meter-example --environment-variables DEVICEID=air-quality-meter-example-0 SERVER_ADDRESS=eu.iot.avsystem.cloud OPEN_WEATHER_API_TOKEN=exampletoken Note Remember to change the command parameters accordingly so that they are in line with your naming and credentials. once the command is executed, you should see a JSON payload that describes the content of the container instance. Go back to Coiote DM and in Device inventory , check if the devices have registered to the platform and if their data model has been updated. Click the Refresh data icon if needed. Click on a device and in the Device Management Center , select the Actions panel. Select the Refresh data model from device link and confirm by clicking Yes, execute task now . Go to the Objects panel to see if the data model for the device has been updated. You should be able to see objects such as 3 Device (along with the Model number resource which shows the name of the city of the temperature reading), 3303 Temperature , and 3428 Air quality .","title":"Adding and connecting LwM2M air quality meter simulators to Coiote DM and Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#bidirectional-communication-using-device-twin","text":"","title":"Bidirectional communication using Device Twin"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#from-coiote-dm-to-azure-iot-hub","text":"In your Coiote DM account, go to Device inventory , select a device. In the Device Management Center , go to the Objects panel. In the 1 LwM2M Server object, find the Lifetime resource. Click the pen icon next to it, change the lifetime value and click the Apply link. Go to your Azure IoT hub, select IoT devices , click your device and select the Device Twin panel. Click Refresh and check in the JSON payload if the reported property for the 1/0/1 (Lifetime) resource has changed.","title":"From Coiote DM to Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#from-azure-iot-hub-to-coiote-dm","text":"Note To read more about how the Device Twins work in the Coiote DM - Azure IoT Hub integration, please refer to the LwM2M Mappings section . In your Azure IoT hub, select IoT devices , click one of your added devices and select the Device Twin panel. To change the Lifetime resource in Coiote DM, you need to modify the relevant Device Twin desired property. under the properties tag in the Device Twin JSON payload, paste the following nested structure: \"reported\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 45 } } } } }, - Click Save and Refresh . The value of the resource should now be changed in the Device Twin reported properties as well as in the Coiote DM Objects panel, in the Lifetime resource of the 1 LwM2M Server object.","title":"From Azure IoT Hub to Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#passing-telemetry-to-azure-iot-hub","text":"","title":"Passing telemetry to Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#setting-group-value-tracking-on-resources-in-coiote-dm","text":"In Coiote DM, go to Device inventory and use the search option to display your air quality meter devices. Then, click the Add to group icon. In the pop-up, click Add to new group , provide a name for your group (following the pattern root.iothubexample.airqualitymeter), click Confirm and Yes . Go to the Group management panel, select your group and click Devices to see if all of your devices are added to the group. Go to the Value tracking panel and click Add new . In the pop-up: Add value tracking for the Temperature resource: Provide the resource path: Temperature.1.Sensor Value . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Add value tracking for the Air quality PM10 resource: Provide the resource path: Air quality.1.PM10 . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Add value tracking for the Air quality PM2.5 resource: Provide the resource path: Air quality.1.PM2_5 . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Go back to Device inventory and select a device of your group. In the Dashboard view , you should be able to see the value tracking parameters as in the picture below:","title":"Setting group value tracking on resources in Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#configuring-message-routing-for-sending-telemetry-data-in-azure-iot-hub","text":"Go to your Azure IoT hub and add message routing: Under Messaging , select Message routing and click + Add . Provide a name for your event, for example EventRoute . From the Endpoint drop-down list, select events . In the Routing query , paste the following: IS_DEFINED($body.lwm2m.3303.1.5700.value) OR IS_DEFINED($body.lwm2m.3428.1.1.value) OR IS_DEFINED($body.lwm2m.3428.1.3.value) Click Save . While in the Message routing panel, go to the Enrich messages tab to set up location tracking: For latitude: Name - type lat Value - copy and paste $twin.properties.reported.lwm2m.6.1.0.value Endpoint(s) - select events For longitude: Name - type lon Value - copy and paste $twin.properties.reported.lwm2m.6.1.1.value Endpoint(s) - select events For longitude: Name - type deviceId Value - copy and paste $twin.properties.reported.lwm2m.3.1.1.value Endpoint(s) - select events Use search to go to Stream analytics jobs and create a job for transferring the gathered data to Power BI. Click + Add and provide the following: Job name - e.g. avsystem-iot-hub-to-powerbi . Resource group - pick your resource group. Click Create . Once your deployment is complete, click Go to resource . While in your Stream Analytics job panel, add a stream input and output and write a query: Under Job topology , select Inputs . From the + Add stream input drop-down list, select Iot Hub and provide the following: Input alias - e.g. avsystem-iot-hub-input . Consumer group - pick the $Default group. Click Save . Under Job topology , select Outputs . From the + Add drop-down list, select Power BI and click Authorize . Log in to Power BI using your Azure account. In the Power BI right-hand side panel, provide the following: Output alias - e.g. avsystem-iot-hub-output Dataset name - e.g. AVSystemIoTHubDataSet Table name - e.g. Data Click Save . Under Job topology , select Query . Paste the following query into the query input field (remember to adjust your naming inside the query if needed): SELECT CAST(lwm2m.\"3303.\"1\".\"5700\".value as float) as temperature, CAST(lwm2m.\"3428.\"1\".\"1\".value as float) as pm10, CAST(lwm2m.\"3428.\"1\".\"3\".value as float) as pm25, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User].[lat]') as lat, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User],[lon]') as lon, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User],[deviceId]') as deviceId2, EventProcessedUtcTime as processedTimestamp, IoTHub.EnqueuedTime as iotHubTimestamp, IoTHub.ConnectionDeviceId as deviceId INTO \"avsystem-iot-hub-output\" FROM \"avsystem-iot-hub-input\" Click Save query . In your Stream analytics job, go to Overview and click Start and confirm by clicking Start in the Start job window to run the created query.","title":"Configuring message routing for sending telemetry data in Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#data-visualization-using-power-bi","text":"Once the query is finished, you can go to Power BI to create a visualization for the data you have gathered. Go to https://powerbi.microsoft.com/ and sign in to your account. Go to My workspace and find your recently created dataset. Click the more options icon and select Create report From the Visualizations menu, select the table icon and drag and drop it to the work space. From the Fields menu, select the deviceId2 , temperature , pm10 and pm25 parameters. In the Values submenu, expand the drop-down list for the temperature , pm10 and pm25 parameters and select Average for each. Create a map with air quality indicators: From the Visualizations menu, click the get more visuals icon and select Get more visuals . Use search to find the Heatmap and click Add . From the Visualizations menu, click the Heatmap icon. Add the relevant parameters to the map data fields: To the Latitude data field, drag and drop the lat parameter from the Fields menu. To the Longitude data field, drag and drop the lon parameter from the Fields menu. To the Value data field, drag and drop the pm10 parameter from the Fields menu. In the Value data field, expand the drop-down list and select Average . To refresh the displayed data, click the Refresh button located in the upper navigation bar.","title":"Data visualization using Power BI"},{"location":"Coiote_DM_Device_Onboarding/Device_onboarding.html","text":"Device onboarding # This guide will walk you through the process of adding new devices to Coiote DM. You will learn how to onboard devices using different scenarios: connection via the Management server, via the Bootstrap server, or running a simulated test device with the Anjay LwM2M Client. Prerequisites # An active Coiote DM user account with appropriate role assigned. A LwM2M device (except for the simulated test device scenario). An Anjay SDK repository (only for the simulated test device scenario). A configured Bootstrap server (only for the Bootstrap server scenario). Add a device via the Management server # To add a device using the Management server: From the navigation menu, select Device Inventory and click the Add device button. Note If you're a new user with no added devices, the Add your LwM2M device panel will be displayed upon logging in to the platform. Select the Connect your LwM2M device directly via the Management server tile. In the Device credentials step, provide the following: Device ID - enter the endpoint name of your LwM2M device. Friendly name (optional) - enter a name for your device that will help user identify it in the platform. Security mode: PSK - authorize your device using a pre-shared key. To use this option, provide the following: Key identity - define the name that the device will use during DTLS handshake. Can be equal with the LwM2M device endpoint name. Key - provide the shared secret used in the device-server authentication. Select the Key in hexadecimal check box to enable specifying the key in hexadecimal format. NoSec - use the device with no security established for the device-server communication. Using this mode is not recommended except for testing purposes. Certificate - secure your device-server communication with a certificate: Select Use a previously uploaded certificate if you have already uploaded a certificate to the platform using the DTLS/TLS Certificates panel. Select Upload a new certificate to load your certificate file using the Browse button. Click the Add device button and Confirm in the confirmation pop-up. Important At this stage, your device will be already visible in the platform. However, to get your device connected, you need to configure it using the credentials from the next step. In the Connect your device step, insert the given connection parameters into your device to start connection. Click Go to device to see your added device dashboard. Add a device via the Bootstrap server # To add a device using the Bootstrap server: From the navigation menu, select Device Inventory and click the Add device button. Note If you're a new user with no added devices, the Add your LwM2M device panel will be displayed upon logging in to the platform. Select the Connect your LwM2M device via the Bootstrap server tile. In the Device credentials step, provide the following: Device ID - enter the endpoint name of your LwM2M device. Friendly name (optional) - enter a name for your device that will help user identify it in the platform. Security mode: PSK - authorize your device using a pre-shared key. To use this option, provide the following: Key identity - define the name that the device will use during DTLS handshake. Can be equal with the LwM2M device endpoint name. Key - provide the shared secret used in the device-server authentication. Select the Key in hexadecimal check box to enable specifying the key in hexadecimal format. NoSec - use the device with no security established for the device-server communication. It is recommended to use this mode only for testing purposes. Certificate - secure your device-server communication with a certificate: Select Use a previously uploaded certificate if you have already uploaded a certificate to the platform using the DTLS/TLS Certificates panel. Select Upload a new certificate to load your certificate file using the Browse button. Click the Configuration button to go to the next step. In the Configuration step, select a Management server for your device from the drop-down list: Use the bootstrap configuration set as default for your domain - use this setting if you want to make use of the inherited bootstrap settings for your domain. This Coiote DM Management Server (Cert with EST) - use this setting if you have chosen the Certificate mode in the Device credentials step. This Coiote DM Management Server NoSec - use this setting to establish the device-server communication with no security. Using this mode is not recommended except for testing purposes. This Coiote DM Management Server PSK - use this setting to authorize the device-server communication using a pre-shared key. Your custom bootstrap setting - this type of setting will appear if you have configured a bootstrap server setting using the Bootstrap configuration panel. Click the Add device button and Confirm in the confirmation pop-up. Important At this stage, your device will be already visible in the platform. However, to get your device connected, you need to configure it using the credentials from the next step. In the Connect your device step, insert the given connection parameters into your device to start connection. Click Go to device to see your added device dashboard. Add a device using the Anjay LwM2M Client # To add a simulated device with the Anjay LwM2M Client: From the navigation menu, select Device Inventory and click the Add device button. Note If you're a new user with no added devices, the Add your LwM2M device panel will be displayed upon logging in to the platform. Select the Run your device using the Anjay LwM2M Client tile. Open a command line interface in your Anjay SDK repository folder and run the command displayed inside the command field. Click Go to device to see your added device dashboard.","title":"Device onboarding"},{"location":"Coiote_DM_Device_Onboarding/Device_onboarding.html#device-onboarding","text":"This guide will walk you through the process of adding new devices to Coiote DM. You will learn how to onboard devices using different scenarios: connection via the Management server, via the Bootstrap server, or running a simulated test device with the Anjay LwM2M Client.","title":"Device onboarding"},{"location":"Coiote_DM_Device_Onboarding/Device_onboarding.html#prerequisites","text":"An active Coiote DM user account with appropriate role assigned. A LwM2M device (except for the simulated test device scenario). An Anjay SDK repository (only for the simulated test device scenario). A configured Bootstrap server (only for the Bootstrap server scenario).","title":"Prerequisites"},{"location":"Coiote_DM_Device_Onboarding/Device_onboarding.html#add-a-device-via-the-management-server","text":"To add a device using the Management server: From the navigation menu, select Device Inventory and click the Add device button. Note If you're a new user with no added devices, the Add your LwM2M device panel will be displayed upon logging in to the platform. Select the Connect your LwM2M device directly via the Management server tile. In the Device credentials step, provide the following: Device ID - enter the endpoint name of your LwM2M device. Friendly name (optional) - enter a name for your device that will help user identify it in the platform. Security mode: PSK - authorize your device using a pre-shared key. To use this option, provide the following: Key identity - define the name that the device will use during DTLS handshake. Can be equal with the LwM2M device endpoint name. Key - provide the shared secret used in the device-server authentication. Select the Key in hexadecimal check box to enable specifying the key in hexadecimal format. NoSec - use the device with no security established for the device-server communication. Using this mode is not recommended except for testing purposes. Certificate - secure your device-server communication with a certificate: Select Use a previously uploaded certificate if you have already uploaded a certificate to the platform using the DTLS/TLS Certificates panel. Select Upload a new certificate to load your certificate file using the Browse button. Click the Add device button and Confirm in the confirmation pop-up. Important At this stage, your device will be already visible in the platform. However, to get your device connected, you need to configure it using the credentials from the next step. In the Connect your device step, insert the given connection parameters into your device to start connection. Click Go to device to see your added device dashboard.","title":"Add a device via the Management server"},{"location":"Coiote_DM_Device_Onboarding/Device_onboarding.html#add-a-device-via-the-bootstrap-server","text":"To add a device using the Bootstrap server: From the navigation menu, select Device Inventory and click the Add device button. Note If you're a new user with no added devices, the Add your LwM2M device panel will be displayed upon logging in to the platform. Select the Connect your LwM2M device via the Bootstrap server tile. In the Device credentials step, provide the following: Device ID - enter the endpoint name of your LwM2M device. Friendly name (optional) - enter a name for your device that will help user identify it in the platform. Security mode: PSK - authorize your device using a pre-shared key. To use this option, provide the following: Key identity - define the name that the device will use during DTLS handshake. Can be equal with the LwM2M device endpoint name. Key - provide the shared secret used in the device-server authentication. Select the Key in hexadecimal check box to enable specifying the key in hexadecimal format. NoSec - use the device with no security established for the device-server communication. It is recommended to use this mode only for testing purposes. Certificate - secure your device-server communication with a certificate: Select Use a previously uploaded certificate if you have already uploaded a certificate to the platform using the DTLS/TLS Certificates panel. Select Upload a new certificate to load your certificate file using the Browse button. Click the Configuration button to go to the next step. In the Configuration step, select a Management server for your device from the drop-down list: Use the bootstrap configuration set as default for your domain - use this setting if you want to make use of the inherited bootstrap settings for your domain. This Coiote DM Management Server (Cert with EST) - use this setting if you have chosen the Certificate mode in the Device credentials step. This Coiote DM Management Server NoSec - use this setting to establish the device-server communication with no security. Using this mode is not recommended except for testing purposes. This Coiote DM Management Server PSK - use this setting to authorize the device-server communication using a pre-shared key. Your custom bootstrap setting - this type of setting will appear if you have configured a bootstrap server setting using the Bootstrap configuration panel. Click the Add device button and Confirm in the confirmation pop-up. Important At this stage, your device will be already visible in the platform. However, to get your device connected, you need to configure it using the credentials from the next step. In the Connect your device step, insert the given connection parameters into your device to start connection. Click Go to device to see your added device dashboard.","title":"Add a device via the Bootstrap server"},{"location":"Coiote_DM_Device_Onboarding/Device_onboarding.html#add-a-device-using-the-anjay-lwm2m-client","text":"To add a simulated device with the Anjay LwM2M Client: From the navigation menu, select Device Inventory and click the Add device button. Note If you're a new user with no added devices, the Add your LwM2M device panel will be displayed upon logging in to the platform. Select the Run your device using the Anjay LwM2M Client tile. Open a command line interface in your Anjay SDK repository folder and run the command displayed inside the command field. Click Go to device to see your added device dashboard.","title":"Add a device using the Anjay LwM2M Client"},{"location":"Coiote_DM_Device_Onboarding/Quick_start.html","text":"Quick start # Learn how to onboard a LwM2M device in just a few clicks. Prerequisites # An active Coiote DM user account with appropriate role assigned. A LwM2M device (except for the simulated test device scenario). Onboard a device via the Management server with PSK security mode # Upon logging in to Coiote DM, you will see the Add your LwM2M device panel. Note If you have added a device already, the panel will not show. In this case, from the navigation menu, select Device Inventory and click the Add device button. Select the Connect your LwM2M device directly via the Management server tile. In the Device credentials step: In the Device ID enter your LwM2M device endpoint name, e.g. test_device . In the Security mode section, select the PSK mode: In the Key identity field, type test_device In the Key field, type the shared secret used in the device-server authentication. Click the Add device button and Confirm in the confirmation pop-up. In the Connect your device step, insert the given connection parameters into your device to start connection. Click Go to device to see your added device dashboard.","title":"Quick start"},{"location":"Coiote_DM_Device_Onboarding/Quick_start.html#quick-start","text":"Learn how to onboard a LwM2M device in just a few clicks.","title":"Quick start"},{"location":"Coiote_DM_Device_Onboarding/Quick_start.html#prerequisites","text":"An active Coiote DM user account with appropriate role assigned. A LwM2M device (except for the simulated test device scenario).","title":"Prerequisites"},{"location":"Coiote_DM_Device_Onboarding/Quick_start.html#onboard-a-device-via-the-management-server-with-psk-security-mode","text":"Upon logging in to Coiote DM, you will see the Add your LwM2M device panel. Note If you have added a device already, the panel will not show. In this case, from the navigation menu, select Device Inventory and click the Add device button. Select the Connect your LwM2M device directly via the Management server tile. In the Device credentials step: In the Device ID enter your LwM2M device endpoint name, e.g. test_device . In the Security mode section, select the PSK mode: In the Key identity field, type test_device In the Key field, type the shared secret used in the device-server authentication. Click the Add device button and Confirm in the confirmation pop-up. In the Connect your device step, insert the given connection parameters into your device to start connection. Click Go to device to see your added device dashboard.","title":"Onboard a device via the Management server with PSK security mode"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html","text":"Configuring test cases # Introduction # This chapter covers the configuration aspects of the interoperability tests. It explains how to list and view the configuration of test cases, and how to add, edit, delete, import, and export them. Note The configuration of test cases is device-independent, which means that all the configured test cases can be applied for all the devices that have registered to the platform. Interoperability tests configuration panel # In this section you will learn about the layout and main features of the Protocol tests configuration panel. To enter the panel, in the navigation menu, select Protocol tests configuration . Search \u2013 use it to search the test case list. Import \u2013 use it to import test cases. Add a new test case \u2013 use it to add a new test case to the list. 'Select all' checkbox \u2013 use it to select or deselect all test cases visible in the list. 'Delete selected' button \u2013 use it to delete selected test cases. 'Export selected' button - use it to export selected test cases. Test case list \u2013 it features all the test cases available for you at the moment, or all the test cases meeting the search criteria (if entered). Domain name \u2013 it shows the names of domains and subdomains to which your test cases belong. Export icon \u2013 use it to export a single test case. Trash bin icon \u2013 use it to delete a single test case. Listing test cases # The test cases appearing in the test cases panel are presented in the form of a searchable alphabetical list to ensure their convenient viewing and management. Read this section to learn how to use the search to list your test cases. Using the search # To search the list of configured test cases start typing your entry into the search field. The matching items will appear in the list. Tip Note that if you select a test case from the filtered list, and then erase your entry from the search field, the selection will be carried over to the complete list view. Similarly, if you use the select all checkbox in the full list view, and then filter the list using the search, the selection will be carried over to the filtered list view. Viewing test case configuration # Read this section to learn how to view the configuration of an individual test case: From the navigation menu, select Protocol tests configuration . In the list, find the test case you want to view and click on its name. In the action list, expand the action items by clicking the \u02c5 icon. To expand or collapse the complete action list, use the Expand all and Collapse all buttons. Optionally, you can use the Edit test case button to edit your test case or click the trash bin icon to delete it. Adding new test cases # Read this section to learn how to add a new test case. From the navigation menu, select Protocol tests configuration . Click the Add a new test case button in the top-right corner: Configure your test case: Enter your Test case name (this field is mandatory). Enter your Test case description (this field is optional). Select your Reference device (this field is optional). You can either: type the exact device name in the Reference device search field and hit \u2018Enter\u2019, click Select reference device and select your device from the pop-up list. If you cannot see your device in the list, start typing its name in the search field to get matching results. In the Action list , specify your actions: To add your first action item, choose its name from the drop-down list, or type its name in the Specify action field. Within the action, fill in the mandatory attributes field. To add another action item, use the Add action button and specify your next action. To change the order of actions within the test case, drag and drop the action item you want to move by using the drag icon. To copy an action item, click the copy icon (except for the Loop action). To delete an action item, click the trash bin icon. If your test case is ready and all the mandatory fields are filled, click Add a new test case . Note To learn more about individual test actions, see the Test case action description chapter. Editing test cases # Read this section to learn how to edit a test case. Note If you edit a test case that was executed before, the existing historical results for this test case will no longer be available. From the navigation menu, select Protocol tests configuration . From the list, choose the test case you want to edit and click on its name. Click the Edit test case button in the top-right corner. Edit your test case: Modify your Test case name (this field is mandatory). Modify your Test case description (this field is optional). Change or add your Reference device (this field is optional). You can either: type the exact device ID in the Reference device search field and hit Enter , click Select reference device and select your device from the pop-up list. If you cannot see your device in the list, start typing its name in the search field to get matching results. In the Action list, edit your actions: Edit an existing action item by changing its name, modifying its attributes. Add another action item using the Add action button. Change the order of actions within the test case by dragging and dropping the action item you want to move using the drag icon. Copy an action item by clicking on the copy icon (except for the Loop action). Delete an action item by clicking on the trash bin icon. If you are done editing your test case and all the mandatory fields remain filled, click Save changes . Deleting test cases # Read this section to learn how to delete test cases. To delete individual test cases: From the navigation menu, select Protocol tests configuration . From the list, choose the test case you want to delete. Click the trash bin icon located on the right of the test case entry. In the pop-up that appears, click Confirm . To delete multiple test cases: From the navigation menu, select Protocol tests configuration . From the test case list, choose the test case you want to delete and click the 'Delete selected' button. In the pop-up that appears, click Confirm . Importing test cases # Read this section to learn how to import test cases. From the navigation menu, select Protocol tests configuration . Select the Import button, choose your file from the pop-up window and click Open . Your imported test cases will appear in the list with the status New . Exporting test cases # Read this section to learn how to export test cases. From the navigation menu, select Protocol tests configuration . From the list, select the test case(s) you want to export: If you want to export a single test case, just select the test case and click on the export icon on the right of the test case line item. If you want to export a group of test cases, select all the test cases and click on the export icon appearing at the top of the list. The test case(s) will be downloaded in the .conf format. Tip Edit the exported test cases using Windows Notepad or other standard text editor.","title":"Configuring test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#configuring-test-cases","text":"","title":"Configuring test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#introduction","text":"This chapter covers the configuration aspects of the interoperability tests. It explains how to list and view the configuration of test cases, and how to add, edit, delete, import, and export them. Note The configuration of test cases is device-independent, which means that all the configured test cases can be applied for all the devices that have registered to the platform.","title":"Introduction"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#interoperability-tests-configuration-panel","text":"In this section you will learn about the layout and main features of the Protocol tests configuration panel. To enter the panel, in the navigation menu, select Protocol tests configuration . Search \u2013 use it to search the test case list. Import \u2013 use it to import test cases. Add a new test case \u2013 use it to add a new test case to the list. 'Select all' checkbox \u2013 use it to select or deselect all test cases visible in the list. 'Delete selected' button \u2013 use it to delete selected test cases. 'Export selected' button - use it to export selected test cases. Test case list \u2013 it features all the test cases available for you at the moment, or all the test cases meeting the search criteria (if entered). Domain name \u2013 it shows the names of domains and subdomains to which your test cases belong. Export icon \u2013 use it to export a single test case. Trash bin icon \u2013 use it to delete a single test case.","title":"Interoperability tests configuration panel"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#listing-test-cases","text":"The test cases appearing in the test cases panel are presented in the form of a searchable alphabetical list to ensure their convenient viewing and management. Read this section to learn how to use the search to list your test cases.","title":"Listing test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#using-the-search","text":"To search the list of configured test cases start typing your entry into the search field. The matching items will appear in the list. Tip Note that if you select a test case from the filtered list, and then erase your entry from the search field, the selection will be carried over to the complete list view. Similarly, if you use the select all checkbox in the full list view, and then filter the list using the search, the selection will be carried over to the filtered list view.","title":"Using the search"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#viewing-test-case-configuration","text":"Read this section to learn how to view the configuration of an individual test case: From the navigation menu, select Protocol tests configuration . In the list, find the test case you want to view and click on its name. In the action list, expand the action items by clicking the \u02c5 icon. To expand or collapse the complete action list, use the Expand all and Collapse all buttons. Optionally, you can use the Edit test case button to edit your test case or click the trash bin icon to delete it.","title":"Viewing test case configuration"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#adding-new-test-cases","text":"Read this section to learn how to add a new test case. From the navigation menu, select Protocol tests configuration . Click the Add a new test case button in the top-right corner: Configure your test case: Enter your Test case name (this field is mandatory). Enter your Test case description (this field is optional). Select your Reference device (this field is optional). You can either: type the exact device name in the Reference device search field and hit \u2018Enter\u2019, click Select reference device and select your device from the pop-up list. If you cannot see your device in the list, start typing its name in the search field to get matching results. In the Action list , specify your actions: To add your first action item, choose its name from the drop-down list, or type its name in the Specify action field. Within the action, fill in the mandatory attributes field. To add another action item, use the Add action button and specify your next action. To change the order of actions within the test case, drag and drop the action item you want to move by using the drag icon. To copy an action item, click the copy icon (except for the Loop action). To delete an action item, click the trash bin icon. If your test case is ready and all the mandatory fields are filled, click Add a new test case . Note To learn more about individual test actions, see the Test case action description chapter.","title":"Adding new test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#editing-test-cases","text":"Read this section to learn how to edit a test case. Note If you edit a test case that was executed before, the existing historical results for this test case will no longer be available. From the navigation menu, select Protocol tests configuration . From the list, choose the test case you want to edit and click on its name. Click the Edit test case button in the top-right corner. Edit your test case: Modify your Test case name (this field is mandatory). Modify your Test case description (this field is optional). Change or add your Reference device (this field is optional). You can either: type the exact device ID in the Reference device search field and hit Enter , click Select reference device and select your device from the pop-up list. If you cannot see your device in the list, start typing its name in the search field to get matching results. In the Action list, edit your actions: Edit an existing action item by changing its name, modifying its attributes. Add another action item using the Add action button. Change the order of actions within the test case by dragging and dropping the action item you want to move using the drag icon. Copy an action item by clicking on the copy icon (except for the Loop action). Delete an action item by clicking on the trash bin icon. If you are done editing your test case and all the mandatory fields remain filled, click Save changes .","title":"Editing test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#deleting-test-cases","text":"Read this section to learn how to delete test cases. To delete individual test cases: From the navigation menu, select Protocol tests configuration . From the list, choose the test case you want to delete. Click the trash bin icon located on the right of the test case entry. In the pop-up that appears, click Confirm . To delete multiple test cases: From the navigation menu, select Protocol tests configuration . From the test case list, choose the test case you want to delete and click the 'Delete selected' button. In the pop-up that appears, click Confirm .","title":"Deleting test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#importing-test-cases","text":"Read this section to learn how to import test cases. From the navigation menu, select Protocol tests configuration . Select the Import button, choose your file from the pop-up window and click Open . Your imported test cases will appear in the list with the status New .","title":"Importing test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#exporting-test-cases","text":"Read this section to learn how to export test cases. From the navigation menu, select Protocol tests configuration . From the list, select the test case(s) you want to export: If you want to export a single test case, just select the test case and click on the export icon on the right of the test case line item. If you want to export a group of test cases, select all the test cases and click on the export icon appearing at the top of the list. The test case(s) will be downloaded in the .conf format. Tip Edit the exported test cases using Windows Notepad or other standard text editor.","title":"Exporting test cases"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html","text":"Device data model and variables # Displaying device data model and running simple actions # Coiote DM gives you the possibility to view and perform actions on the data model of individual devices defined by the LwM2M protocol. This view is available under the Objects panel of your device. Read this chapter to learn how to use the panel. Search - use it to find a particular object. To find the object, type its name. If checked, the changes you make to device objects will be applied immediately. Otherwise, you will have to wait for the device to trigger action execution or use the Execute tasks button (for devices in non-queue mode). !!! note The Apply immediately option is only available for devices in non-queue mode. Use this button to add a new LwM2M object definition. Division into objects. The info icon - click it to see the object description. Managing instances: [A] - Use it to select another instance of an object if the object has instances. [B] - Use it to add a new instance if an object allows it. [C] - Use it to select another instance or remove it. Search - use it to find a particular resource. To find the resource, type its name. Use it to refresh data, track values (send an Observe task) and add additional attributes to a selected instance. Use it to refresh data, track values (send an Observe task) and add additional attributes to a selected object. The table with resources of an object instance. Note The icon displaying the status of execution is available after clicking on one of the action buttons located in the Actions column. If you click it, you will see additional information about execution. Execution status icon Use it to refresh the resource. Value tracking - use it to send an Observe task to the device and configure monitoring to collect data. Attributes - use it to edit resource attributes or add new ones. Use it to edit a value of a resource. Execute - use it to send an Execute task to the device. Click the icon next to the button to add additional parameters. Managing device variables # Use the Variables panel to add custom variables onto your device for the purpose of protocol tests and view the existing variables that the device has inherited. To enter the Variables panel, go to Device Management Center by clicking on a selected device name and choose the Variables tab. The Custom device variables list shows the variables that belong to this particular device. To add a variable, click on Add , provide its name and value, and click Save . Note that every custom variable that you add will have the VARIABLE_ prefix. To delete a previously added variable, click the Trash bin icon and click Save . The Inherited variables list shows only the variables that the device inherits from the groups of devices that is belongs to. The list is view-only. To add a variable to this list, go to Device Groups and, in the Profiles panel, add an entry with the name beginning with VARIABLE_ . Using variables in test case actions # To use device variables, enter the expression context by typing ${variable.<variableName>} while defining a test case action. Remember that each variable is treated as a string, therefore, to use it as a different data type, you will have to cast it to the appropriate type.\u2003 Using variables - example # Learn how to use device variables in Interoperability tests in a few steps: Use case: Testing the WRITE action on the LwM2M Server.1.Lifetime resource. Add the variable: In Device inventory , click on a selected device name to enter its Device Management Center . Select the Variables tab. Tip If the Variables tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Click on Add and provide the following: Name: lifetime120 . Value: 120 . Click Save . Create a test case and include the new variable in the appropriate format: To add a new test case, follow the steps in Creating your first test case section, but including the adjustments below: For example purposes, pick only the Write action. In the Parameter name field, type LwM2M Server.1.Lifetime (note that the path may vary slightly depending on your device data model). In the Value field, type ${variable.lifetime120.toInt} . Tip By default, the variable value is rendered as a string data type. To cast it to the integer data type, .toInt suffix is added to the created expression, as seen above. Run the created test case and check if the variable works correctly: To run the test case, follow the steps in Running the test case on device using the test case created in the previous step. After the test case is finished, check if the Lifetime resource value has changed on the device: Go to the Objects panel of your device and under the LwM2M Server object, look for the Lifetime resource value: If the value has changed accordingly, the variable can be now reused and populated to any other test cases.","title":"Device data model and variables"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html#device-data-model-and-variables","text":"","title":"Device data model and variables"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html#displaying-device-data-model-and-running-simple-actions","text":"Coiote DM gives you the possibility to view and perform actions on the data model of individual devices defined by the LwM2M protocol. This view is available under the Objects panel of your device. Read this chapter to learn how to use the panel. Search - use it to find a particular object. To find the object, type its name. If checked, the changes you make to device objects will be applied immediately. Otherwise, you will have to wait for the device to trigger action execution or use the Execute tasks button (for devices in non-queue mode). !!! note The Apply immediately option is only available for devices in non-queue mode. Use this button to add a new LwM2M object definition. Division into objects. The info icon - click it to see the object description. Managing instances: [A] - Use it to select another instance of an object if the object has instances. [B] - Use it to add a new instance if an object allows it. [C] - Use it to select another instance or remove it. Search - use it to find a particular resource. To find the resource, type its name. Use it to refresh data, track values (send an Observe task) and add additional attributes to a selected instance. Use it to refresh data, track values (send an Observe task) and add additional attributes to a selected object. The table with resources of an object instance. Note The icon displaying the status of execution is available after clicking on one of the action buttons located in the Actions column. If you click it, you will see additional information about execution. Execution status icon Use it to refresh the resource. Value tracking - use it to send an Observe task to the device and configure monitoring to collect data. Attributes - use it to edit resource attributes or add new ones. Use it to edit a value of a resource. Execute - use it to send an Execute task to the device. Click the icon next to the button to add additional parameters.","title":"Displaying device data model and running simple actions"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html#managing-device-variables","text":"Use the Variables panel to add custom variables onto your device for the purpose of protocol tests and view the existing variables that the device has inherited. To enter the Variables panel, go to Device Management Center by clicking on a selected device name and choose the Variables tab. The Custom device variables list shows the variables that belong to this particular device. To add a variable, click on Add , provide its name and value, and click Save . Note that every custom variable that you add will have the VARIABLE_ prefix. To delete a previously added variable, click the Trash bin icon and click Save . The Inherited variables list shows only the variables that the device inherits from the groups of devices that is belongs to. The list is view-only. To add a variable to this list, go to Device Groups and, in the Profiles panel, add an entry with the name beginning with VARIABLE_ .","title":"Managing device variables"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html#using-variables-in-test-case-actions","text":"To use device variables, enter the expression context by typing ${variable.<variableName>} while defining a test case action. Remember that each variable is treated as a string, therefore, to use it as a different data type, you will have to cast it to the appropriate type.","title":"Using variables in test case actions"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html#using-variables-example","text":"Learn how to use device variables in Interoperability tests in a few steps: Use case: Testing the WRITE action on the LwM2M Server.1.Lifetime resource. Add the variable: In Device inventory , click on a selected device name to enter its Device Management Center . Select the Variables tab. Tip If the Variables tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Click on Add and provide the following: Name: lifetime120 . Value: 120 . Click Save . Create a test case and include the new variable in the appropriate format: To add a new test case, follow the steps in Creating your first test case section, but including the adjustments below: For example purposes, pick only the Write action. In the Parameter name field, type LwM2M Server.1.Lifetime (note that the path may vary slightly depending on your device data model). In the Value field, type ${variable.lifetime120.toInt} . Tip By default, the variable value is rendered as a string data type. To cast it to the integer data type, .toInt suffix is added to the created expression, as seen above. Run the created test case and check if the variable works correctly: To run the test case, follow the steps in Running the test case on device using the test case created in the previous step. After the test case is finished, check if the Lifetime resource value has changed on the device: Go to the Objects panel of your device and under the LwM2M Server object, look for the Lifetime resource value: If the value has changed accordingly, the variable can be now reused and populated to any other test cases.","title":"Using variables - example"},{"location":"Interoperability_tests_guide/Getting_started.html","text":"Getting started # Start using the Interoperability tests feature right away. This short instruction will help you create your first test case, run it on a device and see the execution logs. Prerequisites # A device that is added and registered in the platform. Create your first test case # From the navigation menu on the left, select Protocol tests configuration . Click the Add a new test case button in the top-right corner. Configure your test case: Provide a name for your test case. Under the Action list , click the Add action button and select Write from the drop down list and provide data for the following fields: Parameter name : Device.0.Manufacturer , Expected value : Example_manufacturer , Expected response code : 4.05 MethodNotAllowed . Under the Action list , select Read from the drop down list and provide data for the following fields: Parameter name : LwM2M Server.1.Binding , Expected value : U , Expected response code : 2.05 Content . Select the Add a new test case button. Run the test case on device # In the Device inventory , select a currently registered device and enter its Device Management Center . In Device Management Center , select the Protocol tests tab. Note If the Protocol tests tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Tick the test case you have just created and click Run selected (1) . After a few moments, the execution should end and test case status changes from In progress to Success . Tip The Success status of a test case is a measure of the correctness of the device response against the expected test case parameters. Depending on the device and tester's needs, there may be test cases that are successful when the device responds with a Failure message (similarly to the example presented in this section). Check test execution details # To see test execution logs for your test case: While in the Protocol tests panel, find your test case and click on its name. Expand the Logs section using the ^ arrow icon to see execution details. 3. Use the Check logs button for each action inside the test case to see the highlighted results for this action.","title":"Getting started"},{"location":"Interoperability_tests_guide/Getting_started.html#getting-started","text":"Start using the Interoperability tests feature right away. This short instruction will help you create your first test case, run it on a device and see the execution logs.","title":"Getting started"},{"location":"Interoperability_tests_guide/Getting_started.html#prerequisites","text":"A device that is added and registered in the platform.","title":"Prerequisites"},{"location":"Interoperability_tests_guide/Getting_started.html#create-your-first-test-case","text":"From the navigation menu on the left, select Protocol tests configuration . Click the Add a new test case button in the top-right corner. Configure your test case: Provide a name for your test case. Under the Action list , click the Add action button and select Write from the drop down list and provide data for the following fields: Parameter name : Device.0.Manufacturer , Expected value : Example_manufacturer , Expected response code : 4.05 MethodNotAllowed . Under the Action list , select Read from the drop down list and provide data for the following fields: Parameter name : LwM2M Server.1.Binding , Expected value : U , Expected response code : 2.05 Content . Select the Add a new test case button.","title":"Create your first test case"},{"location":"Interoperability_tests_guide/Getting_started.html#run-the-test-case-on-device","text":"In the Device inventory , select a currently registered device and enter its Device Management Center . In Device Management Center , select the Protocol tests tab. Note If the Protocol tests tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Tick the test case you have just created and click Run selected (1) . After a few moments, the execution should end and test case status changes from In progress to Success . Tip The Success status of a test case is a measure of the correctness of the device response against the expected test case parameters. Depending on the device and tester's needs, there may be test cases that are successful when the device responds with a Failure message (similarly to the example presented in this section).","title":"Run the test case on device"},{"location":"Interoperability_tests_guide/Getting_started.html#check-test-execution-details","text":"To see test execution logs for your test case: While in the Protocol tests panel, find your test case and click on its name. Expand the Logs section using the ^ arrow icon to see execution details. 3. Use the Check logs button for each action inside the test case to see the highlighted results for this action.","title":"Check test execution details"},{"location":"Interoperability_tests_guide/Overview.html","text":"Overview # Interoperability tests are a comprehensive and convenient solution for the customization and performance of LwM2M protocol tests on LwM2M devices. Offered as part of the Coiote IoT Device Management platform, it enables you develop test cases from scratch to tailor them to your devices, or use the ready-made test cases (including scenarios described in OMA Enabler Test Specification for Lightweight M2M by OMA SpecWorks and scenarios created by AVSystem ). The following guide will walk you through the basic functionalities of the interoperability tests solution. You will learn how to configure, run and manage your test cases and get to know in detail each possible action that can be defined within a test case.","title":"Overview"},{"location":"Interoperability_tests_guide/Overview.html#overview","text":"Interoperability tests are a comprehensive and convenient solution for the customization and performance of LwM2M protocol tests on LwM2M devices. Offered as part of the Coiote IoT Device Management platform, it enables you develop test cases from scratch to tailor them to your devices, or use the ready-made test cases (including scenarios described in OMA Enabler Test Specification for Lightweight M2M by OMA SpecWorks and scenarios created by AVSystem ). The following guide will walk you through the basic functionalities of the interoperability tests solution. You will learn how to configure, run and manage your test cases and get to know in detail each possible action that can be defined within a test case.","title":"Overview"},{"location":"Interoperability_tests_guide/Running_test_cases.html","text":"Running test cases # If you have test cases configured in the platform, you can run them on your device using the Protocol tests panel. Read this chapter to learn how to display test case descriptions, start and stop test case execution and view test results and logs. Protocol tests panel description # The protocol tests panel is available in the Device Management Center individually for each device. To access it, select a device in Device Inventory to enter its Device Management Center and select Protocol tests from the menu on the left. Tip If the Protocol tests tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Read this section to learn about the main components that it comprises. Test case list \u2013 views all the test cases available for a given device. It is searchable and can be filtered. Info icon \u2013 hover over this icon to see test case description. 'Select all' checkbox \u2013 use this checkbox to select all items visible in the list. Note that if you filter or search the list, the previously made selection you will be kept nonetheless. In such case, the number of selected test cases visible in the Run selected button will be their total count, which may not correspond to the number of selections in your filtered list view. Status \u2013 use this field to filter your list view by test case execution status. Type - use this field to filter your list view by test case type ( Automated or Semi-manual ). Search \u2013 use this field to search among the listed test cases by their name. Start typing to get matching results. Show report - use this button to view a summary of tests commissioned for your devices along with test case success rate. To get the report in the CSV format, select the Download summary file button. 'Run selected (_)' button \u2013 use it to start the execution of previously selected tests. The number of tests to be run is shown in brackets. Displaying test case description # Read this section to learn how to display details of test cases. In Device Inventory , find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Select a test case and click on its name to enter the detailed view. Starting test cases # Read this section to learn how to start the execution of test cases on a device. In Device Inventory , find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Select the test cases you want to run and click Run selected (_) . Note Even if you leave the Protocol tests panel, tests once run will continue until all are finished or stopped. Stopping test cases # Read this section to learn how to stop the execution of test cases on a device. With the tests running, go to Device Inventory . Find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Click the Cancel all tests button located inside the footer bar. Test execution will be stopped. Note Tests completed before you hit the Cancel all tests button will display their execution status. Test case statuses and logs # Test case statuses # Test case statuses are labels attached to test cases that help to identify their state in each stage of their execution. There are eight available test case statuses: New \u2013 a test case that has been recently added and has not been scheduled nor executed. NotScheduled \u2013 a test case that has never been picked for execution. NotTested \u2013 a test case that has been picked for execution, but its execution has not started due to some error or test case execution interruption. Pending \u2013 a test case whose execution is pending. In progress \u2013 a test case whose execution is under way. Halted \u2013 a test case whose execution is under way. Warning \u2013 a test case that has finished with error(s). Success \u2013 a test case that has finished with success. Tip Statuses are available both for test cases after execution as well as for individual actions inside a test case. To view test results for individual actions, enter the finished test case and see the action list. Test case logs # Logs store detailed information on the test case execution and can be displayed after its completion. To display the logs for an individual test case, enter the test case and click Check logs or expand the Logs list. If there are many logs from a selected period of time, use Scroll to the bottom and Scroll to the top links to navigate. If a log entry is long, not all lines are displayed at once. To see more lines, click the Show \u2026 lines/characters more link. To display only particular logs and logs of a higher level, use Show from level list . To wrap words of logs, select the Word wrap checkbox. To format messages in a more readable way, select the Format messages checkbox. To see which messages were received (green color) and which were sent (blue color), select the Color messages checkbox. To download logs from a particular period of time matching with used filters, click the Download button.","title":"Running test cases"},{"location":"Interoperability_tests_guide/Running_test_cases.html#running-test-cases","text":"If you have test cases configured in the platform, you can run them on your device using the Protocol tests panel. Read this chapter to learn how to display test case descriptions, start and stop test case execution and view test results and logs.","title":"Running test cases"},{"location":"Interoperability_tests_guide/Running_test_cases.html#protocol-tests-panel-description","text":"The protocol tests panel is available in the Device Management Center individually for each device. To access it, select a device in Device Inventory to enter its Device Management Center and select Protocol tests from the menu on the left. Tip If the Protocol tests tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Read this section to learn about the main components that it comprises. Test case list \u2013 views all the test cases available for a given device. It is searchable and can be filtered. Info icon \u2013 hover over this icon to see test case description. 'Select all' checkbox \u2013 use this checkbox to select all items visible in the list. Note that if you filter or search the list, the previously made selection you will be kept nonetheless. In such case, the number of selected test cases visible in the Run selected button will be their total count, which may not correspond to the number of selections in your filtered list view. Status \u2013 use this field to filter your list view by test case execution status. Type - use this field to filter your list view by test case type ( Automated or Semi-manual ). Search \u2013 use this field to search among the listed test cases by their name. Start typing to get matching results. Show report - use this button to view a summary of tests commissioned for your devices along with test case success rate. To get the report in the CSV format, select the Download summary file button. 'Run selected (_)' button \u2013 use it to start the execution of previously selected tests. The number of tests to be run is shown in brackets.","title":"Protocol tests panel description"},{"location":"Interoperability_tests_guide/Running_test_cases.html#displaying-test-case-description","text":"Read this section to learn how to display details of test cases. In Device Inventory , find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Select a test case and click on its name to enter the detailed view.","title":"Displaying test case description"},{"location":"Interoperability_tests_guide/Running_test_cases.html#starting-test-cases","text":"Read this section to learn how to start the execution of test cases on a device. In Device Inventory , find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Select the test cases you want to run and click Run selected (_) . Note Even if you leave the Protocol tests panel, tests once run will continue until all are finished or stopped.","title":"Starting test cases"},{"location":"Interoperability_tests_guide/Running_test_cases.html#stopping-test-cases","text":"Read this section to learn how to stop the execution of test cases on a device. With the tests running, go to Device Inventory . Find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Click the Cancel all tests button located inside the footer bar. Test execution will be stopped. Note Tests completed before you hit the Cancel all tests button will display their execution status.","title":"Stopping test cases"},{"location":"Interoperability_tests_guide/Running_test_cases.html#test-case-statuses-and-logs","text":"","title":"Test case statuses and logs"},{"location":"Interoperability_tests_guide/Running_test_cases.html#test-case-statuses","text":"Test case statuses are labels attached to test cases that help to identify their state in each stage of their execution. There are eight available test case statuses: New \u2013 a test case that has been recently added and has not been scheduled nor executed. NotScheduled \u2013 a test case that has never been picked for execution. NotTested \u2013 a test case that has been picked for execution, but its execution has not started due to some error or test case execution interruption. Pending \u2013 a test case whose execution is pending. In progress \u2013 a test case whose execution is under way. Halted \u2013 a test case whose execution is under way. Warning \u2013 a test case that has finished with error(s). Success \u2013 a test case that has finished with success. Tip Statuses are available both for test cases after execution as well as for individual actions inside a test case. To view test results for individual actions, enter the finished test case and see the action list.","title":"Test case statuses"},{"location":"Interoperability_tests_guide/Running_test_cases.html#test-case-logs","text":"Logs store detailed information on the test case execution and can be displayed after its completion. To display the logs for an individual test case, enter the test case and click Check logs or expand the Logs list. If there are many logs from a selected period of time, use Scroll to the bottom and Scroll to the top links to navigate. If a log entry is long, not all lines are displayed at once. To see more lines, click the Show \u2026 lines/characters more link. To display only particular logs and logs of a higher level, use Show from level list . To wrap words of logs, select the Word wrap checkbox. To format messages in a more readable way, select the Format messages checkbox. To see which messages were received (green color) and which were sent (blue color), select the Color messages checkbox. To download logs from a particular period of time matching with used filters, click the Download button.","title":"Test case logs"},{"location":"Interoperability_tests_guide/Test_case_actions.html","text":"Test case actions # Introduction # Based on the LwM2M 1.0 standard protocol operations, Actions are steps that can be defined within a test case. While some are used for the communication between the Server and the LwM2M test device, others help to define the test case logic. Read this chapter to learn how to use Actions in the configuration of customizable interoperability test cases. Action attributes # All the available Actions are defined using a set of configurable attributes that you can specify while adding or editing a test case. The attributes available under each action are determined by the type of given Action. However, to set up a test case, not all attributes are mandatory. The general rule is that if you leave an optional attribute\u2019s field blank, the final test case result won\u2019t be affected in any way. Tip if you would like to make the test device ignore a particular attribute so that it doesn\u2019t answer to the server request, type None in the optional attribute\u2019s field. Description of Actions # Within the Server simulator test cases, the following Actions are available (with mandatory attributes written in bold): READ WRITE EXECUTE DISCOVER DELETE CREATE WRITE ATTRIBUTES CLEAR ATTRIBUTES OBSERVE CANCEL OBSERVE Firmware Update Wait Pause response Wait for uplink request Send paused response Start Notification recording Expect Notification Loop start READ # READ is used to access the value of an object, object instances, a resource and single resource instances. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter you want to read. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected value \u2013 if the value you enter here equals the value read from the device, the test will be passed. If left blank, the value will only show up in the test case log and it will have no impact on the test case result. Note that this READ attribute works only for Resources and Resource Instances. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. LwM2M: Requested content format \u2013 the content format of the device answer that you request for your read operation. If the device doesn\u2019t support the requested format, the test will fail. If left blank, the device can decide what content format to use; any format will be accepted. WRITE # WRITE is used to change the value of a Resource. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter for which you want to set a new value or overwrite the existing one. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Value \u2013 the value you enter here sets a new value or overwrites the existing one. If left blank, the existing value will be kept and the test will be passed. LwM2M: Content format \u2013 the content format in which you send the write request to the device. If the device doesn\u2019t support the specified format, the test will fail. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. EXECUTE # EXECUTE is used to initiate some action and can only be performed on individual Resources. If the device receives an EXECUTE for an Object Instance(s) or Resource Instance(s), it will return an error. You can define it using two attributes: Parameter name \u2013 the name of the data model parameter for which you will issue an execute. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Execute arguments \u2013 the execution arguments passed to the device expressed in Plain Text format. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. DISCOVER # DISCOVER is used to discover LwM2M Attributes attached to an Object, Object Instances, and Resources. You can define it using two attributes: Parameter name \u2013 the name of the data model parameter whose attributes you want to discover. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. DELETE # DELETE is used for the server to delete an Object Instance within the LwM2M Client. Note that an Object Instance to be deleted must be an Object Instance that is announced by the Client to the Server using the Register and Update operations of the Client Registration Interface. Object instance \u2013 the object instance that you want to delete. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0) or the numerical (e.g. 3.0) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. CREATE # CREATE is used by the Server simulator to create Object Instance(s) within the LwM2M Client. You can define the action using three parameters and a set of Object Instance-dependent values: Object ID or name \u2013 the Object that you want to create an Instance for. Note that it can be specified either using the full name in the string (e.g. \u2018Portfolio\u2019) or the numerical (e.g. \u201816\u2019) value of the parameter. LwM2M: Instance number \u2013 the number assigned to the Object Instance to be created. If left blank, the number will be chosen by the device. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Resources \u2013 click the Provide initial values button to view and specify the possible Resources and Resource Instances of the Object Instance to be created. Note that if the values marked as required are left blank, the action will fail for devices that correctly implement LwM2M. WRITE ATTRIBUTES # WRITE ATTRIBUTES is used to attach metadata containing parameters for Notifications to an Object, an Object Instance or a Resource. You can define it using seven attributes: Parameter name \u2013 the name of the data model parameter for which you will write attributes. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Minimum period \u2013 the minimum time in seconds that the device waits between two notifications. Maximum period \u2013 the minimum time in seconds that the device waits between two notifications. Value greater than \u2013 notifications will be sent only when the monitored value crosses the threshold you set here. However, please note that the interpretation of this parameter may differ depending on the specific LwM2M Client implementation. Value less than \u2013 notifications will be sent only when the monitored value crosses the threshold you set here. However, please note that the interpretation of this parameter may differ depending on the specific LwM2M Client implementation. Step \u2013 the minimum change value between two notifications. CLEAR ATTRIBUTES # CLEAR ATTRIBUTES is used to clear the metadata attached to an Object, an Object Instance or a Resource which contain parameters for Notifications. You can define it using seven attributes: Parameter name \u2013 the name of the data model parameter for which you will clear attributes. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Clear minimum period \u2013 if set to true, it clears the minimum time in seconds between two notifications. If set to false, the value is kept. Clear maximum period \u2013 if set to true, it clears the maximum time set between two notifications. If set to false, the value is kept. Clear value greater than \u2013 if set to true, it clears the threshold set for the monitored value. If set to false, the value is kept. Clear value less than \u2013 if set to true, it clears the threshold set for the monitored value. If set to false, the value is kept. Clear step \u2013 if set to true, it clears the minimum change value between two notifications. If set to false, the value is kept. OBSERVE # OBSERVE is used to initiate an observation request for changes of a specific Resource, Resources within an Object Instance or for all the Object Instances of an Object. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter whose value(s) you will observe. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Fail if already observed \u2013 if set to true, the test will fail in case there is an existing observation set on this parameter. In case there is no observation set, your observe request should be accepted and the test won\u2019t fail. If set to false, any existing observations will be cancelled and requested again by this one and the test will be passed. LwM2M: Content format \u2013 the content format in which you send the OBSERVE request to the device. If the device doesn\u2019t support the specified format, the test will fail. CANCEL OBSERVE # CANCEL OBSERVE is used to cancel an observation. You can define it using three attributes: Parameter name \u2013 the name of the data model parameter for which you will cancel an existing observation. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Cancel type \u2013 the mode in which the CANCEL OBSERVE will be sent to the device. o ACTIVE - CANCEL OBSERVE is sent to the device immediately. o PASSIVE - CoAP RESET is sent in response to the next notification message received from the device. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Firmware Update # Firmware Update is used to perform a firmware update operation on the test device. You can define it using five attributes: Firmware \u2013 the ID of the resource used as the firmware source. Update timeout \u2013 the time period in seconds within which the firmware update should be completed. In case the timeout is up and the update process has not finished, the action will fail. Delivery method \u2013 The protocol and transfer method used to deliver the firmware file to the device. Use notifications \u2013 if set to true, an OBSERVE will be issued automatically for the \u2018State\u2019 and \u2018Update result\u2019 parameters while upgrading the device. The notifications returned by the device will be visible in the test case logs. Expected update result \u2013 if the update result you enter here equals the result returned by the device, the test will be passed. If left blank, the server will expect the default result defined by the LwM2M standard. You can choose among the ten update results defined as per the LwM2M protocol specification. WAIT # Wait is used to set the waiting time before executing the next action. You can define it using two attributes: Waiting time \u2013 the interval set before the next action is executed. In progress message \u2013 a custom text that will be displayed as the test case progress message while waiting for the execution of the next action. Pause response # Pause response is used to delay a response to be sent to the device. If set, the server will wait before sending the response until the Send paused response action is executed. Request type \u2013 the kind of request for which you want to pause the response. Wait for uplink request # Wait for uplink request is used to prevent the server from executing any tasks or actions until an uplink request arrives from the device. You can define the action using three attributes: Request type to wait for \u2013 the kind of request you want to wait for. Timeout \u2013 the time period in seconds within which the uplink request should arrive. In case the timeout is up with no request, the action will fail. Waiting message \u2013 the message displayed during the test case execution while waiting for the arrival of the uplink request. Send paused response # Send paused response is used to send the previously paused response to the device. Request type \u2013 the kind of request for which you want to send the previously paused response. Start Notification recording # Start Notification recording is used to make the Server simulator save all notifications received from the device in its memory. The limit of recorded notifications can be configured using the ddscNotificationRecordingLimit setting value. Once the limit is reached, new notifications are not recorded. Execute the Start Notification recording action again in the same test to clear the recording state and to be able to match more notifications than the recording limit. Expect Notification # Expect Notification is used to check if recorded Notifications match the required criteria. You can define it using five attributes: Expected path \u2013 only notifications that were received on this path will be validated. In case of a notification with multiple paths and values, each path and value are treated as separate notifications. Expected value \u2013 use it to check if there is any notification that has a given value and matches all other criteria. Expected arrival order \u2013 use it to limit the validation only to one notification on a given path that arrived in a given order since the last Start Notification recording action. Note that the counting starts from 0 and that the Observe response is also counted if it is executed after the recording action started. Timeout \u2013 if the expected notification does not arrive within this time limit, the action will fail. Waiting message \u2013 a custom text that will be displayed as the test case progress message while waiting for the action execution. Loop start # Loop start is used to repeat an action or a set of actions within a test case. Note that when configuring the first action inside the loop, the Loop end action is added automatically. Repetitions \u2013 the number of iterations of action(s) inside the loop.","title":"Test case actions"},{"location":"Interoperability_tests_guide/Test_case_actions.html#test-case-actions","text":"","title":"Test case actions"},{"location":"Interoperability_tests_guide/Test_case_actions.html#introduction","text":"Based on the LwM2M 1.0 standard protocol operations, Actions are steps that can be defined within a test case. While some are used for the communication between the Server and the LwM2M test device, others help to define the test case logic. Read this chapter to learn how to use Actions in the configuration of customizable interoperability test cases.","title":"Introduction"},{"location":"Interoperability_tests_guide/Test_case_actions.html#action-attributes","text":"All the available Actions are defined using a set of configurable attributes that you can specify while adding or editing a test case. The attributes available under each action are determined by the type of given Action. However, to set up a test case, not all attributes are mandatory. The general rule is that if you leave an optional attribute\u2019s field blank, the final test case result won\u2019t be affected in any way. Tip if you would like to make the test device ignore a particular attribute so that it doesn\u2019t answer to the server request, type None in the optional attribute\u2019s field.","title":"Action attributes"},{"location":"Interoperability_tests_guide/Test_case_actions.html#description-of-actions","text":"Within the Server simulator test cases, the following Actions are available (with mandatory attributes written in bold): READ WRITE EXECUTE DISCOVER DELETE CREATE WRITE ATTRIBUTES CLEAR ATTRIBUTES OBSERVE CANCEL OBSERVE Firmware Update Wait Pause response Wait for uplink request Send paused response Start Notification recording Expect Notification Loop start","title":"Description of Actions"},{"location":"Interoperability_tests_guide/Test_case_actions.html#read","text":"READ is used to access the value of an object, object instances, a resource and single resource instances. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter you want to read. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected value \u2013 if the value you enter here equals the value read from the device, the test will be passed. If left blank, the value will only show up in the test case log and it will have no impact on the test case result. Note that this READ attribute works only for Resources and Resource Instances. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. LwM2M: Requested content format \u2013 the content format of the device answer that you request for your read operation. If the device doesn\u2019t support the requested format, the test will fail. If left blank, the device can decide what content format to use; any format will be accepted.","title":"READ"},{"location":"Interoperability_tests_guide/Test_case_actions.html#write","text":"WRITE is used to change the value of a Resource. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter for which you want to set a new value or overwrite the existing one. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Value \u2013 the value you enter here sets a new value or overwrites the existing one. If left blank, the existing value will be kept and the test will be passed. LwM2M: Content format \u2013 the content format in which you send the write request to the device. If the device doesn\u2019t support the specified format, the test will fail. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard.","title":"WRITE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#execute","text":"EXECUTE is used to initiate some action and can only be performed on individual Resources. If the device receives an EXECUTE for an Object Instance(s) or Resource Instance(s), it will return an error. You can define it using two attributes: Parameter name \u2013 the name of the data model parameter for which you will issue an execute. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Execute arguments \u2013 the execution arguments passed to the device expressed in Plain Text format. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard.","title":"EXECUTE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#discover","text":"DISCOVER is used to discover LwM2M Attributes attached to an Object, Object Instances, and Resources. You can define it using two attributes: Parameter name \u2013 the name of the data model parameter whose attributes you want to discover. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard.","title":"DISCOVER"},{"location":"Interoperability_tests_guide/Test_case_actions.html#delete","text":"DELETE is used for the server to delete an Object Instance within the LwM2M Client. Note that an Object Instance to be deleted must be an Object Instance that is announced by the Client to the Server using the Register and Update operations of the Client Registration Interface. Object instance \u2013 the object instance that you want to delete. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0) or the numerical (e.g. 3.0) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard.","title":"DELETE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#create","text":"CREATE is used by the Server simulator to create Object Instance(s) within the LwM2M Client. You can define the action using three parameters and a set of Object Instance-dependent values: Object ID or name \u2013 the Object that you want to create an Instance for. Note that it can be specified either using the full name in the string (e.g. \u2018Portfolio\u2019) or the numerical (e.g. \u201816\u2019) value of the parameter. LwM2M: Instance number \u2013 the number assigned to the Object Instance to be created. If left blank, the number will be chosen by the device. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Resources \u2013 click the Provide initial values button to view and specify the possible Resources and Resource Instances of the Object Instance to be created. Note that if the values marked as required are left blank, the action will fail for devices that correctly implement LwM2M.","title":"CREATE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#write-attributes","text":"WRITE ATTRIBUTES is used to attach metadata containing parameters for Notifications to an Object, an Object Instance or a Resource. You can define it using seven attributes: Parameter name \u2013 the name of the data model parameter for which you will write attributes. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Minimum period \u2013 the minimum time in seconds that the device waits between two notifications. Maximum period \u2013 the minimum time in seconds that the device waits between two notifications. Value greater than \u2013 notifications will be sent only when the monitored value crosses the threshold you set here. However, please note that the interpretation of this parameter may differ depending on the specific LwM2M Client implementation. Value less than \u2013 notifications will be sent only when the monitored value crosses the threshold you set here. However, please note that the interpretation of this parameter may differ depending on the specific LwM2M Client implementation. Step \u2013 the minimum change value between two notifications.","title":"WRITE ATTRIBUTES"},{"location":"Interoperability_tests_guide/Test_case_actions.html#clear-attributes","text":"CLEAR ATTRIBUTES is used to clear the metadata attached to an Object, an Object Instance or a Resource which contain parameters for Notifications. You can define it using seven attributes: Parameter name \u2013 the name of the data model parameter for which you will clear attributes. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Clear minimum period \u2013 if set to true, it clears the minimum time in seconds between two notifications. If set to false, the value is kept. Clear maximum period \u2013 if set to true, it clears the maximum time set between two notifications. If set to false, the value is kept. Clear value greater than \u2013 if set to true, it clears the threshold set for the monitored value. If set to false, the value is kept. Clear value less than \u2013 if set to true, it clears the threshold set for the monitored value. If set to false, the value is kept. Clear step \u2013 if set to true, it clears the minimum change value between two notifications. If set to false, the value is kept.","title":"CLEAR ATTRIBUTES"},{"location":"Interoperability_tests_guide/Test_case_actions.html#observe","text":"OBSERVE is used to initiate an observation request for changes of a specific Resource, Resources within an Object Instance or for all the Object Instances of an Object. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter whose value(s) you will observe. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Fail if already observed \u2013 if set to true, the test will fail in case there is an existing observation set on this parameter. In case there is no observation set, your observe request should be accepted and the test won\u2019t fail. If set to false, any existing observations will be cancelled and requested again by this one and the test will be passed. LwM2M: Content format \u2013 the content format in which you send the OBSERVE request to the device. If the device doesn\u2019t support the specified format, the test will fail.","title":"OBSERVE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#cancel-observe","text":"CANCEL OBSERVE is used to cancel an observation. You can define it using three attributes: Parameter name \u2013 the name of the data model parameter for which you will cancel an existing observation. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Cancel type \u2013 the mode in which the CANCEL OBSERVE will be sent to the device. o ACTIVE - CANCEL OBSERVE is sent to the device immediately. o PASSIVE - CoAP RESET is sent in response to the next notification message received from the device. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard.","title":"CANCEL OBSERVE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#firmware-update","text":"Firmware Update is used to perform a firmware update operation on the test device. You can define it using five attributes: Firmware \u2013 the ID of the resource used as the firmware source. Update timeout \u2013 the time period in seconds within which the firmware update should be completed. In case the timeout is up and the update process has not finished, the action will fail. Delivery method \u2013 The protocol and transfer method used to deliver the firmware file to the device. Use notifications \u2013 if set to true, an OBSERVE will be issued automatically for the \u2018State\u2019 and \u2018Update result\u2019 parameters while upgrading the device. The notifications returned by the device will be visible in the test case logs. Expected update result \u2013 if the update result you enter here equals the result returned by the device, the test will be passed. If left blank, the server will expect the default result defined by the LwM2M standard. You can choose among the ten update results defined as per the LwM2M protocol specification.","title":"Firmware Update"},{"location":"Interoperability_tests_guide/Test_case_actions.html#wait","text":"Wait is used to set the waiting time before executing the next action. You can define it using two attributes: Waiting time \u2013 the interval set before the next action is executed. In progress message \u2013 a custom text that will be displayed as the test case progress message while waiting for the execution of the next action.","title":"WAIT"},{"location":"Interoperability_tests_guide/Test_case_actions.html#pause-response","text":"Pause response is used to delay a response to be sent to the device. If set, the server will wait before sending the response until the Send paused response action is executed. Request type \u2013 the kind of request for which you want to pause the response.","title":"Pause response"},{"location":"Interoperability_tests_guide/Test_case_actions.html#wait-for-uplink-request","text":"Wait for uplink request is used to prevent the server from executing any tasks or actions until an uplink request arrives from the device. You can define the action using three attributes: Request type to wait for \u2013 the kind of request you want to wait for. Timeout \u2013 the time period in seconds within which the uplink request should arrive. In case the timeout is up with no request, the action will fail. Waiting message \u2013 the message displayed during the test case execution while waiting for the arrival of the uplink request.","title":"Wait for uplink request"},{"location":"Interoperability_tests_guide/Test_case_actions.html#send-paused-response","text":"Send paused response is used to send the previously paused response to the device. Request type \u2013 the kind of request for which you want to send the previously paused response.","title":"Send paused response"},{"location":"Interoperability_tests_guide/Test_case_actions.html#start-notification-recording","text":"Start Notification recording is used to make the Server simulator save all notifications received from the device in its memory. The limit of recorded notifications can be configured using the ddscNotificationRecordingLimit setting value. Once the limit is reached, new notifications are not recorded. Execute the Start Notification recording action again in the same test to clear the recording state and to be able to match more notifications than the recording limit.","title":"Start Notification recording"},{"location":"Interoperability_tests_guide/Test_case_actions.html#expect-notification","text":"Expect Notification is used to check if recorded Notifications match the required criteria. You can define it using five attributes: Expected path \u2013 only notifications that were received on this path will be validated. In case of a notification with multiple paths and values, each path and value are treated as separate notifications. Expected value \u2013 use it to check if there is any notification that has a given value and matches all other criteria. Expected arrival order \u2013 use it to limit the validation only to one notification on a given path that arrived in a given order since the last Start Notification recording action. Note that the counting starts from 0 and that the Observe response is also counted if it is executed after the recording action started. Timeout \u2013 if the expected notification does not arrive within this time limit, the action will fail. Waiting message \u2013 a custom text that will be displayed as the test case progress message while waiting for the action execution.","title":"Expect Notification"},{"location":"Interoperability_tests_guide/Test_case_actions.html#loop-start","text":"Loop start is used to repeat an action or a set of actions within a test case. Note that when configuring the first action inside the loop, the Loop end action is added automatically. Repetitions \u2013 the number of iterations of action(s) inside the loop.","title":"Loop start"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html","text":"Jenkins/GitLab integration with interop tests API # If you would like to automate your interoperability tests, you can use the Coiote DM API and integrate it with a CI/CD environment like Jenkins or GitLab. Follow the guide below to learn how to configure the integration, run tests and summarize your test execution using these tools. Note The following instruction is based on integration with Jenkins. To integrate with GitLab, you can follow the same steps, but with slight adjustments - for details, please see subsection on GitLab . Prerequisites # An active Jenkins and GitLab account. A Git project repository. A working Coiote DM installation and a port for communication with the installation API. A device registered in the platform (if the tests require the device to be registered). A Coiote DM user with access to the device and the appropriate API permissions. Jenkins - standard pipeline # Set up standard pipeline # Upload a file with python script used to run test cases to your project repository: Edit the following python script where required to adjust it to your environment (remember to select the appropriate tab with script depending on whether you want to run your tests on a single device or a device group). Device #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_NAME = \"test-device\" # type the endpoint name of your device. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the device. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/device/\" + DEVICE_NAME REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/device/\" + DEVICE_NAME PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = result . json ()[ \"waitingForExecution\" ] time . sleep ( 15 ) for test in result . json ()[ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Group #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_GROUP = \"root.mt.embedded.devicetypes.test.demo_client.2_9_0\" # type the name of your device group. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the group. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/group/\" + DEVICE_GROUP REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/group/\" + DEVICE_GROUP PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : still_running = 0 result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) exit ( 1 ) for device in result . json (): if not ( result . json ()[ device ][ \"waitingForExecution\" ] == []): still_running += 1 if ( still_running == 0 ): tests_running = False time . sleep ( 15 ) for device in result . json (): for test in result . json ()[ device ][ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ device ][ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ device ][ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Save the script as a .py file and upload it to your project repository. Create a pipeline for your project: Go to your Jenkins account and in the Dashboard view, select New Item from the menu on the left. Enter a name for your pipeline, select Pipeline , and confirm by clicking OK . Configure your pipeline: Go to your newly created pipeline and select Configure from the menu on the left. In the Source Code Management section, select the Git option and provide the following: Repository URL - enter the URL address of your GitLab repository that hosts the python script file from Step 1 . Credentials - add the user name and password of your git repository account. Branch Specifier - choose the GitLab branch you want to use in the pipeline. In the Build section, select the Execute Shell option from the drop-down list and provide the command to run the python script file from Step 1 : python3 example_filename.py Additionally, in the Post-build Actions section, select the Publish Junit test result report to set up test result report generation: Depending on your preferences, check or uncheck the Allow empty results option. Click Save . Run standard pipeline # Enter pipeline and select Build Now . Note Remember to check if the device you run the tests for is connected and registered in Coiote DM. Once the tests are performed, you will see your build status along with a graph reporting the execution status for each test case. Jenkins multibranch pipeline # Set up multibranch pipeline # Alternatively to the standard pipeline, you may configure a multibranch pipeline to run your test cases. Upload the Jenkinsfile that will define your multibranch pipeline to your project repository: Edit the script where required to adjust it to your environment: Note Remember to change the name example_filename.py to your custom name that you will choose in Step 2 . pipeline { options { disableConcurrentBuilds () } agent any stages { stage ( 'protocol_tests' ) { steps { sh 'python3 example_filename.py' } } } post { always { junit \"report.xml\" archiveArtifacts artifacts : 'report.xml' } cleanup { script { clean () } } } } Save the file as Jenkinsfile and upload it to the chosen branch of your project repository. Upload a file with python script used to run test cases to your project repository: Edit the following python script where required to adjust it to your environment (remember to select the appropriate tab with script depending on whether you want to run your tests on a single device or a device group). Device #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_NAME = \"test-device\" # type the endpoint name of your device. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the device. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/device/\" + DEVICE_NAME REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/device/\" + DEVICE_NAME PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = result . json ()[ \"waitingForExecution\" ] time . sleep ( 15 ) for test in result . json ()[ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Group #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_GROUP = \"root.mt.embedded.devicetypes.test.demo_client.2_9_0\" # type the name of your device group. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the group. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/group/\" + DEVICE_GROUP REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/group/\" + DEVICE_GROUP PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : still_running = 0 result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) exit ( 1 ) for device in result . json (): if not ( result . json ()[ device ][ \"waitingForExecution\" ] == []): still_running += 1 if ( still_running == 0 ): tests_running = False time . sleep ( 15 ) for device in result . json (): for test in result . json ()[ device ][ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ device ][ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ device ][ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Save the script as a .py file (using the filename specified in the Jenkinsfile in the previous step) and upload it to your project repository. Create a pipeline for your project: Go to your Jenkins account and in the Dashboard view, select New Item from the menu on the left. Enter a name for your pipeline, select Multibranch Pipeline and confirm by clicking OK . Configure your pipeline: Go to your newly created pipeline and select Configure from the menu on the left. In the Branch Sources section, select the Git option and provide the following: Project Repository - enter the URL address of your project repository that hosts the Jenkinsfile and the python script file from Step 2 . Credentials - add the user name and password of your GitLab account. In the Build Configuration section, select the by Jenkinsfile mode from the drop-down list and provide the GitLab path to the Jenkinsfile from Step 1 (if the file is located in the GitLab root folder, it is enough to type Jenkinsfile ) Click Save . Run multibranch pipeline # Before running the tests for a chosen branch, you have to perform a scan to detect available branches (those with a Jenkinsfile ): Go to your multibranch pipeline and select Scan Multibranch Pipeline Now option from the menu on the left. Once the scan is completed, you will see a list of available branches. Enter a chosen branch by clicking on its name and select Build Now . Note Remember to check if the device you run the tests for is connected and registered in Coiote DM. Once the tests are performed, you will see your build status along with a graph reporting the execution status for each test case. GitLab - configure and run pipeline # Coiote DM interop tests API can also be integrated with GitLab using the GitLab's CI/CD toolset. Here is how to do it: Upload the gitlab-ci.yml file that will define your GitLab pipeline to your project repository: Edit the script where required to adjust it to your environment: Note Remember to change the name example_filename.py to your custom name that you will choose in the next step. Also, keep in mind that running a pipeline in GitLab requires a docker image of a Linux distribution (or any operating system that can run python script). image : name : example.repository.com/docker-local/linux_image protocol-tests : stage : test script : - python3 example_filename.py artifacts : when : always paths : - report.xml reports : junit : report.xml Save the file as gitlab-ci.yml and upload it to the chosen branch of your project repository. Follow Step 2 from Creating a Jenkins multibranch pipeline (uploading a file with python script to your GitLab repository). Run a created pipeline for your project: Go to your GitLab project and in the Dashboard view, select CI/CD from the menu on the left and click Pipelines . Attention Note that to be able to run a pipeline, you will need to have the GitLab CI/CD toolset configured. For details, please check https://docs.gitlab.com/ee/ci/introduction/index.html . You should be able to see the branch with the uploaded gitlab-ci.yml file. Select the Run pipeline button, then confirm again by clicking Run pipeline . Once the pipeline execution is finished, you should be able to see the results in the Tests tab of your pipeline. Note Viewing graphs with test results is not supported in GitLab by default as it requires additional plugins.","title":"Jenkins/GitLab integration with interop tests API"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#jenkinsgitlab-integration-with-interop-tests-api","text":"If you would like to automate your interoperability tests, you can use the Coiote DM API and integrate it with a CI/CD environment like Jenkins or GitLab. Follow the guide below to learn how to configure the integration, run tests and summarize your test execution using these tools. Note The following instruction is based on integration with Jenkins. To integrate with GitLab, you can follow the same steps, but with slight adjustments - for details, please see subsection on GitLab .","title":"Jenkins/GitLab integration with interop tests API"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#prerequisites","text":"An active Jenkins and GitLab account. A Git project repository. A working Coiote DM installation and a port for communication with the installation API. A device registered in the platform (if the tests require the device to be registered). A Coiote DM user with access to the device and the appropriate API permissions.","title":"Prerequisites"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#jenkins-standard-pipeline","text":"","title":"Jenkins - standard pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#set-up-standard-pipeline","text":"Upload a file with python script used to run test cases to your project repository: Edit the following python script where required to adjust it to your environment (remember to select the appropriate tab with script depending on whether you want to run your tests on a single device or a device group). Device #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_NAME = \"test-device\" # type the endpoint name of your device. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the device. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/device/\" + DEVICE_NAME REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/device/\" + DEVICE_NAME PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = result . json ()[ \"waitingForExecution\" ] time . sleep ( 15 ) for test in result . json ()[ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Group #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_GROUP = \"root.mt.embedded.devicetypes.test.demo_client.2_9_0\" # type the name of your device group. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the group. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/group/\" + DEVICE_GROUP REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/group/\" + DEVICE_GROUP PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : still_running = 0 result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) exit ( 1 ) for device in result . json (): if not ( result . json ()[ device ][ \"waitingForExecution\" ] == []): still_running += 1 if ( still_running == 0 ): tests_running = False time . sleep ( 15 ) for device in result . json (): for test in result . json ()[ device ][ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ device ][ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ device ][ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Save the script as a .py file and upload it to your project repository. Create a pipeline for your project: Go to your Jenkins account and in the Dashboard view, select New Item from the menu on the left. Enter a name for your pipeline, select Pipeline , and confirm by clicking OK . Configure your pipeline: Go to your newly created pipeline and select Configure from the menu on the left. In the Source Code Management section, select the Git option and provide the following: Repository URL - enter the URL address of your GitLab repository that hosts the python script file from Step 1 . Credentials - add the user name and password of your git repository account. Branch Specifier - choose the GitLab branch you want to use in the pipeline. In the Build section, select the Execute Shell option from the drop-down list and provide the command to run the python script file from Step 1 : python3 example_filename.py Additionally, in the Post-build Actions section, select the Publish Junit test result report to set up test result report generation: Depending on your preferences, check or uncheck the Allow empty results option. Click Save .","title":"Set up standard pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#run-standard-pipeline","text":"Enter pipeline and select Build Now . Note Remember to check if the device you run the tests for is connected and registered in Coiote DM. Once the tests are performed, you will see your build status along with a graph reporting the execution status for each test case.","title":"Run standard pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#jenkins-multibranch-pipeline","text":"","title":"Jenkins multibranch pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#set-up-multibranch-pipeline","text":"Alternatively to the standard pipeline, you may configure a multibranch pipeline to run your test cases. Upload the Jenkinsfile that will define your multibranch pipeline to your project repository: Edit the script where required to adjust it to your environment: Note Remember to change the name example_filename.py to your custom name that you will choose in Step 2 . pipeline { options { disableConcurrentBuilds () } agent any stages { stage ( 'protocol_tests' ) { steps { sh 'python3 example_filename.py' } } } post { always { junit \"report.xml\" archiveArtifacts artifacts : 'report.xml' } cleanup { script { clean () } } } } Save the file as Jenkinsfile and upload it to the chosen branch of your project repository. Upload a file with python script used to run test cases to your project repository: Edit the following python script where required to adjust it to your environment (remember to select the appropriate tab with script depending on whether you want to run your tests on a single device or a device group). Device #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_NAME = \"test-device\" # type the endpoint name of your device. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the device. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/device/\" + DEVICE_NAME REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/device/\" + DEVICE_NAME PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = result . json ()[ \"waitingForExecution\" ] time . sleep ( 15 ) for test in result . json ()[ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Group #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_GROUP = \"root.mt.embedded.devicetypes.test.demo_client.2_9_0\" # type the name of your device group. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the group. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/group/\" + DEVICE_GROUP REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/group/\" + DEVICE_GROUP PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : still_running = 0 result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) exit ( 1 ) for device in result . json (): if not ( result . json ()[ device ][ \"waitingForExecution\" ] == []): still_running += 1 if ( still_running == 0 ): tests_running = False time . sleep ( 15 ) for device in result . json (): for test in result . json ()[ device ][ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ device ][ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ device ][ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Save the script as a .py file (using the filename specified in the Jenkinsfile in the previous step) and upload it to your project repository. Create a pipeline for your project: Go to your Jenkins account and in the Dashboard view, select New Item from the menu on the left. Enter a name for your pipeline, select Multibranch Pipeline and confirm by clicking OK . Configure your pipeline: Go to your newly created pipeline and select Configure from the menu on the left. In the Branch Sources section, select the Git option and provide the following: Project Repository - enter the URL address of your project repository that hosts the Jenkinsfile and the python script file from Step 2 . Credentials - add the user name and password of your GitLab account. In the Build Configuration section, select the by Jenkinsfile mode from the drop-down list and provide the GitLab path to the Jenkinsfile from Step 1 (if the file is located in the GitLab root folder, it is enough to type Jenkinsfile ) Click Save .","title":"Set up multibranch pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#run-multibranch-pipeline","text":"Before running the tests for a chosen branch, you have to perform a scan to detect available branches (those with a Jenkinsfile ): Go to your multibranch pipeline and select Scan Multibranch Pipeline Now option from the menu on the left. Once the scan is completed, you will see a list of available branches. Enter a chosen branch by clicking on its name and select Build Now . Note Remember to check if the device you run the tests for is connected and registered in Coiote DM. Once the tests are performed, you will see your build status along with a graph reporting the execution status for each test case.","title":"Run multibranch pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#gitlab-configure-and-run-pipeline","text":"Coiote DM interop tests API can also be integrated with GitLab using the GitLab's CI/CD toolset. Here is how to do it: Upload the gitlab-ci.yml file that will define your GitLab pipeline to your project repository: Edit the script where required to adjust it to your environment: Note Remember to change the name example_filename.py to your custom name that you will choose in the next step. Also, keep in mind that running a pipeline in GitLab requires a docker image of a Linux distribution (or any operating system that can run python script). image : name : example.repository.com/docker-local/linux_image protocol-tests : stage : test script : - python3 example_filename.py artifacts : when : always paths : - report.xml reports : junit : report.xml Save the file as gitlab-ci.yml and upload it to the chosen branch of your project repository. Follow Step 2 from Creating a Jenkins multibranch pipeline (uploading a file with python script to your GitLab repository). Run a created pipeline for your project: Go to your GitLab project and in the Dashboard view, select CI/CD from the menu on the left and click Pipelines . Attention Note that to be able to run a pipeline, you will need to have the GitLab CI/CD toolset configured. For details, please check https://docs.gitlab.com/ee/ci/introduction/index.html . You should be able to see the branch with the uploaded gitlab-ci.yml file. Select the Run pipeline button, then confirm again by clicking Run pipeline . Once the pipeline execution is finished, you should be able to see the results in the Tests tab of your pipeline. Note Viewing graphs with test results is not supported in GitLab by default as it requires additional plugins.","title":"GitLab - configure and run pipeline"},{"location":"User_Guide/test-md.html","text":"yyyy # Tip tekst # ddddd ^^x^^ {==some text==} ++enter++ ++ctrl+alt+delete++ Form manager ~~words~~ (works) {>>I just wanted to comment on it.<<} {-- incorrect --} {--deleted--} ~~The world is flat.~~ [x] Write the press release [ ] Update the website [ ] Contact the media","title":"Test md"},{"location":"User_Guide/test-md.html#yyyy","text":"","title":"yyyy"},{"location":"User_Guide/test-md.html#tip-tekst","text":"ddddd ^^x^^ {==some text==} ++enter++ ++ctrl+alt+delete++ Form manager ~~words~~ (works) {>>I just wanted to comment on it.<<} {-- incorrect --} {--deleted--} ~~The world is flat.~~ [x] Write the press release [ ] Update the website [ ] Contact the media","title":"Tip tekst"},{"location":"User_Guide/Appendixes/Third_party_software.html","text":"Third party software # The below table presents all third party libraries with their licenses. table { width: 90%; overflow-wrap: anywhere; word-break: break-all; Category License Dependency Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) joda-time # joda-time # 2.8.2 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.objenesis # objenesis # 2.1 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.snmp4j # snmp4j # 2.4.1 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.snmp4j # snmp4j-agent # 2.4.1 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0.html) com.typesafe.scala-logging # scala-logging_2.12 # 3.5.0 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.ftpserver # ftplet-api # 1.0.6 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.ftpserver # ftpserver-core # 1.0.6 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.mina # mina-core # 2.0.7 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.sshd # apache-sshd # 0.13.0 Apache Apache License (http://www.apache.org/licenses/LICENSE-2.0.txt) com.chuusai # shapeless_2.12 # 2.3.2 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin.external.google # guava # 16.0.1.vaadin1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin.external.streamhtmlparser # streamhtmlparser-jsilver # 0.0.10.vaadin1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-annotations # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-core # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-models # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-parser # 1.0.31 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) org.xerial.snappy # snappy-java # 1.1.7.1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) org.jgroups # jgroups # 4.0.15.Final Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-client # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-server # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-shared # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-shared-deps # 1.0.3 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe # config # 1.3.4 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe # ssl-config-core_2.12 # 0.2.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-actor_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-agent_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-slf4j_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-stream_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-testkit_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-cli # commons-cli # 1.3.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-codec # commons-codec # 1.10 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-collections # commons-collections # 3.2.2 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-eval_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-execution_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-reactive_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-types_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix_2.12 # 2.3.0 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) io.netty # netty-all # 4.1.27.Final Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) net.sf.supercsv # super-csv # 2.3.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.commons # commons-lang3 # 3.4 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.commons # commons-math3 # 3.6.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.jctools # jctools-core # 2.0.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.yaml # snakeyaml # 1.17 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-client # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-continuation # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-http # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-io # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-jmx # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-proxy # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-rewrite # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-security # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-server # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-servlet # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-servlets # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-util # 9.3.19.v20170502 Apache Apache Software License, Version 1.1 (http://www.apache.org/licenses/LICENSE-1.1) org.bouncycastle # bcpg-jdk15on # 1.51 Apache Apache Software Licenses (http://www.apache.org/licenses/LICENSE-2.0.txt) org.slf4j # log4j-over-slf4j # 1.7.21 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-macros_2.12 # 0.8.0-RC3 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-rest_2.12 # 0.8.0-RC3 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-utils_2.12 # 0.8.0-RC3 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-http-core_2.12 # 10.0.1 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-http_2.12 # 10.0.1 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-parsing_2.12 # 10.0.1 Apache Similar to Apache License but with the acknowledgment clause removed (https://raw.github.com/hunterhacker/jdom/master/LICENSE.txt) org.jdom # jdom2 # 2.0.6 Apache The Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.github.ghik # silencer-lib_2.12 # 1.4.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-annotations # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-core # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-databind # 2.8.7 Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.dataformat # jackson-dataformat-yaml # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.google.code.findbugs # jsr305 # 3.0.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.google.guava # guava # 21.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-io # commons-io # 2.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-lang # commons-lang # 2.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) io.prometheus.jmx # jmx_prometheus_javaagent # 0.12.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) javax.validation # validation-api # 1.1.0.Final Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.kafka # kafka-clients # 1.1.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.logging.log4j # log4j-api # 2.5 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.logging.log4j # log4j-to-slf4j # 2.5 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi-ooxml # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi-ooxml-schemas # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.velocity # velocity # 1.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.xmlbeans # xmlbeans # 2.3.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.codehaus.jackson # jackson-core-asl # 1.9.13 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.codehaus.jackson # jackson-mapper-asl # 1.9.13 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.jgroups.kubernetes # jgroups-kubernetes # 1.0.8.Final Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.lz4 # lz4-java # 1.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # bson # 3.11.2 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-async # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-core # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-legacy # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-reactivestreams # 1.12.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-sync # 3.11.2 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.quartz-scheduler # quartz # 2.2.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-aop # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-beans # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-context # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-context-support # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-core # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-expression # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-oxm # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-test # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-tx # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-web # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-webmvc # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-ws-core # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-ws-test # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-xml # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.typelevel # macro-compat_2.12 # 1.1.1 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) stax # stax-api # 1.0.1 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) tomcat # tomcat-apr # 5.5.23 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) xerces # xercesImpl # 2.9.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) xml-apis # xml-apis # 1.0.b2 BSD BSD (https://github.com/nbronson/scala-stm/blob/master/LICENSE.txt) org.scala-stm # scala-stm_2.12 # 0.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-compiler # 2.12.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-library # 2.12.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-reflect # 2.12.8 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.owasp.encoder # encoder # 1.2.2 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-java8-compat_2.12 # 1.1.1 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-parser-combinators_2.12 # 1.0.5 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-xml_2.12 # 1.0.6 BSD BSD License (http://xmlunit.svn.sourceforge.net/viewvc/ checkout /xmlunit/trunk/xmlunit/LICENSE.txt) xmlunit # xmlunit # 1.5 BSD BSD License (https://opensource.org/licenses/bsd-license.php) com.yahoo.platform.yui # yuicompressor # 2.4.8 BSD BSD style (http://xstream.codehaus.org/license.html) com.thoughtworks.xstream # xstream # 1.4.8 BSD BSD-style (http://www.opensource.org/licenses/bsd-license.php) org.scalacheck # scalacheck_2.12 # 1.13.4 BSD New BSD License (http://www.opensource.org/licenses/bsd-license.php) org.hamcrest # hamcrest-core # 1.3 BSD Revised BSD (http://www.jcraft.com/jsch/LICENSE.txt) com.jcraft # jsch # 0.1.55 BSD The BSD License (http://www.opensource.org/licenses/bsd-license.php) jline # jline # 2.14.6 BSD Two-clause BSD-style license (http://github.com/sbt/junit-interface/blob/master/LICENSE.txt) com.novocode # junit-interface # 0.11 CC0 CC0 (http://creativecommons.org/publicdomain/zero/1.0/) org.reactivestreams # reactive-streams # 1.0.2 CDDL COMMON DEVELOPMENT AND DISTRIBUTION LICENSE (CDDL) Version 1.1 (https://javaee.github.io/javamail/LICENSE) com.sun.mail # javax.mail # 1.4.5 CDDL COMMON DEVELOPMENT AND DISTRIBUTION LICENSE (CDDL) Version 1.1 (https://javaee.github.io/servlet-spec/LICENSE) javax.servlet # javax.servlet-api # 4.0.1 LGPL GNU LESSER GENERAL PUBLIC LICENSE (http://www.gnu.org/licenses/lgpl.txt) c3p0 # c3p0 # 0.9.1.1 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) ch.qos.logback # logback-classic # 1.1.8 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) ch.qos.logback # logback-core # 1.1.8 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) info.faljse # SDNotify # 1.3 MIT MIT (http://www.opensource.org/licenses/mit-license.html) com.lihaoyi # sourcecode_2.12 # 0.1.4 MIT MIT (https://opensource.org/licenses/MIT) org.scalamock # scalamock-core_2.12 # 3.5.0 MIT MIT (https://opensource.org/licenses/MIT) org.scalamock # scalamock-scalatest-support_2.12 # 3.5.0 MIT MIT (http://opensource.org/licenses/MIT) org.spire-math # jawn-parser_2.12 # 0.10.3 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) ch.qos.cal10n # cal10n-api # 0.7.4 MIT MIT License (http://www.slf4j.org/license.html) net.logstash.logback # logstash-logback-encoder # 4.6 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # jcl-over-slf4j # 1.7.21 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # jul-to-slf4j # 1.7.21 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # slf4j-ext # 1.6.3 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # derive_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # fastparse-utils_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # fastparse_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # scalaparse_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # upickle_2.12 # 0.4.4 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-annotations_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-core_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-jetty_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-macros_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-redis_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-shared_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-spring_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-core_2.12 # 1.20.19 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-macros_2.12 # 1.20.19 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-util_2.12 # 1.20.19 MIT The MIT License (http://jsoup.com/license) org.jsoup # jsoup # 1.8.3 MIT The MIT License (http://github.com/mockito/mockito/blob/master/LICENSE) org.mockito # mockito-core # 1.10.19 Mozilla MPL 1.1 (http://www.mozilla.org/MPL/MPL-1.1.html) org.javassist # javassist # 3.19.0-GA Mozilla MPL 1.1 (http://www.mozilla.org/MPL/MPL-1.1.html) rhino # js # 1.7R2 Public Domain Public Domain aopalliance # aopalliance # 1.0 Public Domain Public Domain (http://www.xmlpull.org/v1/download/unpacked/LICENSE.txt) xmlpull # xmlpull # 1.1.3.1 Public Domain Public Domain (http://creativecommons.org/licenses/publicdomain) xpp3 # xpp3_min # 1.1.4c unrecognized Bouncy Castle Licence (http://www.bouncycastle.org/licence.html) org.bouncycastle # bcpkix-jdk15on # 1.51 unrecognized Bouncy Castle Licence (http://www.bouncycastle.org/licence.html) org.bouncycastle # bcprov-jdk15on # 1.51 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # californium-core # 2.0.0-M18 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # californium-legal # 2.0.0-M18 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # scandium # 2.0.0-M18 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # com.ibm.icu # 50.1.1.v201304230130 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.apache.commons.logging # 1.1.1.v201101211721 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.birt.runtime # 4.3.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.contenttype # 3.4.200.v20130326-1255 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.expressions # 3.4.500.v20130515-1343 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.filesystem # 1.4.0.v20130514-1240 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.jobs # 3.5.300.v20130429-1813 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.resources # 3.8.100.v20130521-2026 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.runtime # 3.9.0.v20130326-1255 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity # 1.2.8.v201305301230 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.apache.derby # 1.0.103.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.apache.derby.dbdefinition # 1.0.2.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.console.profile # 1.0.10.v201109250955 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.db.generic # 1.0.1.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.dbdefinition.genericJDBC # 1.0.1.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda # 3.4.0.v201305170924 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.consumer # 3.2.6.v201305170644 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.design # 3.3.6.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.flatfile # 3.1.5.v201305221644 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.profile # 3.2.8.v201209080429 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.sqm.core # 1.2.6.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.hsqldb # 1.0.0.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.hsqldb.dbdefinition # 1.0.0.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.db2.luw # 1.0.2.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.db2.luw.dbdefinition # 1.0.4.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.informix # 1.0.1.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.informix.dbdefinition # 1.0.4.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.msft.sqlserver # 1.0.2.v201212120617 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.msft.sqlserver.dbdefinition # 1.0.1.v201201240505 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.mysql # 1.0.4.v201212120617 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.mysql.dbdefinition # 1.0.4.v201109022331 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oda.ws # 1.2.5.v201305031101 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oda.xml # 1.2.5.v201305031101 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oracle # 1.0.0.v201107221506 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oracle.dbdefinition # 1.0.103.v201206010214 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.postgresql # 1.1.1.v201205252207 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.postgresql.dbdefinition # 1.0.2.v201110070445 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.dbdefinition # 1.0.2.v201107221519 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.derby # 1.0.0.v201107221519 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.sql # 1.0.6.v201208230744 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.sql.query # 1.1.4.v201212120619 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf # 2.6.0.v20130610-0406 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.common # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore.change # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore.xmi # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.app # 1.3.100.v20130327-1442 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.common # 3.6.200.v20130402-1505 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.preferences # 3.5.100.v20130422-1538 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.registry # 3.5.300.v20130327-1442 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.osgi # 3.9.0.v20130529-1710 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.osgi.services # 3.3.100.v20130513-1956 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.update.configurator # 3.3.200.v20130326-1319 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # Tidy # 1 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # com.lowagie.text # 2.1.7 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # derby # 10.5.1000001 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.bridge # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.css # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.dom # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.dom.svg # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.ext.awt # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.parser # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.svggen # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.transcoder # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.util # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.util.gui # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.xml # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xerces # 2.9.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xml.resolver # 1.2.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xml.serializer # 2.7.1 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.mozilla.javascript # 1.7.2 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.css.sac # 1.3.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.dom.smil # 1.0.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.dom.svg # 1.1.0 unrecognized Eclipse Public License - v 1.0 (https://www.eclipse.org/org/documents/epl-v10.php) org.eclipse.paho:org.eclipse.paho.client.mqttv3:1.2.0 unrecognized Eclipse Public License 1.0 (http://www.eclipse.org/legal/epl-v10.html) junit # junit # 4.12 unrecognized The W3C Software License (http://www.w3.org/Consortium/Legal/copyright-software-19980720) org.w3c.css # sac # 1.3 unrecognized The W3C Software License (http://www.w3.org/Consortium/Legal/copyright-software-19980720) com.vaadin.external.flute # flute # 1.3.0.gg2 unrecognized none specified (none specified) commons-net # commons-net # 3.3 unrecognized none specified (none specified) dom4j # dom4j # 1.6.1 unrecognized none specified (none specified) javax.activation # activation # 1.1.1 unrecognized none specified (none specified) milyn # flute # 1.3 unrecognized none specified (none specified) net.java.dev.jna # jna # 5.1.0 unrecognized none specified (none specified) org.apache.commons # commons-compress # 1.13 unrecognized none specified (none specified) org.codehaus.jettison # jettison # 1.3 unrecognized none specified (none specified) org.eclipse.birt.report.engine.emitter # csv # 1.0.0.201110121016 unrecognized none specified (none specified) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.pdf # 1.6.0 unrecognized none specified (none specified) org.slf4j # slf4j-api # 1.7.21 unrecognized none specified (none specified) org.vaadin.addons # aceeditor # 0.8.14 unrecognized none specified (none specified) org.vaadin.addons # ckeditor-wrapper-for-vaadin # 7.10.8 unrecognized none specified (none specified) org.vaadin.addons # legacycombobox # 0.1.4 unrecognized none specified (none specified) org.vaadin.addons # tokenfield # 7.0.1","title":"Third party software"},{"location":"User_Guide/Appendixes/Third_party_software.html#third-party-software","text":"The below table presents all third party libraries with their licenses. table { width: 90%; overflow-wrap: anywhere; word-break: break-all; Category License Dependency Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) joda-time # joda-time # 2.8.2 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.objenesis # objenesis # 2.1 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.snmp4j # snmp4j # 2.4.1 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.snmp4j # snmp4j-agent # 2.4.1 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0.html) com.typesafe.scala-logging # scala-logging_2.12 # 3.5.0 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.ftpserver # ftplet-api # 1.0.6 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.ftpserver # ftpserver-core # 1.0.6 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.mina # mina-core # 2.0.7 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.sshd # apache-sshd # 0.13.0 Apache Apache License (http://www.apache.org/licenses/LICENSE-2.0.txt) com.chuusai # shapeless_2.12 # 2.3.2 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin.external.google # guava # 16.0.1.vaadin1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin.external.streamhtmlparser # streamhtmlparser-jsilver # 0.0.10.vaadin1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-annotations # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-core # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-models # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-parser # 1.0.31 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) org.xerial.snappy # snappy-java # 1.1.7.1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) org.jgroups # jgroups # 4.0.15.Final Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-client # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-server # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-shared # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-shared-deps # 1.0.3 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe # config # 1.3.4 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe # ssl-config-core_2.12 # 0.2.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-actor_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-agent_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-slf4j_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-stream_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-testkit_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-cli # commons-cli # 1.3.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-codec # commons-codec # 1.10 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-collections # commons-collections # 3.2.2 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-eval_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-execution_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-reactive_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-types_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix_2.12 # 2.3.0 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) io.netty # netty-all # 4.1.27.Final Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) net.sf.supercsv # super-csv # 2.3.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.commons # commons-lang3 # 3.4 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.commons # commons-math3 # 3.6.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.jctools # jctools-core # 2.0.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.yaml # snakeyaml # 1.17 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-client # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-continuation # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-http # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-io # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-jmx # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-proxy # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-rewrite # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-security # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-server # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-servlet # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-servlets # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-util # 9.3.19.v20170502 Apache Apache Software License, Version 1.1 (http://www.apache.org/licenses/LICENSE-1.1) org.bouncycastle # bcpg-jdk15on # 1.51 Apache Apache Software Licenses (http://www.apache.org/licenses/LICENSE-2.0.txt) org.slf4j # log4j-over-slf4j # 1.7.21 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-macros_2.12 # 0.8.0-RC3 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-rest_2.12 # 0.8.0-RC3 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-utils_2.12 # 0.8.0-RC3 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-http-core_2.12 # 10.0.1 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-http_2.12 # 10.0.1 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-parsing_2.12 # 10.0.1 Apache Similar to Apache License but with the acknowledgment clause removed (https://raw.github.com/hunterhacker/jdom/master/LICENSE.txt) org.jdom # jdom2 # 2.0.6 Apache The Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.github.ghik # silencer-lib_2.12 # 1.4.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-annotations # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-core # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-databind # 2.8.7 Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.dataformat # jackson-dataformat-yaml # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.google.code.findbugs # jsr305 # 3.0.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.google.guava # guava # 21.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-io # commons-io # 2.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-lang # commons-lang # 2.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) io.prometheus.jmx # jmx_prometheus_javaagent # 0.12.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) javax.validation # validation-api # 1.1.0.Final Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.kafka # kafka-clients # 1.1.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.logging.log4j # log4j-api # 2.5 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.logging.log4j # log4j-to-slf4j # 2.5 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi-ooxml # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi-ooxml-schemas # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.velocity # velocity # 1.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.xmlbeans # xmlbeans # 2.3.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.codehaus.jackson # jackson-core-asl # 1.9.13 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.codehaus.jackson # jackson-mapper-asl # 1.9.13 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.jgroups.kubernetes # jgroups-kubernetes # 1.0.8.Final Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.lz4 # lz4-java # 1.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # bson # 3.11.2 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-async # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-core # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-legacy # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-reactivestreams # 1.12.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-sync # 3.11.2 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.quartz-scheduler # quartz # 2.2.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-aop # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-beans # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-context # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-context-support # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-core # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-expression # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-oxm # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-test # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-tx # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-web # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-webmvc # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-ws-core # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-ws-test # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-xml # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.typelevel # macro-compat_2.12 # 1.1.1 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) stax # stax-api # 1.0.1 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) tomcat # tomcat-apr # 5.5.23 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) xerces # xercesImpl # 2.9.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) xml-apis # xml-apis # 1.0.b2 BSD BSD (https://github.com/nbronson/scala-stm/blob/master/LICENSE.txt) org.scala-stm # scala-stm_2.12 # 0.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-compiler # 2.12.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-library # 2.12.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-reflect # 2.12.8 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.owasp.encoder # encoder # 1.2.2 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-java8-compat_2.12 # 1.1.1 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-parser-combinators_2.12 # 1.0.5 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-xml_2.12 # 1.0.6 BSD BSD License (http://xmlunit.svn.sourceforge.net/viewvc/ checkout /xmlunit/trunk/xmlunit/LICENSE.txt) xmlunit # xmlunit # 1.5 BSD BSD License (https://opensource.org/licenses/bsd-license.php) com.yahoo.platform.yui # yuicompressor # 2.4.8 BSD BSD style (http://xstream.codehaus.org/license.html) com.thoughtworks.xstream # xstream # 1.4.8 BSD BSD-style (http://www.opensource.org/licenses/bsd-license.php) org.scalacheck # scalacheck_2.12 # 1.13.4 BSD New BSD License (http://www.opensource.org/licenses/bsd-license.php) org.hamcrest # hamcrest-core # 1.3 BSD Revised BSD (http://www.jcraft.com/jsch/LICENSE.txt) com.jcraft # jsch # 0.1.55 BSD The BSD License (http://www.opensource.org/licenses/bsd-license.php) jline # jline # 2.14.6 BSD Two-clause BSD-style license (http://github.com/sbt/junit-interface/blob/master/LICENSE.txt) com.novocode # junit-interface # 0.11 CC0 CC0 (http://creativecommons.org/publicdomain/zero/1.0/) org.reactivestreams # reactive-streams # 1.0.2 CDDL COMMON DEVELOPMENT AND DISTRIBUTION LICENSE (CDDL) Version 1.1 (https://javaee.github.io/javamail/LICENSE) com.sun.mail # javax.mail # 1.4.5 CDDL COMMON DEVELOPMENT AND DISTRIBUTION LICENSE (CDDL) Version 1.1 (https://javaee.github.io/servlet-spec/LICENSE) javax.servlet # javax.servlet-api # 4.0.1 LGPL GNU LESSER GENERAL PUBLIC LICENSE (http://www.gnu.org/licenses/lgpl.txt) c3p0 # c3p0 # 0.9.1.1 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) ch.qos.logback # logback-classic # 1.1.8 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) ch.qos.logback # logback-core # 1.1.8 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) info.faljse # SDNotify # 1.3 MIT MIT (http://www.opensource.org/licenses/mit-license.html) com.lihaoyi # sourcecode_2.12 # 0.1.4 MIT MIT (https://opensource.org/licenses/MIT) org.scalamock # scalamock-core_2.12 # 3.5.0 MIT MIT (https://opensource.org/licenses/MIT) org.scalamock # scalamock-scalatest-support_2.12 # 3.5.0 MIT MIT (http://opensource.org/licenses/MIT) org.spire-math # jawn-parser_2.12 # 0.10.3 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) ch.qos.cal10n # cal10n-api # 0.7.4 MIT MIT License (http://www.slf4j.org/license.html) net.logstash.logback # logstash-logback-encoder # 4.6 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # jcl-over-slf4j # 1.7.21 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # jul-to-slf4j # 1.7.21 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # slf4j-ext # 1.6.3 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # derive_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # fastparse-utils_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # fastparse_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # scalaparse_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # upickle_2.12 # 0.4.4 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-annotations_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-core_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-jetty_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-macros_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-redis_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-shared_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-spring_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-core_2.12 # 1.20.19 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-macros_2.12 # 1.20.19 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-util_2.12 # 1.20.19 MIT The MIT License (http://jsoup.com/license) org.jsoup # jsoup # 1.8.3 MIT The MIT License (http://github.com/mockito/mockito/blob/master/LICENSE) org.mockito # mockito-core # 1.10.19 Mozilla MPL 1.1 (http://www.mozilla.org/MPL/MPL-1.1.html) org.javassist # javassist # 3.19.0-GA Mozilla MPL 1.1 (http://www.mozilla.org/MPL/MPL-1.1.html) rhino # js # 1.7R2 Public Domain Public Domain aopalliance # aopalliance # 1.0 Public Domain Public Domain (http://www.xmlpull.org/v1/download/unpacked/LICENSE.txt) xmlpull # xmlpull # 1.1.3.1 Public Domain Public Domain (http://creativecommons.org/licenses/publicdomain) xpp3 # xpp3_min # 1.1.4c unrecognized Bouncy Castle Licence (http://www.bouncycastle.org/licence.html) org.bouncycastle # bcpkix-jdk15on # 1.51 unrecognized Bouncy Castle Licence (http://www.bouncycastle.org/licence.html) org.bouncycastle # bcprov-jdk15on # 1.51 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # californium-core # 2.0.0-M18 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # californium-legal # 2.0.0-M18 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # scandium # 2.0.0-M18 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # com.ibm.icu # 50.1.1.v201304230130 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.apache.commons.logging # 1.1.1.v201101211721 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.birt.runtime # 4.3.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.contenttype # 3.4.200.v20130326-1255 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.expressions # 3.4.500.v20130515-1343 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.filesystem # 1.4.0.v20130514-1240 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.jobs # 3.5.300.v20130429-1813 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.resources # 3.8.100.v20130521-2026 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.runtime # 3.9.0.v20130326-1255 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity # 1.2.8.v201305301230 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.apache.derby # 1.0.103.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.apache.derby.dbdefinition # 1.0.2.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.console.profile # 1.0.10.v201109250955 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.db.generic # 1.0.1.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.dbdefinition.genericJDBC # 1.0.1.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda # 3.4.0.v201305170924 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.consumer # 3.2.6.v201305170644 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.design # 3.3.6.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.flatfile # 3.1.5.v201305221644 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.profile # 3.2.8.v201209080429 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.sqm.core # 1.2.6.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.hsqldb # 1.0.0.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.hsqldb.dbdefinition # 1.0.0.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.db2.luw # 1.0.2.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.db2.luw.dbdefinition # 1.0.4.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.informix # 1.0.1.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.informix.dbdefinition # 1.0.4.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.msft.sqlserver # 1.0.2.v201212120617 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.msft.sqlserver.dbdefinition # 1.0.1.v201201240505 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.mysql # 1.0.4.v201212120617 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.mysql.dbdefinition # 1.0.4.v201109022331 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oda.ws # 1.2.5.v201305031101 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oda.xml # 1.2.5.v201305031101 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oracle # 1.0.0.v201107221506 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oracle.dbdefinition # 1.0.103.v201206010214 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.postgresql # 1.1.1.v201205252207 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.postgresql.dbdefinition # 1.0.2.v201110070445 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.dbdefinition # 1.0.2.v201107221519 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.derby # 1.0.0.v201107221519 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.sql # 1.0.6.v201208230744 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.sql.query # 1.1.4.v201212120619 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf # 2.6.0.v20130610-0406 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.common # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore.change # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore.xmi # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.app # 1.3.100.v20130327-1442 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.common # 3.6.200.v20130402-1505 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.preferences # 3.5.100.v20130422-1538 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.registry # 3.5.300.v20130327-1442 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.osgi # 3.9.0.v20130529-1710 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.osgi.services # 3.3.100.v20130513-1956 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.update.configurator # 3.3.200.v20130326-1319 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # Tidy # 1 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # com.lowagie.text # 2.1.7 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # derby # 10.5.1000001 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.bridge # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.css # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.dom # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.dom.svg # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.ext.awt # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.parser # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.svggen # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.transcoder # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.util # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.util.gui # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.xml # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xerces # 2.9.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xml.resolver # 1.2.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xml.serializer # 2.7.1 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.mozilla.javascript # 1.7.2 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.css.sac # 1.3.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.dom.smil # 1.0.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.dom.svg # 1.1.0 unrecognized Eclipse Public License - v 1.0 (https://www.eclipse.org/org/documents/epl-v10.php) org.eclipse.paho:org.eclipse.paho.client.mqttv3:1.2.0 unrecognized Eclipse Public License 1.0 (http://www.eclipse.org/legal/epl-v10.html) junit # junit # 4.12 unrecognized The W3C Software License (http://www.w3.org/Consortium/Legal/copyright-software-19980720) org.w3c.css # sac # 1.3 unrecognized The W3C Software License (http://www.w3.org/Consortium/Legal/copyright-software-19980720) com.vaadin.external.flute # flute # 1.3.0.gg2 unrecognized none specified (none specified) commons-net # commons-net # 3.3 unrecognized none specified (none specified) dom4j # dom4j # 1.6.1 unrecognized none specified (none specified) javax.activation # activation # 1.1.1 unrecognized none specified (none specified) milyn # flute # 1.3 unrecognized none specified (none specified) net.java.dev.jna # jna # 5.1.0 unrecognized none specified (none specified) org.apache.commons # commons-compress # 1.13 unrecognized none specified (none specified) org.codehaus.jettison # jettison # 1.3 unrecognized none specified (none specified) org.eclipse.birt.report.engine.emitter # csv # 1.0.0.201110121016 unrecognized none specified (none specified) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.pdf # 1.6.0 unrecognized none specified (none specified) org.slf4j # slf4j-api # 1.7.21 unrecognized none specified (none specified) org.vaadin.addons # aceeditor # 0.8.14 unrecognized none specified (none specified) org.vaadin.addons # ckeditor-wrapper-for-vaadin # 7.10.8 unrecognized none specified (none specified) org.vaadin.addons # legacycombobox # 0.1.4 unrecognized none specified (none specified) org.vaadin.addons # tokenfield # 7.0.1","title":"Third party software"},{"location":"User_Guide/Extensions/Forwarding_notifications.html","text":"Forwarding notifications to a REST endpoint # Read this chapter to learn how to forward a message to a REST endpoint. To forward a notification: Go to Administration \u2014> Extensions . In the My custom REST template panel, click the Setup button. Configure your message: From a list of groups, select a group to which you want to forward a message. If you want to add a new group, click the click here link. Into the URL field, type an URL to which the message will be sent. You can use expressions inside the URL. From the HTTP method list, select a method you want to use. If you want to use basic authentication, into proper fields, type a username and a password. Into the Message content field, type the message that you want to forward in a JSON format. If you leave this field blank; then a default message (displayed in gray) will be forwarded. You can use Expressions : ${#path} - a placeholder for a path of a resource, instance or object that is observed. ${#value} - a placeholder for an observed value sent in the notification. Note ${#path} and ${#value} are valid JSONs so due to the format they cannot be in additional quotation marks (if they will, the format of the entire message will be invalid). Other expressions need to be inside quotation marks. Click the Confirm button. The properly configured task executes on a selected group of devices.","title":"Forwarding notifications to a REST endpoint"},{"location":"User_Guide/Extensions/Forwarding_notifications.html#forwarding-notifications-to-a-rest-endpoint","text":"Read this chapter to learn how to forward a message to a REST endpoint. To forward a notification: Go to Administration \u2014> Extensions . In the My custom REST template panel, click the Setup button. Configure your message: From a list of groups, select a group to which you want to forward a message. If you want to add a new group, click the click here link. Into the URL field, type an URL to which the message will be sent. You can use expressions inside the URL. From the HTTP method list, select a method you want to use. If you want to use basic authentication, into proper fields, type a username and a password. Into the Message content field, type the message that you want to forward in a JSON format. If you leave this field blank; then a default message (displayed in gray) will be forwarded. You can use Expressions : ${#path} - a placeholder for a path of a resource, instance or object that is observed. ${#value} - a placeholder for an observed value sent in the notification. Note ${#path} and ${#value} are valid JSONs so due to the format they cannot be in additional quotation marks (if they will, the format of the entire message will be invalid). Other expressions need to be inside quotation marks. Click the Confirm button. The properly configured task executes on a selected group of devices.","title":"Forwarding notifications to a REST endpoint"},{"location":"User_Guide/Extensions/Integrating_with_Coiote_IoT_Data_Orchestration.html","text":"Integrating with Coiote IoT Data Orchestration # Read this chapter to learn how to integrate with Coiote IoT Data Orchestration to manage data retrieved from devices and telemetry channels. To integrate with Coiote IoT Data Orchestration: Go to Administration \u2014> Extensions . In the Coiote IoT Data Orchestration panel, click the Setup button. Copy all data found on the pop-up because you will need it later. Paste copied data to the Coiote IoT Data Orchestration platform and click the Connect button. The integration process will be done by the Coiote IoT Data Orchestration platform.","title":"Integrating with Coiote IoT Data Orchestration"},{"location":"User_Guide/Extensions/Integrating_with_Coiote_IoT_Data_Orchestration.html#integrating-with-coiote-iot-data-orchestration","text":"Read this chapter to learn how to integrate with Coiote IoT Data Orchestration to manage data retrieved from devices and telemetry channels. To integrate with Coiote IoT Data Orchestration: Go to Administration \u2014> Extensions . In the Coiote IoT Data Orchestration panel, click the Setup button. Copy all data found on the pop-up because you will need it later. Paste copied data to the Coiote IoT Data Orchestration platform and click the Connect button. The integration process will be done by the Coiote IoT Data Orchestration platform.","title":"Integrating with Coiote IoT Data Orchestration"},{"location":"User_Guide/Extensions/Integrating_with_the_ThingWorx_platform.html","text":"Integrating with the ThingWorx platform # To integrate with ThingWorx, read the attached instruction: the LwM2M ThingWorx extension user guide .","title":"Integrating with the ThingWorx platform"},{"location":"User_Guide/Extensions/Integrating_with_the_ThingWorx_platform.html#integrating-with-the-thingworx-platform","text":"To integrate with ThingWorx, read the attached instruction: the LwM2M ThingWorx extension user guide .","title":"Integrating with the ThingWorx platform"},{"location":"User_Guide/Extensions/Registration_status_action.html","text":"Setting up registration status action # The registration status action extension lets you configure actions performed on the lists of registered and deregistered devices. Read the instructions below to learn how to set them up. To configure the registration status action extension: Go to Administration \u2014> Extensions . In the Devices registration status action panel, click the Setup button. In the window that appears, configure your action: In the Edit tab, define your action logic. The lists of registered and deregistered devices are available in the ${args.registeredDevices} and ${args.deregisteredDevices} expression contexts. Note Each newly executed action is performed on the list of devices that have registered/deregistered within the defined interval. Note that if the action execution fails, it will be retried within the subsequent time interval. You can also specify how often the status of registered/deregistered devices should be checked and updated using the time interval and time unit dropdowns. After you have configured your registration status action, click Save . Action execution will start immediately. If you want to check the status of execution of your configured action, go to the Execution logs tab. Example setup # Assuming that your config directory is called my-config : Create file my-config/entities/carp.conf : entities { \"com.avsystem.ump.core.db.entities.carp.Carp\" { \"/DevicesRegistrationStatus\" = { \"hook\" : \"DevicesRegistrationStatus\" \"definition\" : \"\"\"<config><log message=\"Hello!\" /></config>\"\"\" domain: \"/\" logLevel = 3 properties { jobIntervalTimeSeconds : \"60\" } } } } Add the following to my-config/beans.conf: commonEntitiesList += ${abstractDataTransceiverEntry}{ importOption = ADD_NEW_AND_UPDATE_EXISTING map.\"com.avsystem.ump.core.db.entities.carp.Carp\" = /my-config/entities/carp.conf } Warning Note that you need to adjust my-config inside! Optionally, you can adjust the following entries in my-config/cdm.conf to your liking: smg.mod.dataTransceiver { carpRegistrationStatusPostImportHook { # After a CARP is imported, the fist execution of the CARP job # will be delayed by a random duration between the two provided # This is meant as a form of preventing many computation- and I/O- # intensive tasks from executing at once during system startup # You can set both to the same value to eliminate randomness # Or set both to \"0s\" to disable delay minimalInitialDelay = 20s maximalInitialDelay = 2min } }","title":"Setting up registration status action"},{"location":"User_Guide/Extensions/Registration_status_action.html#setting-up-registration-status-action","text":"The registration status action extension lets you configure actions performed on the lists of registered and deregistered devices. Read the instructions below to learn how to set them up. To configure the registration status action extension: Go to Administration \u2014> Extensions . In the Devices registration status action panel, click the Setup button. In the window that appears, configure your action: In the Edit tab, define your action logic. The lists of registered and deregistered devices are available in the ${args.registeredDevices} and ${args.deregisteredDevices} expression contexts. Note Each newly executed action is performed on the list of devices that have registered/deregistered within the defined interval. Note that if the action execution fails, it will be retried within the subsequent time interval. You can also specify how often the status of registered/deregistered devices should be checked and updated using the time interval and time unit dropdowns. After you have configured your registration status action, click Save . Action execution will start immediately. If you want to check the status of execution of your configured action, go to the Execution logs tab.","title":"Setting up registration status action"},{"location":"User_Guide/Extensions/Registration_status_action.html#example-setup","text":"Assuming that your config directory is called my-config : Create file my-config/entities/carp.conf : entities { \"com.avsystem.ump.core.db.entities.carp.Carp\" { \"/DevicesRegistrationStatus\" = { \"hook\" : \"DevicesRegistrationStatus\" \"definition\" : \"\"\"<config><log message=\"Hello!\" /></config>\"\"\" domain: \"/\" logLevel = 3 properties { jobIntervalTimeSeconds : \"60\" } } } } Add the following to my-config/beans.conf: commonEntitiesList += ${abstractDataTransceiverEntry}{ importOption = ADD_NEW_AND_UPDATE_EXISTING map.\"com.avsystem.ump.core.db.entities.carp.Carp\" = /my-config/entities/carp.conf } Warning Note that you need to adjust my-config inside! Optionally, you can adjust the following entries in my-config/cdm.conf to your liking: smg.mod.dataTransceiver { carpRegistrationStatusPostImportHook { # After a CARP is imported, the fist execution of the CARP job # will be delayed by a random duration between the two provided # This is meant as a form of preventing many computation- and I/O- # intensive tasks from executing at once during system startup # You can set both to the same value to eliminate randomness # Or set both to \"0s\" to disable delay minimalInitialDelay = 20s maximalInitialDelay = 2min } }","title":"Example setup"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module.html","text":"Monitoring # The Monitoring module is responsible for collecting historical data about devices' state as well as providing rich user interface for browsing such information. Device's state is usually expressed by a subset of its data model parameters values, which are selected either if they expresses devices performance or their usability for analysis. There are separate sets of specific properties suitable for DSL or WiMAX devices as well as common ones, such as link consumption and connection latency. Composing those areas you can get a full picture. Sampling interval is the most often expressed by devices periodic interval - as a result, state is logged every periodic session. The module is able to aggregate data from multiple devices. For every group of devices, which has monitoring enabled, samples from all devices, which belong to it are aggregated providing high-level statistics. In contrast to device's state history, which provides exact information about properties value, associated with event time, aggregates provide accumulated values disjointed from exact event time, but available at different levels of granularity. Every property being under monitoring is called a monitoring resource. Depending on its content it can have a numerical or textual type: Numerical resources are used when values such as signal strength, transferred bytes or packet loss come into consideration. Aggregated provides such metrics as an average value and standard deviation. Textual resources, besides obvious usage for tracing, for example, PPP username, can be used for enumerable values, for example, enabled, disabled or beacon type. During aggregation, for each encountered value, hit count is available. Another type of resources are alerts, which are used for signaling occurrences of interesting events or classifying devices state. They introduce some added logic in order to help you detect abnormal situations. They are divided into: One shot alerts - an event occurrence is logged, this type relates to, for example, PPP username, modulation type, Wi-Fi SSID change. Stateful alerts - they have two states: raised and hidden. They express state persistence, for example, noise margin exceeded alert is raised all the time connection noise margin exceeds a configured threshold. Data collection frequency # In order to provide statistics with desired granularity, monitoring introduces a concept of a sampling interval - a time period during which one sample should be collected. On the other hand, it prevents excessive storage usage - only one sample per sampling interval is stored. As samples collection usually occurs during a device's periodic visit, monitoring ensures the sampling interval by lowering, if it is required, the device's periodic interval too meet mentioned requirements. Giving examples: Monitoring interval: 180s, periodic interval: 60s - during 180s 3 periodic visits occur, only one monitoring sample is collected, a periodic interval is not modified. Monitoring interval: 180s, periodic interval: 600s - periodic interval is lowered to 180s in order to ensure at least one sample is collected every 180s. Aggregates storage manages samples collection differently. There is always a constant number of aggregates as they should be pre-allocated in order to store events that may occur on devices. They are broken down into multiple levels: minute, hour, day; values from a finery-grained level applies to a coarser-level aggregate. Finer level aggregates are available only for the most recent time frame, the rationale for this is to provide detailed information only for the latest data, optimizing storage space simultaneously. Retention time is: Minute - for the last 24 hours Hour - for the last week. Example: Group contains Device 1 (D1, periodic 20 min) and Device 2 (D2, periodic 30 min), the sampling interval is equal to 30 minutes. Numerical values reported by devices are v1 & v2. Through an hour following events occur: 14 Periodic Samples collection Minute aggregated value hour Aggregate value :00 -- collection window 0 0 :01 D1, D2 periodic D1, D2 v1 + v2 v1 + v2 :16 D1 periodic -- 0 v1 + v2 :21 D2 periodic -- 0 v1 + v2 :30 -- collection window 0 v1 + v2 :31 D1 periodic D1 v1 2 * v1 + v2 :41 D2 periodic D2 v2 2 * v1 + 2 * v2 :46 D1 periodic -- 0 2 * v1 + 2 * v2 :60 -- collection window 0 2 * v1 + 2 * v2 Summary: Device 1 - 2 samples - 14:01, 14:31, Device 2 - 2 samples - 14:01, 14:41, Minute aggregates - there are 60 aggregates per each minute, from which 3 have non-zero value: 14:01. 14:31, 14:41, Hour aggregate - there is 1, which has accumulated value: 2 * v1 + 2 * v2. Target selection # You have to choose, which devices you want to monitor by selecting monitoring groups. Every device, which belongs to any of selected groups or their sub-groups is under monitoring. The same applies to aggregate storage, group scoped statistics are available for all selected groups and their sub-groups. Given such a hierarchy: root |-- lwm2m | |-- dsl | | |-- firmware v1 (D1) | | |-- firmware v2 (D2) | +-- adsl | |-- firmware v4 (D3) | |-- firmware v5 +-- devicetypes |-- manufacturer 1 |-- manufacturer 2 (D1, D2) |-- manufacturer 3 (D3) Selection of root.lwm2m.dsl and root.lwm2m.adsl groups as monitoring groups results in device samples collection for all devices (D1, D2, D3) and aggregates storage for all groups in the hierarchy. Samples will be collected in all groups including devices D1, D2, D3. Determining a group set where aggregates are available might be a resource consuming task, as every monitored devices group set should be checked. Enter a monitoring group view to see available monitoring types for which data is available. They are divided into two groups: Group monitoring - presented for groups (and their sub-groups) directly chosen as monitoring groups, taken into consideration when calculating monitored devices set. Other monitoring - all other monitoring types configured in the system, for which aggregates might exist. Target exclusion # As aggregates are stored separately for every group under monitoring, in case there exist multi-level, wide hierarchy it may lead to excessive storage consumption. Let us consider a situation where devices are grouped by their location into country - region - city - area hierarchy. In such case, area level may not be very useful as it aggregates data from a few devices can be excluded from monitored groups in order to reduce required storage space. It is accomplished by usage of exclusion \ufeffpatterns expressed as a Java programming language regular expression. If a group name matches any of configured expressions, it will be excluded from monitoring. For hierarchy from previous paragraph, selection of root.lwm2m results in device samples collection for devices and aggregates storage for: root.lwm2m root.lwm2m.dsl root.lwm2m.dsl.firmware v1 root.lwm2m.dsl.firmware v2 root.lwm2m.adsl root.lwm2m.adsl.firmware v4 root.lwm2m.adsl.firmware v5 Application of exclusion pattern: root\\.lwm2m\\..* reduces the monitored group set to group root.lwm2m. See also: Monitoring configuration Specific settings for monitoring Adding monitoring Browsing monitoring results Monitoring map","title":"Monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module.html#monitoring","text":"The Monitoring module is responsible for collecting historical data about devices' state as well as providing rich user interface for browsing such information. Device's state is usually expressed by a subset of its data model parameters values, which are selected either if they expresses devices performance or their usability for analysis. There are separate sets of specific properties suitable for DSL or WiMAX devices as well as common ones, such as link consumption and connection latency. Composing those areas you can get a full picture. Sampling interval is the most often expressed by devices periodic interval - as a result, state is logged every periodic session. The module is able to aggregate data from multiple devices. For every group of devices, which has monitoring enabled, samples from all devices, which belong to it are aggregated providing high-level statistics. In contrast to device's state history, which provides exact information about properties value, associated with event time, aggregates provide accumulated values disjointed from exact event time, but available at different levels of granularity. Every property being under monitoring is called a monitoring resource. Depending on its content it can have a numerical or textual type: Numerical resources are used when values such as signal strength, transferred bytes or packet loss come into consideration. Aggregated provides such metrics as an average value and standard deviation. Textual resources, besides obvious usage for tracing, for example, PPP username, can be used for enumerable values, for example, enabled, disabled or beacon type. During aggregation, for each encountered value, hit count is available. Another type of resources are alerts, which are used for signaling occurrences of interesting events or classifying devices state. They introduce some added logic in order to help you detect abnormal situations. They are divided into: One shot alerts - an event occurrence is logged, this type relates to, for example, PPP username, modulation type, Wi-Fi SSID change. Stateful alerts - they have two states: raised and hidden. They express state persistence, for example, noise margin exceeded alert is raised all the time connection noise margin exceeds a configured threshold.","title":"Monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module.html#data-collection-frequency","text":"In order to provide statistics with desired granularity, monitoring introduces a concept of a sampling interval - a time period during which one sample should be collected. On the other hand, it prevents excessive storage usage - only one sample per sampling interval is stored. As samples collection usually occurs during a device's periodic visit, monitoring ensures the sampling interval by lowering, if it is required, the device's periodic interval too meet mentioned requirements. Giving examples: Monitoring interval: 180s, periodic interval: 60s - during 180s 3 periodic visits occur, only one monitoring sample is collected, a periodic interval is not modified. Monitoring interval: 180s, periodic interval: 600s - periodic interval is lowered to 180s in order to ensure at least one sample is collected every 180s. Aggregates storage manages samples collection differently. There is always a constant number of aggregates as they should be pre-allocated in order to store events that may occur on devices. They are broken down into multiple levels: minute, hour, day; values from a finery-grained level applies to a coarser-level aggregate. Finer level aggregates are available only for the most recent time frame, the rationale for this is to provide detailed information only for the latest data, optimizing storage space simultaneously. Retention time is: Minute - for the last 24 hours Hour - for the last week. Example: Group contains Device 1 (D1, periodic 20 min) and Device 2 (D2, periodic 30 min), the sampling interval is equal to 30 minutes. Numerical values reported by devices are v1 & v2. Through an hour following events occur: 14 Periodic Samples collection Minute aggregated value hour Aggregate value :00 -- collection window 0 0 :01 D1, D2 periodic D1, D2 v1 + v2 v1 + v2 :16 D1 periodic -- 0 v1 + v2 :21 D2 periodic -- 0 v1 + v2 :30 -- collection window 0 v1 + v2 :31 D1 periodic D1 v1 2 * v1 + v2 :41 D2 periodic D2 v2 2 * v1 + 2 * v2 :46 D1 periodic -- 0 2 * v1 + 2 * v2 :60 -- collection window 0 2 * v1 + 2 * v2 Summary: Device 1 - 2 samples - 14:01, 14:31, Device 2 - 2 samples - 14:01, 14:41, Minute aggregates - there are 60 aggregates per each minute, from which 3 have non-zero value: 14:01. 14:31, 14:41, Hour aggregate - there is 1, which has accumulated value: 2 * v1 + 2 * v2.","title":"Data collection frequency"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module.html#target-selection","text":"You have to choose, which devices you want to monitor by selecting monitoring groups. Every device, which belongs to any of selected groups or their sub-groups is under monitoring. The same applies to aggregate storage, group scoped statistics are available for all selected groups and their sub-groups. Given such a hierarchy: root |-- lwm2m | |-- dsl | | |-- firmware v1 (D1) | | |-- firmware v2 (D2) | +-- adsl | |-- firmware v4 (D3) | |-- firmware v5 +-- devicetypes |-- manufacturer 1 |-- manufacturer 2 (D1, D2) |-- manufacturer 3 (D3) Selection of root.lwm2m.dsl and root.lwm2m.adsl groups as monitoring groups results in device samples collection for all devices (D1, D2, D3) and aggregates storage for all groups in the hierarchy. Samples will be collected in all groups including devices D1, D2, D3. Determining a group set where aggregates are available might be a resource consuming task, as every monitored devices group set should be checked. Enter a monitoring group view to see available monitoring types for which data is available. They are divided into two groups: Group monitoring - presented for groups (and their sub-groups) directly chosen as monitoring groups, taken into consideration when calculating monitored devices set. Other monitoring - all other monitoring types configured in the system, for which aggregates might exist.","title":"Target selection"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module.html#target-exclusion","text":"As aggregates are stored separately for every group under monitoring, in case there exist multi-level, wide hierarchy it may lead to excessive storage consumption. Let us consider a situation where devices are grouped by their location into country - region - city - area hierarchy. In such case, area level may not be very useful as it aggregates data from a few devices can be excluded from monitored groups in order to reduce required storage space. It is accomplished by usage of exclusion \ufeffpatterns expressed as a Java programming language regular expression. If a group name matches any of configured expressions, it will be excluded from monitoring. For hierarchy from previous paragraph, selection of root.lwm2m results in device samples collection for devices and aggregates storage for: root.lwm2m root.lwm2m.dsl root.lwm2m.dsl.firmware v1 root.lwm2m.dsl.firmware v2 root.lwm2m.adsl root.lwm2m.adsl.firmware v4 root.lwm2m.adsl.firmware v5 Application of exclusion pattern: root\\.lwm2m\\..* reduces the monitored group set to group root.lwm2m. See also: Monitoring configuration Specific settings for monitoring Adding monitoring Browsing monitoring results Monitoring map","title":"Target exclusion"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_a_single_parameter_on_a_device.html","text":"Monitoring a single parameter on a device # Read this chapter to learn how to monitor a single parameter on one device. To monitor a parameter: Go to Device inventory . From the list of devices, select a proper device. Go to the Objects tab. Find a parameter you want to monitor, and click the Value tracking button. From the Select mode list, select Monitoring (collect data) . To limit data usage, click the Limit data usage link and select proper check boxes. Click the Set tracking button. As a result, the Observe request is sent to the device and notifications (results) are saved in the database and their history is visible on the chart. Tip To view results of monitoring , click the Value tracking button. To stop monitoring, click the Value tracking button, go to the Settings tab, and click the Delete tracking link. Keep in mind, that if you stop monitoring then its results will not be saved and visible on the chart anymore.","title":"Monitoring a single parameter on a device"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_a_single_parameter_on_a_device.html#monitoring-a-single-parameter-on-a-device","text":"Read this chapter to learn how to monitor a single parameter on one device. To monitor a parameter: Go to Device inventory . From the list of devices, select a proper device. Go to the Objects tab. Find a parameter you want to monitor, and click the Value tracking button. From the Select mode list, select Monitoring (collect data) . To limit data usage, click the Limit data usage link and select proper check boxes. Click the Set tracking button. As a result, the Observe request is sent to the device and notifications (results) are saved in the database and their history is visible on the chart. Tip To view results of monitoring , click the Value tracking button. To stop monitoring, click the Value tracking button, go to the Settings tab, and click the Delete tracking link. Keep in mind, that if you stop monitoring then its results will not be saved and visible on the chart anymore.","title":"Monitoring a single parameter on a device"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html","text":"Reporting # This document describes the reporting module. In this module you can find information about: Viewing and scheduling reports Managing reports templates Configuring reports Reports # In this tab you can view all scheduled reports and their results. Reports search input - you can filter reports by a column from a table. You can select a filtering column by clicking the icon in the table header. The table contains most important information about scheduled reports: - a report was generated successfully - a generation process is not finished yet - there were some problems with the report generation Configuration - you can read more about a configuration in the Reporting configuration details section. Buttons: Delete - use it to delete a report. Warning Reports are deleted without confirmation. If you click the Delete button, then the report will be deleted immediately. Remove all results - use it to delete all files generated by report executions. Warning Results are deleted without confirmation. If you click the Remove all results button, then report results will be deleted immediately. Modify - use it to modify a report. Create similar - use it to quickly create a new report on the basis of the report you view. Results - use it to find all results files and to download them. Schedule report # Reports can be customized in many ways. Read a short description of a layout and a detailed description of a configuration with examples. Layout # Title - use it to name a report. Template selection - use it to select a template of a report. You can find more about templates in the Templates section. Schedule - use it to select when the report will be created: Immediate - use it to generate a report as soon as possible. Single execution - use it to generate a report once on selected date. Periodic execution - use it to generate a report periodically. Time interval - use it to select a period from which data will be used to generate the report. Output - use it to select a format of the report, for example, PDF, HTML or CSV. Transfers - use it to select how the generated report will be sent, for example, by email or uploaded to a remote server using FTP, SFTP or SCP. Parameters - use it to set detailed parameters of the report. Retention policy - use it to set rules of cleaning up old report files. Schedule - use this button to schedule a report. Reporting configuration details # This part describes the report configuration in details. Template selection # There is a lot of templates you can select to generate the report. All templates are grouped in categories, for example: General Report - reports connected with general information about users and devices. Hosted - a report for clients of the Coiote DM Cloud installation. Monitoring reports - all reports based on monitoring. Inactivity reports . The selected template can impact possible options in other sections of configuration. Schedule # There are three types of a report execution schedule: Immediate - a report will be generated only once as soon as possible. Single execution - the report will be generated once on a selected date, you can select any future date. Periodic execution - the report will be generated every selected time period: Monthly - on a selected day of a month and time of the day. Be careful with selecting the last day of a month, for example, February has only 28/29 days. Weekly - on a selected day of a week and time of the day. Daily - everyday on selected time. Time interval # This part defines a time period that will be taken to the report. There are two ways of selecting it: Sliding window - this option is useful for periodic reports, you can select interval relatively to generation time, for example, last 6 hours, last month. Custom - you can select custom time, for example, 8 days 2 hours and 15 minutes. Start and End date - a fixed time period, useful for a single execution. Output # You can select an output type for the report. Possible formats may differ between report templates. Usually you can use: CSV, DOC, HTML, PDF, PPT or XLS. Transfers # Beside downloading report files, you can use four transport mechanisms (you need to select the Use check box to activate this option): Email - after every execution, results will be sent to added emails. FTP - results will be uploaded to a provided server using the FTP protocol. SFTP - results will be uploaded to the provided server using the SFTP protocol. SCP - results will be uploaded to the provided server using the SCP protocol. In FTP/SFTP/SCP you can select Add date to generated file name check box, than every transferred file will have a generation date added at a beginning of a file name. If you do not select this option, then newer files will be overridden by older ones. To eliminate any problems with file names, since the 16.01 version an additional setting was added in cdm.conf : reports.replaceForbiddenChars=true By default it is set to true , and it replaces all forbidden characters with proper ones. For example, a report title is FAP Node H CPE and its file name was generated in versions previous to 16.01 as FAP Node H CPE and now it will be FAP_Node_H_Group . Tip Remember that a user password provided in this form is not encrypted. Parameters # Content of this part depends on a selected report template. Usually you can find device or group selection, monitoring ID selection for monitoring based reports. Retention policy # You can set two parameters: Remove reports older than - all report files older than a provided number of days will be removed (default: 14 days). Number of files to retain - if report executions will generate more files than a provided number (default: 30), then the system will remove all beside the newest number. Note This rules concern only local report files, they do not affect files uploaded to a remote server using the Transfers feature. Templates # Here you can read more about report templates and a panel to manage them. Layout # Report templates - use it to browse through all report templates. Additionally, you can download, delete or check their details. If a report template has an invalid file format, then you will see information Invalid file in the `Structure column. What is more, you will not be able to use this template while scheduling a report. Add new template - use it to open a creation form. Check Custom templates section for more details. When you select the report template from a table, an edition form will open. It looks exactly the same as the creation form. Custom templates creation # Look at the list below to find information about creating custom report templates. Save - use it to save changes. Cancel - use it to discard all changes. Template title - use it to set a name of a template. Template category - use it to set a category from which the template will be accessible. File name - use it to set a name of a file with the template. Required permission - use it to select a permission that will be required to use the template. This field is optional. Monitoring report - use it to indicate if the template is based on monitoring. Monitoring type - if the template is based on monitoring, then you should select which one. Upload - use this button to upload the report template file. A template file must be in a .rptdesign or .cft format. If you try to upload the file in another format, then you will see information that a structure is invalid and you will not be able to save this template. There is a limit regarding a size of the report template, information about it is displayed when you try to upload the bigger file than allowed. If needed, you can change the limit in the configuration file. To learn how to do this, please refer to the Admin Guide, Changing the size of a report template section. Reports configuration # This panel allows you to configure default reports properties and make scheduling of new reports faster. Preferences target - use it to select if this settings should be visible only for you ( Current user ) or for everyone in UMP. Output - use it to select default output formats. You can use CSV, DOC, HTML, PDF, PPT or XLS. Email address - use it to add email addresses to which reports will be sent. Default retention policy - look at the Retention policy section for details. Save - click it to save changes in default reports settings.","title":"Reporting"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#reporting","text":"This document describes the reporting module. In this module you can find information about: Viewing and scheduling reports Managing reports templates Configuring reports","title":"Reporting"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#reports","text":"In this tab you can view all scheduled reports and their results. Reports search input - you can filter reports by a column from a table. You can select a filtering column by clicking the icon in the table header. The table contains most important information about scheduled reports: - a report was generated successfully - a generation process is not finished yet - there were some problems with the report generation Configuration - you can read more about a configuration in the Reporting configuration details section. Buttons: Delete - use it to delete a report. Warning Reports are deleted without confirmation. If you click the Delete button, then the report will be deleted immediately. Remove all results - use it to delete all files generated by report executions. Warning Results are deleted without confirmation. If you click the Remove all results button, then report results will be deleted immediately. Modify - use it to modify a report. Create similar - use it to quickly create a new report on the basis of the report you view. Results - use it to find all results files and to download them.","title":"Reports"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#schedule-report","text":"Reports can be customized in many ways. Read a short description of a layout and a detailed description of a configuration with examples.","title":"Schedule report"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#layout","text":"Title - use it to name a report. Template selection - use it to select a template of a report. You can find more about templates in the Templates section. Schedule - use it to select when the report will be created: Immediate - use it to generate a report as soon as possible. Single execution - use it to generate a report once on selected date. Periodic execution - use it to generate a report periodically. Time interval - use it to select a period from which data will be used to generate the report. Output - use it to select a format of the report, for example, PDF, HTML or CSV. Transfers - use it to select how the generated report will be sent, for example, by email or uploaded to a remote server using FTP, SFTP or SCP. Parameters - use it to set detailed parameters of the report. Retention policy - use it to set rules of cleaning up old report files. Schedule - use this button to schedule a report.","title":"Layout"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#reporting-configuration-details","text":"This part describes the report configuration in details.","title":"Reporting configuration details"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#template-selection","text":"There is a lot of templates you can select to generate the report. All templates are grouped in categories, for example: General Report - reports connected with general information about users and devices. Hosted - a report for clients of the Coiote DM Cloud installation. Monitoring reports - all reports based on monitoring. Inactivity reports . The selected template can impact possible options in other sections of configuration.","title":"Template selection"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#schedule","text":"There are three types of a report execution schedule: Immediate - a report will be generated only once as soon as possible. Single execution - the report will be generated once on a selected date, you can select any future date. Periodic execution - the report will be generated every selected time period: Monthly - on a selected day of a month and time of the day. Be careful with selecting the last day of a month, for example, February has only 28/29 days. Weekly - on a selected day of a week and time of the day. Daily - everyday on selected time.","title":"Schedule"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#time-interval","text":"This part defines a time period that will be taken to the report. There are two ways of selecting it: Sliding window - this option is useful for periodic reports, you can select interval relatively to generation time, for example, last 6 hours, last month. Custom - you can select custom time, for example, 8 days 2 hours and 15 minutes. Start and End date - a fixed time period, useful for a single execution.","title":"Time interval"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#output","text":"You can select an output type for the report. Possible formats may differ between report templates. Usually you can use: CSV, DOC, HTML, PDF, PPT or XLS.","title":"Output"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#transfers","text":"Beside downloading report files, you can use four transport mechanisms (you need to select the Use check box to activate this option): Email - after every execution, results will be sent to added emails. FTP - results will be uploaded to a provided server using the FTP protocol. SFTP - results will be uploaded to the provided server using the SFTP protocol. SCP - results will be uploaded to the provided server using the SCP protocol. In FTP/SFTP/SCP you can select Add date to generated file name check box, than every transferred file will have a generation date added at a beginning of a file name. If you do not select this option, then newer files will be overridden by older ones. To eliminate any problems with file names, since the 16.01 version an additional setting was added in cdm.conf : reports.replaceForbiddenChars=true By default it is set to true , and it replaces all forbidden characters with proper ones. For example, a report title is FAP Node H CPE and its file name was generated in versions previous to 16.01 as FAP Node H CPE and now it will be FAP_Node_H_Group . Tip Remember that a user password provided in this form is not encrypted.","title":"Transfers"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#parameters","text":"Content of this part depends on a selected report template. Usually you can find device or group selection, monitoring ID selection for monitoring based reports.","title":"Parameters"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#retention-policy","text":"You can set two parameters: Remove reports older than - all report files older than a provided number of days will be removed (default: 14 days). Number of files to retain - if report executions will generate more files than a provided number (default: 30), then the system will remove all beside the newest number. Note This rules concern only local report files, they do not affect files uploaded to a remote server using the Transfers feature.","title":"Retention policy"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#templates","text":"Here you can read more about report templates and a panel to manage them.","title":"Templates"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#layout_1","text":"Report templates - use it to browse through all report templates. Additionally, you can download, delete or check their details. If a report template has an invalid file format, then you will see information Invalid file in the `Structure column. What is more, you will not be able to use this template while scheduling a report. Add new template - use it to open a creation form. Check Custom templates section for more details. When you select the report template from a table, an edition form will open. It looks exactly the same as the creation form.","title":"Layout"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#custom-templates-creation","text":"Look at the list below to find information about creating custom report templates. Save - use it to save changes. Cancel - use it to discard all changes. Template title - use it to set a name of a template. Template category - use it to set a category from which the template will be accessible. File name - use it to set a name of a file with the template. Required permission - use it to select a permission that will be required to use the template. This field is optional. Monitoring report - use it to indicate if the template is based on monitoring. Monitoring type - if the template is based on monitoring, then you should select which one. Upload - use this button to upload the report template file. A template file must be in a .rptdesign or .cft format. If you try to upload the file in another format, then you will see information that a structure is invalid and you will not be able to save this template. There is a limit regarding a size of the report template, information about it is displayed when you try to upload the bigger file than allowed. If needed, you can change the limit in the configuration file. To learn how to do this, please refer to the Admin Guide, Changing the size of a report template section.","title":"Custom templates creation"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#reports-configuration","text":"This panel allows you to configure default reports properties and make scheduling of new reports faster. Preferences target - use it to select if this settings should be visible only for you ( Current user ) or for everyone in UMP. Output - use it to select default output formats. You can use CSV, DOC, HTML, PDF, PPT or XLS. Email address - use it to add email addresses to which reports will be sent. Default retention policy - look at the Retention policy section for details. Save - click it to save changes in default reports settings.","title":"Reports configuration"},{"location":"User_Guide/Monitoring_and_Reporting/Reports_descriptions.html","text":"Reports descriptions # Read this section to learn what reports are available in the system and what they display. Look at the table below to find out more. You can access all reports from Monitoring & Reporting \u2014> Reports . To generate a report go to the Schedule report tab. Name Category Description IP CSV Report General reports The report shows a history of IP changes of devices in a selected group and a period of time. Advanced CSV Report Monitoring reports The report shows selected monitoring data prepared by you in Administration \u2014> CSV Import/Export templates .","title":"Reports descriptions"},{"location":"User_Guide/Monitoring_and_Reporting/Reports_descriptions.html#reports-descriptions","text":"Read this section to learn what reports are available in the system and what they display. Look at the table below to find out more. You can access all reports from Monitoring & Reporting \u2014> Reports . To generate a report go to the Schedule report tab. Name Category Description IP CSV Report General reports The report shows a history of IP changes of devices in a selected group and a period of time. Advanced CSV Report Monitoring reports The report shows selected monitoring data prepared by you in Administration \u2014> CSV Import/Export templates .","title":"Reports descriptions"},{"location":"User_Guide/Monitoring_and_Reporting/Scheduling_Advanced_CSV_Report.html","text":"Scheduling advanced CSV Report # Read this section to learn how to schedule the report using the monitoring data export configuration prepared in Administration \u2014> CSV Import/Export templates . Prerequisites: In order to control report execution parallelism, the used thread pool size can be set in the cdm.conf file in the smg.mod.gui.reportPoolSize=4 setting. Warning Use of many threads speeds up report execution but at the same time it can cause database write contention for regular provisioning. That is why you should balance properly execution and operational performance. To schedule the report: Go to Monitoring & Reporting \u2014> Reports . Go to the Schedule report tab. In the Template selection panel: From the Category list, select Monitoring reports . From the Report template list, select Advanced CSV Report . Configure settings such as a schedule, time interval, transfer and retention policy. Read how to configure these settings in the Reporting chapter. In the Parameters panel: Click the Select group link and from the list select a group on which you want to schedule the report. Note Keep in mind, that the system will include only the devices that are in the selected group when next scheduled generation starts. Even if you delete a device from the group while the report is in progress, it will be included. Optional: Type an expression to schedule the report only on devices that fulfill the specified condition. Select one of export types: Raw Aggregated From the list select a monitoring data export configuration. Click the Schedule button. Tip Apart from having proper data in the generated report, you can also come across the below cases: An empty space instead of some data because there was no data to present. The - sign instead of data because there was no aggregation to present. See also: Adding CSV monitoring data export configurations","title":"Scheduling advanced CSV Report"},{"location":"User_Guide/Monitoring_and_Reporting/Scheduling_Advanced_CSV_Report.html#scheduling-advanced-csv-report","text":"Read this section to learn how to schedule the report using the monitoring data export configuration prepared in Administration \u2014> CSV Import/Export templates . Prerequisites: In order to control report execution parallelism, the used thread pool size can be set in the cdm.conf file in the smg.mod.gui.reportPoolSize=4 setting. Warning Use of many threads speeds up report execution but at the same time it can cause database write contention for regular provisioning. That is why you should balance properly execution and operational performance. To schedule the report: Go to Monitoring & Reporting \u2014> Reports . Go to the Schedule report tab. In the Template selection panel: From the Category list, select Monitoring reports . From the Report template list, select Advanced CSV Report . Configure settings such as a schedule, time interval, transfer and retention policy. Read how to configure these settings in the Reporting chapter. In the Parameters panel: Click the Select group link and from the list select a group on which you want to schedule the report. Note Keep in mind, that the system will include only the devices that are in the selected group when next scheduled generation starts. Even if you delete a device from the group while the report is in progress, it will be included. Optional: Type an expression to schedule the report only on devices that fulfill the specified condition. Select one of export types: Raw Aggregated From the list select a monitoring data export configuration. Click the Schedule button. Tip Apart from having proper data in the generated report, you can also come across the below cases: An empty space instead of some data because there was no data to present. The - sign instead of data because there was no aggregation to present. See also: Adding CSV monitoring data export configurations","title":"Scheduling advanced CSV Report"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Adding_monitoring.html","text":"Adding monitoring # Read this chapter to learn how to add a new monitoring. To add a monitoring: Go to Monitoring & Reporting \u2014> Monitoring . From the Available monitoring list, select a type of monitoring by clicking it. Configure basic settings. To learn about basic configuration, read the Monitoring configuration chapter. From the Monitoring target groups list, select groups you want to monitor. To learn more about adding groups, read the step 6 in the Monitoring configuration chapter. Configure advanced settings. To learn about configuration of an individual monitoring, read the Specific settings for monitoring chapter. Optional: Add additional resources. To learn about configuration of additional resources, read the Adding custom monitoring chapter. Select check boxes next to alerts you want to enable. To learn about alerts of an individual monitoring, read the Specific settings for monitoring chapter. Click the Save button. Tip To edit the monitoring, select it from the list and make necessary changes. Do not forget to save them. To delete the monitoring, select it from the list and click the Delete button. If you do not want to delete the monitoring but you do not want it to collect samples, clear the Enabled check box. Adding custom monitoring # Read this chapter to learn how to add custom monitoring that enables you to decide which resources you want to monitor. To add custom monitoring: Go to Monitoring & Reporting \u2014> Monitoring . From the Available monitoring list, select a Custom monitoring by clicking it. Configure basic settings. In this example, a name is defined, a sampling interval is set to Manual and its value is 300 , a domain is set to / , and the Enabled check box is selected. In the Monitoring target groups panel, click the Add link and select proper groups. In the Advanced configuration panel, click the Add resource link to select a representative device. The representative device will be used to validate a configuration of monitoring. You will be warned if resources created by you are not available on the device. Each monitoring may monitor one or more resources, and for each resource an alert can be configured and a separate chart will be created. Configure particular fields: From the Source list, select whether this resource will be based on a data model or on a setting value, and into the Data model field, type a proper path. In this example, the data model will be selected. The system prompts available objects which are marked in bold. If the device has any instances then the system displays their number on the list. If there are no instances on the selected device, the system cannot prompt them and you need to type object instances values manually (in the place marked as {i} ). From the Its type list, select a proper type. From the Collect for list, select if you want to collect data only for a group, device or for both group and device. Configure other related options: Into the Display name field, type a name that will be displayed above a chart with results. From the Device presentation / Group presentation lists, select how results will be presented, for example as a histogram or timeline. Click the Options link to configure additional options. Fields available for configuration vary depending on your selection in the Source field: X axis label - a name of the X axis, it will be visible on a chart. Y axis label - a name of the Y axis, it will be visible on the chart. Aggregation mode - a way in which data will be presented, if it is a sum or an average of results. To create an alert for this resource, select the Create alert check box. Specify its name and define when it will be raised. In the Actions panel, click the Save button. After saving the additional panel Enable/disable alert status collection will appear where you can enable group alerts (informing you for how many devices (in %) a particular alert occurred). For each defined alert: In the Enable/disable alert status collection , click the enable group alert link next to the alert. Define severity levels using lists and define a number above which the particular severity occurs. To disable the particular severity, select not used instead of above . In the Actions panel, click the Save button. All resources and alerts will be visible in Device inventory \u2014> Monitoring . If you hover over a monitored resource\u2019s graph in any place, you will see its value which was available at the corresponding time. If you hover over an alert\u2019s graph, you will see periods of time the alert was raised/hidden. See also: Monitoring configuration Specific settings for monitoring","title":"Adding monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Adding_monitoring.html#adding-monitoring","text":"Read this chapter to learn how to add a new monitoring. To add a monitoring: Go to Monitoring & Reporting \u2014> Monitoring . From the Available monitoring list, select a type of monitoring by clicking it. Configure basic settings. To learn about basic configuration, read the Monitoring configuration chapter. From the Monitoring target groups list, select groups you want to monitor. To learn more about adding groups, read the step 6 in the Monitoring configuration chapter. Configure advanced settings. To learn about configuration of an individual monitoring, read the Specific settings for monitoring chapter. Optional: Add additional resources. To learn about configuration of additional resources, read the Adding custom monitoring chapter. Select check boxes next to alerts you want to enable. To learn about alerts of an individual monitoring, read the Specific settings for monitoring chapter. Click the Save button. Tip To edit the monitoring, select it from the list and make necessary changes. Do not forget to save them. To delete the monitoring, select it from the list and click the Delete button. If you do not want to delete the monitoring but you do not want it to collect samples, clear the Enabled check box.","title":"Adding monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Adding_monitoring.html#adding-custom-monitoring","text":"Read this chapter to learn how to add custom monitoring that enables you to decide which resources you want to monitor. To add custom monitoring: Go to Monitoring & Reporting \u2014> Monitoring . From the Available monitoring list, select a Custom monitoring by clicking it. Configure basic settings. In this example, a name is defined, a sampling interval is set to Manual and its value is 300 , a domain is set to / , and the Enabled check box is selected. In the Monitoring target groups panel, click the Add link and select proper groups. In the Advanced configuration panel, click the Add resource link to select a representative device. The representative device will be used to validate a configuration of monitoring. You will be warned if resources created by you are not available on the device. Each monitoring may monitor one or more resources, and for each resource an alert can be configured and a separate chart will be created. Configure particular fields: From the Source list, select whether this resource will be based on a data model or on a setting value, and into the Data model field, type a proper path. In this example, the data model will be selected. The system prompts available objects which are marked in bold. If the device has any instances then the system displays their number on the list. If there are no instances on the selected device, the system cannot prompt them and you need to type object instances values manually (in the place marked as {i} ). From the Its type list, select a proper type. From the Collect for list, select if you want to collect data only for a group, device or for both group and device. Configure other related options: Into the Display name field, type a name that will be displayed above a chart with results. From the Device presentation / Group presentation lists, select how results will be presented, for example as a histogram or timeline. Click the Options link to configure additional options. Fields available for configuration vary depending on your selection in the Source field: X axis label - a name of the X axis, it will be visible on a chart. Y axis label - a name of the Y axis, it will be visible on the chart. Aggregation mode - a way in which data will be presented, if it is a sum or an average of results. To create an alert for this resource, select the Create alert check box. Specify its name and define when it will be raised. In the Actions panel, click the Save button. After saving the additional panel Enable/disable alert status collection will appear where you can enable group alerts (informing you for how many devices (in %) a particular alert occurred). For each defined alert: In the Enable/disable alert status collection , click the enable group alert link next to the alert. Define severity levels using lists and define a number above which the particular severity occurs. To disable the particular severity, select not used instead of above . In the Actions panel, click the Save button. All resources and alerts will be visible in Device inventory \u2014> Monitoring . If you hover over a monitored resource\u2019s graph in any place, you will see its value which was available at the corresponding time. If you hover over an alert\u2019s graph, you will see periods of time the alert was raised/hidden. See also: Monitoring configuration Specific settings for monitoring","title":"Adding custom monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Browsing_Monitoring_Results.html","text":"Browsing monitoring results # As mentioned in Monitoring , monitoring is applicable for two scopes - devices and groups. Consequently it is reflected by user interface structure for: Groups in Device groups A single device in Devices management center . Those views are similar for all types of monitoring. Typically they look like that: Predefined time ranges: hour/day/week . Custom time range beginning and end. Type your requested date or click the Date icon and select it from a calendar view. Result comparison. You can compare in a graphical way results with single device(s) ( Add device ) or group(s) ( Add group ). You can remove devices or groups of devices from comparison by clicking the number of selected elements. A typical results chart looks like this: It contains the following useful options: Show statistics - use it to show statistics for a particular chart. Hide legend - use it to hide a legend. Image - use it to export a graph as an image file. CSV - use it to export data from the graph as raw data in a CSV file format. Full screen - use it to expand the graph to the full screen to see details. Close the full screen mode by clicking x in right upper corner. You can also compare two devices on a single chart. This is useful when you need to compare monitoring results of a single device with another one or a group of devices. Comparison between device types shows which of them grant customers better service. To learn how to do this, look at the Basic filters screen.","title":"Browsing monitoring results"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Browsing_Monitoring_Results.html#browsing-monitoring-results","text":"As mentioned in Monitoring , monitoring is applicable for two scopes - devices and groups. Consequently it is reflected by user interface structure for: Groups in Device groups A single device in Devices management center . Those views are similar for all types of monitoring. Typically they look like that: Predefined time ranges: hour/day/week . Custom time range beginning and end. Type your requested date or click the Date icon and select it from a calendar view. Result comparison. You can compare in a graphical way results with single device(s) ( Add device ) or group(s) ( Add group ). You can remove devices or groups of devices from comparison by clicking the number of selected elements. A typical results chart looks like this: It contains the following useful options: Show statistics - use it to show statistics for a particular chart. Hide legend - use it to hide a legend. Image - use it to export a graph as an image file. CSV - use it to export data from the graph as raw data in a CSV file format. Full screen - use it to expand the graph to the full screen to see details. Close the full screen mode by clicking x in right upper corner. You can also compare two devices on a single chart. This is useful when you need to compare monitoring results of a single device with another one or a group of devices. Comparison between device types shows which of them grant customers better service. To learn how to do this, look at the Basic filters screen.","title":"Browsing monitoring results"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Configuration.html","text":"Monitoring configuration # Enabling monitoring requires preparation of monitoring configuration. Monitoring manager is available in the Monitoring & Reporting menu. Monitoring type - information showing you which monitoring you selected. A list of available monitoring types. Basic configuration : Name - a unique name of monitoring configuration. Description - an optional description of monitoring configuration. Execution condition - an additional condition that needs to be met to start the monitoring. You should use Expressions in this field. Type ${ to get a hint. Sampling interval - a time period (expressed in seconds) during which one sample should be collected. You can select the sampling interval from the list - Optimal (a predefined value) or Manual (you can set a value). Health index metric - a selection of KPIs. To learn about KPIs of an individual monitoring, read the Specific settings for monitoring chapter. Domain - a list of available domains. Select it if you want to restrict access only to particular users. To learn about domains, read the Managing multitenancy chapter. Enabled - a check box that allows you to enable or disable a monitoring. Samples are not collected for inactive monitoring, but already collected results can be still browsed. Group exclusion patterns - a list of regular expression patterns that are used to exclude groups from group aggregate collection. Actions Save - a button to save a new monitoring. Delete - a button to delete the monitoring. Advanced configuration - specific configuration for each monitoring. To learn about configuration of an individual monitoring, read the Specific settings for monitoring chapter. Import and Export buttons to export to or import from a XML file monitoring type specific configuration. The Advanced configuration can be divided into: A panel with configuration fields specific for a particular monitoring. Configure monitoring of custom resources with the Add resource icon - additional resources that you can add to be monitored. To learn how to configure additional resources, read the Custom monitoring chapter. Enable/disable alert status collection - a list of alerts that you can enable (click the check box next to the alert) or disable (clear the check box). Legend settings for monitoring map - for almost all monitoring types you can define legend settings for resources that are visible on a monitoring map . You can select: Color schema - how values should be colored. You can select Red - Green - lower values will have a red color and higher will have a green color, or Green - Red - lower values will have a green color and higher will have a red color. Range adjustment - how values will be computed. You can select Automatic - minimum and maximum values will be computed on the basis of monitoring values, or Manual - minimum and maximum values will be defined by a user. Unit - which unit will be used, for example, %, kbps, or ms. Monitoring target groups - a monitoring groups selection option. Select monitoring groups by clicking Add and selecting particular groups from the list. You can select more than one group at the same time, just keep the window open. To stop adding groups, close the window. To delete a group from monitoring, click the icon next to it. Tip When a group is selected its descendants are not accessible as they are also monitoring groups by definition. When the root group is selected, then no more groups can be selected.","title":"Monitoring configuration"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Configuration.html#monitoring-configuration","text":"Enabling monitoring requires preparation of monitoring configuration. Monitoring manager is available in the Monitoring & Reporting menu. Monitoring type - information showing you which monitoring you selected. A list of available monitoring types. Basic configuration : Name - a unique name of monitoring configuration. Description - an optional description of monitoring configuration. Execution condition - an additional condition that needs to be met to start the monitoring. You should use Expressions in this field. Type ${ to get a hint. Sampling interval - a time period (expressed in seconds) during which one sample should be collected. You can select the sampling interval from the list - Optimal (a predefined value) or Manual (you can set a value). Health index metric - a selection of KPIs. To learn about KPIs of an individual monitoring, read the Specific settings for monitoring chapter. Domain - a list of available domains. Select it if you want to restrict access only to particular users. To learn about domains, read the Managing multitenancy chapter. Enabled - a check box that allows you to enable or disable a monitoring. Samples are not collected for inactive monitoring, but already collected results can be still browsed. Group exclusion patterns - a list of regular expression patterns that are used to exclude groups from group aggregate collection. Actions Save - a button to save a new monitoring. Delete - a button to delete the monitoring. Advanced configuration - specific configuration for each monitoring. To learn about configuration of an individual monitoring, read the Specific settings for monitoring chapter. Import and Export buttons to export to or import from a XML file monitoring type specific configuration. The Advanced configuration can be divided into: A panel with configuration fields specific for a particular monitoring. Configure monitoring of custom resources with the Add resource icon - additional resources that you can add to be monitored. To learn how to configure additional resources, read the Custom monitoring chapter. Enable/disable alert status collection - a list of alerts that you can enable (click the check box next to the alert) or disable (clear the check box). Legend settings for monitoring map - for almost all monitoring types you can define legend settings for resources that are visible on a monitoring map . You can select: Color schema - how values should be colored. You can select Red - Green - lower values will have a red color and higher will have a green color, or Green - Red - lower values will have a green color and higher will have a red color. Range adjustment - how values will be computed. You can select Automatic - minimum and maximum values will be computed on the basis of monitoring values, or Manual - minimum and maximum values will be defined by a user. Unit - which unit will be used, for example, %, kbps, or ms. Monitoring target groups - a monitoring groups selection option. Select monitoring groups by clicking Add and selecting particular groups from the list. You can select more than one group at the same time, just keep the window open. To stop adding groups, close the window. To delete a group from monitoring, click the icon next to it. Tip When a group is selected its descendants are not accessible as they are also monitoring groups by definition. When the root group is selected, then no more groups can be selected.","title":"Monitoring configuration"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings.html","text":"Specific settings for monitoring # Go through below sections to learn how to configure a monitoring. Custom Inactive devices","title":"Specific settings for monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings.html#specific-settings-for-monitoring","text":"Go through below sections to learn how to configure a monitoring. Custom Inactive devices","title":"Specific settings for monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map_toctree.html","text":"Monitoring map # Monitoring map Overriding a default zooming feature using SV Example Procedure","title":"Monitoring map"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map_toctree.html#monitoring-map","text":"Monitoring map Overriding a default zooming feature using SV Example Procedure","title":"Monitoring map"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings/Custom_monitoring.html","text":"Custom # Use the Custom monitoring to create a fully customized monitoring to satisfy your needs. The monitoring is based on data model parameters and on setting values, you decide what you want to use. Advanced configuration consists of the following fields: Add resource - click it to add a new resource, then you will be able to select which parameter or setting value you want to monitor on the basis of a device. Representative of monitored devices - a device representative that you selected after clicking the Add resource link. The device representative will be used to validate a configuration of Custom monitoring. You will be warned if resources created by you are not available on the representative device. Click the Preview icon to see a current value of resources on the representative device. Click the name of the device to change it to another one. Save your configuration first, otherwise it will be lost. Click the blue arrow to go to Device inventory and see the device details. Source - defines if the resource is taken from the data model or from setting values. Select: Data model - to take the resource from the data model. The system prompts available resources, which are marked in bold. If a device has any instances then the system displays their number on the list. If there are no instances on the selected device, the system cannot prompt them and you need to type object instances values manually (type them in the place marked as {i} ). Read more in Data model key prompts . Setting value - to take the resource from the setting values. Its type - defines if a resource is expressed as text or as a number. Data interpretation - a list of available ways of presenting your data, if it should be expressed, for example, as a percentage or sample count. Preview - the icon shows if your configuration is correct. Green means correct and red means incorrect configuration. Click the icon to see a hint. If the configuration is correct, a value of a resource for the representative device is shown. Collect for - click it to decide if you want to collect data only for a group, device or for both group and device. Display name - a name that will be displayed above a chart with results. Device presentation / Group presentation - defines how results will be presented, for example as a histogram or timeline. Options - additional options that you can configure. Fields available for configuration vary depending on your selection in the Source field: X axis label - a name of the X axis, it will be visible on a chart. Y axis label - a name of the Y axis, it will be visible on the chart. Aggregation mode - a way in which data will be presented, if it is a sum or an average of results. Create alert - select it to create an alert for a particular resource. Alert name - a name of the alert. Raise it when monitored resource value - a list of conditions from which you select one for the resource. If the defined condition is met, then the alert is raised. Conditions vary depending on the configuration set in the Its type field. If you select, for example, is absent from the following list , type a value and press Enter . To remove the value, click it. Passive - select it to indicate that the resource is passive. Tip You can add as many resources as you want. For each of them a separate chart will be created.","title":"Custom"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings/Custom_monitoring.html#custom","text":"Use the Custom monitoring to create a fully customized monitoring to satisfy your needs. The monitoring is based on data model parameters and on setting values, you decide what you want to use. Advanced configuration consists of the following fields: Add resource - click it to add a new resource, then you will be able to select which parameter or setting value you want to monitor on the basis of a device. Representative of monitored devices - a device representative that you selected after clicking the Add resource link. The device representative will be used to validate a configuration of Custom monitoring. You will be warned if resources created by you are not available on the representative device. Click the Preview icon to see a current value of resources on the representative device. Click the name of the device to change it to another one. Save your configuration first, otherwise it will be lost. Click the blue arrow to go to Device inventory and see the device details. Source - defines if the resource is taken from the data model or from setting values. Select: Data model - to take the resource from the data model. The system prompts available resources, which are marked in bold. If a device has any instances then the system displays their number on the list. If there are no instances on the selected device, the system cannot prompt them and you need to type object instances values manually (type them in the place marked as {i} ). Read more in Data model key prompts . Setting value - to take the resource from the setting values. Its type - defines if a resource is expressed as text or as a number. Data interpretation - a list of available ways of presenting your data, if it should be expressed, for example, as a percentage or sample count. Preview - the icon shows if your configuration is correct. Green means correct and red means incorrect configuration. Click the icon to see a hint. If the configuration is correct, a value of a resource for the representative device is shown. Collect for - click it to decide if you want to collect data only for a group, device or for both group and device. Display name - a name that will be displayed above a chart with results. Device presentation / Group presentation - defines how results will be presented, for example as a histogram or timeline. Options - additional options that you can configure. Fields available for configuration vary depending on your selection in the Source field: X axis label - a name of the X axis, it will be visible on a chart. Y axis label - a name of the Y axis, it will be visible on the chart. Aggregation mode - a way in which data will be presented, if it is a sum or an average of results. Create alert - select it to create an alert for a particular resource. Alert name - a name of the alert. Raise it when monitored resource value - a list of conditions from which you select one for the resource. If the defined condition is met, then the alert is raised. Conditions vary depending on the configuration set in the Its type field. If you select, for example, is absent from the following list , type a value and press Enter . To remove the value, click it. Passive - select it to indicate that the resource is passive. Tip You can add as many resources as you want. For each of them a separate chart will be created.","title":"Custom"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings/Inactive_devices.html","text":"Inactive devices # Use the Inactive devices monitoring to identify devices which last visit in the system is older than expected. It is calculated with this formula: last visit time + expectedSessionRatio * periodicInformInterval . This monitoring does not have any contact with devices, it only inspects the system for devices that were supposed to connect. Prerequisites: To execute the monitoring, the expectedSessionRatio (in %) and periodicInformInterval (in seconds) SVs must be set on a device or a group of devices. Alerts that can be triggered by this monitoring: Inactive device - the alert is triggered when a device does not visit the system in the expected time period. The following KPI is available: Active devices : For a device - KPI shows the last value and when it displays 0% this means that the device is inactive, and when it displays 100% this means that the device is active. For a group of devices - KPI shows a percentage of active devices in the last hour. The higher value the better.","title":"Inactive devices"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings/Inactive_devices.html#inactive-devices","text":"Use the Inactive devices monitoring to identify devices which last visit in the system is older than expected. It is calculated with this formula: last visit time + expectedSessionRatio * periodicInformInterval . This monitoring does not have any contact with devices, it only inspects the system for devices that were supposed to connect. Prerequisites: To execute the monitoring, the expectedSessionRatio (in %) and periodicInformInterval (in seconds) SVs must be set on a device or a group of devices. Alerts that can be triggered by this monitoring: Inactive device - the alert is triggered when a device does not visit the system in the expected time period. The following KPI is available: Active devices : For a device - KPI shows the last value and when it displays 0% this means that the device is inactive, and when it displays 100% this means that the device is active. For a group of devices - KPI shows a percentage of active devices in the last hour. The higher value the better.","title":"Inactive devices"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html","text":"Monitoring map # To visualize monitoring that you configured in your system on a map, go to Monitoring & Reporting \u2014> Monitoring map . Interface # The Monitoring map view is divided into three main panels: Time range - use it to set a time period for which you want to see visualization. To set a date, use the button or the calendar. Tabs - use the tabs to decide which monitoring and options you can see on the map: Monitoring Options Filters Search Map - use it to see monitoring data location. On the map you can click a group or a subgroup to see more details in a pop-up window. When the pop-up window opens, depending on displayed data, you can save it as an image or a CSV file. What is more, you can click the group name to go to Device groups . If there is any data collected for a selected resource, then a proper legend is displayed above the map. For some monitoring resources you will be able to edit the legend by clicking the Edit icon. To learn more about legend settings, read the Monitoring configuration chapter. Changes you make on the monitoring map will be also implemented in monitoring configuration. Groups circles displayed on the map will be highlighted with colors depending on the collected value and according to the scale. To zoom the map, use the zoom slider or your mouse scroll wheel. A level in a group hierarchy depends on zoom on the map (thus when zoom is closer, you are able to see smaller groups or even devices). The default association between zoom and depth in the group hierarchy can be overridden by setting a proper SV. Learn how to do it in the Overriding a default zooming feature using SV chapter. Monitoring # Use the Monitoring section to select a group and monitoring that you want to display on the map. Root group - select a group from which you want to display monitoring. Groups added in Administration \u2014> Import monitoring groups are available on the Root group list automatically. To add other groups use the Edit link (you can also use it to remove any groups). The group selected from the list will be used as a root of a hierarchy displayed below as a tree and as groups circles on the map. If you do not want to show all subgroups, hover over the subgroup and clear the check box next to it. Monitoring - click a monitoring name to display it on the map. Resource - select what resource you want to display. Aggregation - select a proper aggregation of values from the list. Next - click it to go to another tab. Options # Use the Options section to display additional information on the map. Mark min value - select it to mark groups or devices for which a value of a selected resource (in the Monitoring section from the Resource list) is the lowest. Show values - select it to show values of the selected resource. Show names - select it to show names of groups, subgroups, or devices. Voronoi diagram - select it to display the Voronoi diagram on the map. Saturation - move the slider to select proper saturation of the Voronoi diagram. Show in group circle - use this list to display additional information on the map, such as a number of subgroups or devices in the particular group. The number also influences the color of the particular group circle, this helps you to visually compare the size of groups when the map is zoomed out. Mark max value - select it to mark groups or devices for which a value of the selected resource is the highest. Show locations - select it to display a geographical location on the map. Draw beams (BTS) - select it to display a direction of emission of base transceiver stations (BTS). Next - click it to go to another tab. Filters # Use the Filters section to display only specified information. You can add more than one filter. Add filter - click the icon to add a filter. Configure the filter by selecting from lists proper configuration and providing values. Data that you can select for each monitoring type differs. To add another filter, click the icon again. Apply filters - click it to execute the filter on the map. Delete - click the icon to delete the filter. Next - click it to go to another tab. Search # Use the Search section to find a particular device on the map. Type a device identity and click the Search icon. When the device is displayed on the map, you can click it to see more details. See also: Overriding a default zooming feature using SV Importing monitoring groups from CSV","title":"Monitoring map"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#monitoring-map","text":"To visualize monitoring that you configured in your system on a map, go to Monitoring & Reporting \u2014> Monitoring map .","title":"Monitoring map"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#interface","text":"The Monitoring map view is divided into three main panels: Time range - use it to set a time period for which you want to see visualization. To set a date, use the button or the calendar. Tabs - use the tabs to decide which monitoring and options you can see on the map: Monitoring Options Filters Search Map - use it to see monitoring data location. On the map you can click a group or a subgroup to see more details in a pop-up window. When the pop-up window opens, depending on displayed data, you can save it as an image or a CSV file. What is more, you can click the group name to go to Device groups . If there is any data collected for a selected resource, then a proper legend is displayed above the map. For some monitoring resources you will be able to edit the legend by clicking the Edit icon. To learn more about legend settings, read the Monitoring configuration chapter. Changes you make on the monitoring map will be also implemented in monitoring configuration. Groups circles displayed on the map will be highlighted with colors depending on the collected value and according to the scale. To zoom the map, use the zoom slider or your mouse scroll wheel. A level in a group hierarchy depends on zoom on the map (thus when zoom is closer, you are able to see smaller groups or even devices). The default association between zoom and depth in the group hierarchy can be overridden by setting a proper SV. Learn how to do it in the Overriding a default zooming feature using SV chapter.","title":"Interface"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#monitoring","text":"Use the Monitoring section to select a group and monitoring that you want to display on the map. Root group - select a group from which you want to display monitoring. Groups added in Administration \u2014> Import monitoring groups are available on the Root group list automatically. To add other groups use the Edit link (you can also use it to remove any groups). The group selected from the list will be used as a root of a hierarchy displayed below as a tree and as groups circles on the map. If you do not want to show all subgroups, hover over the subgroup and clear the check box next to it. Monitoring - click a monitoring name to display it on the map. Resource - select what resource you want to display. Aggregation - select a proper aggregation of values from the list. Next - click it to go to another tab.","title":"Monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#options","text":"Use the Options section to display additional information on the map. Mark min value - select it to mark groups or devices for which a value of a selected resource (in the Monitoring section from the Resource list) is the lowest. Show values - select it to show values of the selected resource. Show names - select it to show names of groups, subgroups, or devices. Voronoi diagram - select it to display the Voronoi diagram on the map. Saturation - move the slider to select proper saturation of the Voronoi diagram. Show in group circle - use this list to display additional information on the map, such as a number of subgroups or devices in the particular group. The number also influences the color of the particular group circle, this helps you to visually compare the size of groups when the map is zoomed out. Mark max value - select it to mark groups or devices for which a value of the selected resource is the highest. Show locations - select it to display a geographical location on the map. Draw beams (BTS) - select it to display a direction of emission of base transceiver stations (BTS). Next - click it to go to another tab.","title":"Options"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#filters","text":"Use the Filters section to display only specified information. You can add more than one filter. Add filter - click the icon to add a filter. Configure the filter by selecting from lists proper configuration and providing values. Data that you can select for each monitoring type differs. To add another filter, click the icon again. Apply filters - click it to execute the filter on the map. Delete - click the icon to delete the filter. Next - click it to go to another tab.","title":"Filters"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#search","text":"Use the Search section to find a particular device on the map. Type a device identity and click the Search icon. When the device is displayed on the map, you can click it to see more details. See also: Overriding a default zooming feature using SV Importing monitoring groups from CSV","title":"Search"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Overriding_a_default_zooming_feature_using_SV.html","text":"Overriding a default zooming feature using SV # The default association between zoom and a depth in the group hierarchy can be overridden by setting a proper SV. Example # To better understand the format of the SV you will need to type, read the below example. Let's assume that your groups hierarchy looks like the one below: monitoring-root |----- country-1-subgroup | |------ city-1-subgroup <- each group contain devices, no more subgroups | |------ city-2-subgroup | \\------ city-3-subgroup \\----- country-2-subgroup |------ city-4-subgroup \\------ city-5-subgroup Each value from SV corresponds to a level in your group hierarchy: 0 is interpreted as a monitoring group root (in the example - monitoring-root ). 1 is interpreted as a monitoring root's direct children (in the example - country-1-subgroup and country-2-subgroup ). 2 is interpreted as the second level children (in the example - all cities subgroups ). And so on if you have more levels. In the example, you have only three levels in the group hierarchy, that is 0 , 1 and 2 but you can always use one more to display devices. Thus in this case, you can use 3 to denote devices. SV is composed of 16 non-decreasing numbers because this is the number of available zoom levels on the map. The first number indicates the most zoomed out view (the farthest view), the second indicates a slightly closer view and the last one indicates the most zoomed in view (that is the closest one). Let's analyze this SV: 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2 in the context of the above sample group hierarchy: Through the most 5 farthest zooms, only monitoring-root will be shown (5 because there are 5 zeros at the beginning). Through the next 4 map zooms, country-1-subgroup and country-2-subgroup will be shown (4 because there are four 1). Through the last 7 closest map zooms, all cities subgroups will be shown. If you change last four 2 to 3 then you will get 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3 and in this case, for last four most close zooms you will see devices. Procedure # To override the default zooming feature using SV: Go to Device groups . From the group tree, select a group. Go to Profiles and add into: The Name field, type monitoringZoomLevelMapping . The Value field, type a comma separated list of 16 non-decreasing values. Click the Save link. To check if your configuration works, go to Monitoring & Reporting \u2014> Monitoring map . See also: Monitoring map","title":"Overriding a default zooming feature using SV"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Overriding_a_default_zooming_feature_using_SV.html#overriding-a-default-zooming-feature-using-sv","text":"The default association between zoom and a depth in the group hierarchy can be overridden by setting a proper SV.","title":"Overriding a default zooming feature using SV"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Overriding_a_default_zooming_feature_using_SV.html#example","text":"To better understand the format of the SV you will need to type, read the below example. Let's assume that your groups hierarchy looks like the one below: monitoring-root |----- country-1-subgroup | |------ city-1-subgroup <- each group contain devices, no more subgroups | |------ city-2-subgroup | \\------ city-3-subgroup \\----- country-2-subgroup |------ city-4-subgroup \\------ city-5-subgroup Each value from SV corresponds to a level in your group hierarchy: 0 is interpreted as a monitoring group root (in the example - monitoring-root ). 1 is interpreted as a monitoring root's direct children (in the example - country-1-subgroup and country-2-subgroup ). 2 is interpreted as the second level children (in the example - all cities subgroups ). And so on if you have more levels. In the example, you have only three levels in the group hierarchy, that is 0 , 1 and 2 but you can always use one more to display devices. Thus in this case, you can use 3 to denote devices. SV is composed of 16 non-decreasing numbers because this is the number of available zoom levels on the map. The first number indicates the most zoomed out view (the farthest view), the second indicates a slightly closer view and the last one indicates the most zoomed in view (that is the closest one). Let's analyze this SV: 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2 in the context of the above sample group hierarchy: Through the most 5 farthest zooms, only monitoring-root will be shown (5 because there are 5 zeros at the beginning). Through the next 4 map zooms, country-1-subgroup and country-2-subgroup will be shown (4 because there are four 1). Through the last 7 closest map zooms, all cities subgroups will be shown. If you change last four 2 to 3 then you will get 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3 and in this case, for last four most close zooms you will see devices.","title":"Example"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Overriding_a_default_zooming_feature_using_SV.html#procedure","text":"To override the default zooming feature using SV: Go to Device groups . From the group tree, select a group. Go to Profiles and add into: The Name field, type monitoringZoomLevelMapping . The Value field, type a comma separated list of 16 non-decreasing values. Click the Save link. To check if your configuration works, go to Monitoring & Reporting \u2014> Monitoring map . See also: Monitoring map","title":"Procedure"},{"location":"User_Guide/REST_API/Adding_user_API_authorization_tokens.html","text":"Adding user API authorization tokens # Note To be able to access this feature, you need to have the smg.userProfile and userProfile.tokens permissions assigned. The API authorization tokens are used to autorize users in REST API through the Authorization: Bearer HTTP header (example: Authorization: Bearer qp82nps7h23 ). Read this section to learn how to view, generate and invalidate REST API authorization tokens assigned to your account: To see the list of tokens assigned to your account, go to My account \u2014> My profile . Use the Add new link located under the tokens list to add a new token entry. Provide token name and invalidation date, then click the Generate new token link. In the pop-up window that appears, copy the newly generated token to clipboard and close the window. Warning You won't be able to copy the token after closing the window. To invalidate a token, click the Invalidate link. Fig. A list of user tokens","title":"Adding user API authorization tokens"},{"location":"User_Guide/REST_API/Adding_user_API_authorization_tokens.html#adding-user-api-authorization-tokens","text":"Note To be able to access this feature, you need to have the smg.userProfile and userProfile.tokens permissions assigned. The API authorization tokens are used to autorize users in REST API through the Authorization: Bearer HTTP header (example: Authorization: Bearer qp82nps7h23 ). Read this section to learn how to view, generate and invalidate REST API authorization tokens assigned to your account: To see the list of tokens assigned to your account, go to My account \u2014> My profile . Use the Add new link located under the tokens list to add a new token entry. Provide token name and invalidation date, then click the Generate new token link. In the pop-up window that appears, copy the newly generated token to clipboard and close the window. Warning You won't be able to copy the token after closing the window. To invalidate a token, click the Invalidate link. Fig. A list of user tokens","title":"Adding user API authorization tokens"},{"location":"User_Guide/REST_API/Changing_REST_API_documentation_authentication_method.html","text":"Changing REST API documentation authorization method # The administrator can decide whether the REST API documentation should be accessed with or without providing the local account password. In order to change the authorization method, open the cdm.conf and, in the restApi section, find the swaggerDocAuthMode . Set its value to: GUI_COOKIE - if you want the access to REST API documentation to be based on the cookie obtained during logging in to the platform, or BASIC - if you want to require password-based authentication upon entering the REST API documentation. Note Even with the GUI_COOKIE setting in place, the user will still need the standard authentication (using the username and password or API token) to use REST API requests.","title":"Changing REST API documentation authorization method"},{"location":"User_Guide/REST_API/Changing_REST_API_documentation_authentication_method.html#changing-rest-api-documentation-authorization-method","text":"The administrator can decide whether the REST API documentation should be accessed with or without providing the local account password. In order to change the authorization method, open the cdm.conf and, in the restApi section, find the swaggerDocAuthMode . Set its value to: GUI_COOKIE - if you want the access to REST API documentation to be based on the cookie obtained during logging in to the platform, or BASIC - if you want to require password-based authentication upon entering the REST API documentation. Note Even with the GUI_COOKIE setting in place, the user will still need the standard authentication (using the username and password or API token) to use REST API requests.","title":"Changing REST API documentation authorization method"},{"location":"User_Guide/REST_API/Limiting_the_number_of_REST_API_requests.html","text":"Limiting the number of REST API requests # Read this instruction to learn how to set a limit on the number of REST API requests that can be sent by a particular user. To set a limit on a number of requests: Go to Administration \u2014> Users management . Click the System users tab. From a list of users, select a user for which you want to set a limit on a number of requests. Click the Edit button. Click the REST API Quota tab. Configure limits: Into the proper fields, type a number of requests. If you leave any of request fields empty then a user can send an unlimited number of these requests. Into the Quota reset period field, type a time period after which count for requests is cleared. You can express time in days, hours, minutes and seconds, for example, 2 days or 2 hours or 2 minutes or 2 seconds. You can also use abbreviations such as d - for day, h - for hours, min - for minutes and s - for seconds. If you leave this field empty, then the default value is 1 day . Click the Save button.","title":"Limiting the number of REST API requests"},{"location":"User_Guide/REST_API/Limiting_the_number_of_REST_API_requests.html#limiting-the-number-of-rest-api-requests","text":"Read this instruction to learn how to set a limit on the number of REST API requests that can be sent by a particular user. To set a limit on a number of requests: Go to Administration \u2014> Users management . Click the System users tab. From a list of users, select a user for which you want to set a limit on a number of requests. Click the Edit button. Click the REST API Quota tab. Configure limits: Into the proper fields, type a number of requests. If you leave any of request fields empty then a user can send an unlimited number of these requests. Into the Quota reset period field, type a time period after which count for requests is cleared. You can express time in days, hours, minutes and seconds, for example, 2 days or 2 hours or 2 minutes or 2 seconds. You can also use abbreviations such as d - for day, h - for hours, min - for minutes and s - for seconds. If you leave this field empty, then the default value is 1 day . Click the Save button.","title":"Limiting the number of REST API requests"},{"location":"User_Guide/REST_API/REST_API_Authentication.html","text":"REST API authentication # To use REST API, a regular user account in the platform is required. Such user account should have permissions for performing REST API requests. The user can obtain a REST API access token by sending the POST request on an authentication endpoint: curl --request POST --url http://#HOSTNAME/api/auth/oauth_password --header 'content-type: application/x-www-form-urlencoded' --data 'grant_type=password&username=#USERNAME&password=#PASSWORD' A response to this request contains the access token and its expiration time is expressed in seconds: {\"access_token\":\"#TOKEN\",\"token_type\":\"Bearer\",\"expires_in\":\"#EXPIRATION_TIME\"} The obtained token can be used for performing requests on a device management endpoint - it should be included in the \"authorization\" header. For example: curl -i -X GET \"http://#HOSTNAME/api/coiotedm/v3/devices\" -H \"accept: application/json\" -H \"authorization: Bearer #TOKEN\" Token expiration time is renewed on each request. When the token is no longer needed it can be invalidated using the authentication endpoint: curl --request POST --url http://#HOSTNAME/api/auth/invalidate_token --header 'content-type: application/json' --data '{\"token\": \"#TOKEN\"}'","title":"REST API authentication"},{"location":"User_Guide/REST_API/REST_API_Authentication.html#rest-api-authentication","text":"To use REST API, a regular user account in the platform is required. Such user account should have permissions for performing REST API requests. The user can obtain a REST API access token by sending the POST request on an authentication endpoint: curl --request POST --url http://#HOSTNAME/api/auth/oauth_password --header 'content-type: application/x-www-form-urlencoded' --data 'grant_type=password&username=#USERNAME&password=#PASSWORD' A response to this request contains the access token and its expiration time is expressed in seconds: {\"access_token\":\"#TOKEN\",\"token_type\":\"Bearer\",\"expires_in\":\"#EXPIRATION_TIME\"} The obtained token can be used for performing requests on a device management endpoint - it should be included in the \"authorization\" header. For example: curl -i -X GET \"http://#HOSTNAME/api/coiotedm/v3/devices\" -H \"accept: application/json\" -H \"authorization: Bearer #TOKEN\" Token expiration time is renewed on each request. When the token is no longer needed it can be invalidated using the authentication endpoint: curl --request POST --url http://#HOSTNAME/api/auth/invalidate_token --header 'content-type: application/json' --data '{\"token\": \"#TOKEN\"}'","title":"REST API authentication"},{"location":"User_Guide/User_Interface_Reference/Administration/Adding_terms_of_service.html","text":"Adding Terms of Service # As an administrator of the Coiote DM installation you can add and edit Terms of Service that your users have to accept before having access to the system. To add Terms of Service: Go to Administration \u2014> Terms of Service . Click the Create a new version link. Type a proper text containing Terms of Service. You can use various formatting tools. Tip While creating a new version, you can come back to the previous version by clicking the Revert version link. Decide if users have to accept new Terms of Service by selecting the Yes or No option. Click the Save button. New Terms of Service will be visible to your users. You will see how many users accepted them (if you selected that acceptance is required) in the table on the right and you can use the search field to look for particular users by their logins. Editing Terms of Service # At any time you can edit Terms of Service and users will not have to accept it again. To edit Terms of Service: Make necessary changes in the text field. Click the Save button.","title":"Adding Terms of Service"},{"location":"User_Guide/User_Interface_Reference/Administration/Adding_terms_of_service.html#adding-terms-of-service","text":"As an administrator of the Coiote DM installation you can add and edit Terms of Service that your users have to accept before having access to the system. To add Terms of Service: Go to Administration \u2014> Terms of Service . Click the Create a new version link. Type a proper text containing Terms of Service. You can use various formatting tools. Tip While creating a new version, you can come back to the previous version by clicking the Revert version link. Decide if users have to accept new Terms of Service by selecting the Yes or No option. Click the Save button. New Terms of Service will be visible to your users. You will see how many users accepted them (if you selected that acceptance is required) in the table on the right and you can use the search field to look for particular users by their logins.","title":"Adding Terms of Service"},{"location":"User_Guide/User_Interface_Reference/Administration/Adding_terms_of_service.html#editing-terms-of-service","text":"At any time you can edit Terms of Service and users will not have to accept it again. To edit Terms of Service: Make necessary changes in the text field. Click the Save button.","title":"Editing Terms of Service"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates.html","text":"CSV Import/Export templates # Go through below sections to learn how to add, edit and delete CSV import and export configurations. Note This panel supports multitenancy, which means that: CSV Import/Export templates configuration is visible as read only for subtenants. Supertenants can see configurations of their subtenants. Adding CSV import configurations Editing CSV import configurations Deleting CSV import configurations Adding CSV export configurations Editing CSV export configurations Deleting CSV export configurations Adding CSV monitoring data export configurations","title":"CSV Import/Export templates"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates.html#csv-importexport-templates","text":"Go through below sections to learn how to add, edit and delete CSV import and export configurations. Note This panel supports multitenancy, which means that: CSV Import/Export templates configuration is visible as read only for subtenants. Supertenants can see configurations of their subtenants. Adding CSV import configurations Editing CSV import configurations Deleting CSV import configurations Adding CSV export configurations Editing CSV export configurations Deleting CSV export configurations Adding CSV monitoring data export configurations","title":"CSV Import/Export templates"},{"location":"User_Guide/User_Interface_Reference/Administration/Customizing_device_list.html","text":"Customizing device list # Read this chapter to learn how to customize the device list displayed in Device inventory . To customize device list: Go to Administration \u2014> Device inventory preferences . From the Target list, select the target. Configure the device list: To change an order of entries, use the drag and drop functionality or in the Priority column, click the triangles to move the particular entry up or down. To add sorting for the device list, click the Add sort column button and from the list select a column that will sort the list. To sort in an ascending order, select the Ascending check box. To add a new entry, configure it and click the Add entry button. To delete the entry, find it in the table and click the Remove icon. To see changes before saving them, click the Preview button. To reset your changes, click the Set to default button. Click the Save settings button.","title":"Customizing device list"},{"location":"User_Guide/User_Interface_Reference/Administration/Customizing_device_list.html#customizing-device-list","text":"Read this chapter to learn how to customize the device list displayed in Device inventory . To customize device list: Go to Administration \u2014> Device inventory preferences . From the Target list, select the target. Configure the device list: To change an order of entries, use the drag and drop functionality or in the Priority column, click the triangles to move the particular entry up or down. To add sorting for the device list, click the Add sort column button and from the list select a column that will sort the list. To sort in an ascending order, select the Ascending check box. To add a new entry, configure it and click the Add entry button. To delete the entry, find it in the table and click the Remove icon. To see changes before saving them, click the Preview button. To reset your changes, click the Set to default button. Click the Save settings button.","title":"Customizing device list"},{"location":"User_Guide/User_Interface_Reference/Administration/Customizing_device_summary.html","text":"Customizing device summary # Read this chapter to learn how to customize the device summary displayed in Device inventory . To customize device summary: Go to Administration \u2014> Device summary editor . From the Target list, select the target. Configure the device summary: To change an order of entries, use the drag and drop functionality or in the Priority column, click the triangles to move the particular entry up or down. To add a new entry, configure it and click the Add entry button. To delete the entry, find it in the table and click the Remove icon. To see changes before saving them, click the Preview button. To reset your changes, click the Set to default button. Click the Save settings button.","title":"Customizing device summary"},{"location":"User_Guide/User_Interface_Reference/Administration/Customizing_device_summary.html#customizing-device-summary","text":"Read this chapter to learn how to customize the device summary displayed in Device inventory . To customize device summary: Go to Administration \u2014> Device summary editor . From the Target list, select the target. Configure the device summary: To change an order of entries, use the drag and drop functionality or in the Priority column, click the triangles to move the particular entry up or down. To add a new entry, configure it and click the Add entry button. To delete the entry, find it in the table and click the Remove icon. To see changes before saving them, click the Preview button. To reset your changes, click the Set to default button. Click the Save settings button.","title":"Customizing device summary"},{"location":"User_Guide/User_Interface_Reference/Administration/DTLS_TLS_Certificates.html","text":"DTLS/TLS Certificates # As an administrator of the Coiote DM installation, you can add and manage device certificates and their CAs. Adding a certificate # To add a certificate: Go to Administration \u2192 DTLS/TLS Certificates . Click the Add file button. Type your custom certificate name and description. Drag and drop the certificate file or upload it using the Browse button. Optionally, mark the Use expression for endpoint name and enter an expression to be built from client certificate data that will be used for endpoint names of devices authorized by this ceritificate. Click the Save button. Managing a certificate # At any time you can edit, download or remove your certificate. Note Certificates defined in the configuration files cannot be edited or removed. To edit a certificate name and description: Choose a certificate to edit and click the Edit link. Introduce the required changes in the text fields. Click the Save button. To download a certificate: Choose a certificate to download and click the Download link. The certificate will be downloaded automatically to your drive. To remove a certificate: Choose a certificate to remove and click the Remove link. Click the Confirm button. Adding certificates to the Deny list # To make Coiote DM reject a device certificate, you need to add it to the Deny list . To do that, follow these steps: In the Administration \u2192 DTLS/TLS Certificates , go to the Deny list tab and click Add file . In the pop-up, specify name, description, and upload your certificate file by using the drag & drop function or the Browse button. Click Save . After the certificate has been added correctly to the list, you can remove, edit or download it in the same way as in the Trusted certificates list. Note The Deny list has precedence over the Trusted certificates list, so if a certificate is placed in both lists, the Server will reject it.","title":"DTLS/TLS Certificates"},{"location":"User_Guide/User_Interface_Reference/Administration/DTLS_TLS_Certificates.html#dtlstls-certificates","text":"As an administrator of the Coiote DM installation, you can add and manage device certificates and their CAs.","title":"DTLS/TLS Certificates"},{"location":"User_Guide/User_Interface_Reference/Administration/DTLS_TLS_Certificates.html#adding-a-certificate","text":"To add a certificate: Go to Administration \u2192 DTLS/TLS Certificates . Click the Add file button. Type your custom certificate name and description. Drag and drop the certificate file or upload it using the Browse button. Optionally, mark the Use expression for endpoint name and enter an expression to be built from client certificate data that will be used for endpoint names of devices authorized by this ceritificate. Click the Save button.","title":"Adding a certificate"},{"location":"User_Guide/User_Interface_Reference/Administration/DTLS_TLS_Certificates.html#managing-a-certificate","text":"At any time you can edit, download or remove your certificate. Note Certificates defined in the configuration files cannot be edited or removed. To edit a certificate name and description: Choose a certificate to edit and click the Edit link. Introduce the required changes in the text fields. Click the Save button. To download a certificate: Choose a certificate to download and click the Download link. The certificate will be downloaded automatically to your drive. To remove a certificate: Choose a certificate to remove and click the Remove link. Click the Confirm button.","title":"Managing a certificate"},{"location":"User_Guide/User_Interface_Reference/Administration/DTLS_TLS_Certificates.html#adding-certificates-to-the-deny-list","text":"To make Coiote DM reject a device certificate, you need to add it to the Deny list . To do that, follow these steps: In the Administration \u2192 DTLS/TLS Certificates , go to the Deny list tab and click Add file . In the pop-up, specify name, description, and upload your certificate file by using the drag & drop function or the Browse button. Click Save . After the certificate has been added correctly to the list, you can remove, edit or download it in the same way as in the Trusted certificates list. Note The Deny list has precedence over the Trusted certificates list, so if a certificate is placed in both lists, the Server will reject it.","title":"Adding certificates to the Deny list"},{"location":"User_Guide/User_Interface_Reference/Administration/Expressions_Sandbox.html","text":"Expressions sandbox # Use Expressions sandbox to test your expressions in a safe, read-only mode without waiting for provisioning session with a device. You can create a context in which your expression will be evaluated. Layout # On the left side of the panel, you can specify your expression and you can see the results. On the right side of the panel, you can specify the context in which the expression will be executed. Select result type - use it to select a desired result type of an expression. The expression you write must return a value of a selected type. Write your expression - use it to write your expression here. If your expression is incorrect, then a background color of a text field will be red. To see error messages just hold the cursor over the text field. Click the icon on the right side of the field to open the text field as a pop-up. Evaluate expression - click this button to evaluate your expression. The results will be shown below. Select device - use it to execute the expression in a context of any device which exists in the system. Each device has its own device properties and data model parameters which you can use in the expression. Device navigation - use it to navigate through a devices list. Select task - use it to always execute the expression in a context of a task which exists on a selected device. The task has its own properties and report which you can use in the expression. Set local variables - an expression can use local variables which were defined, for example, in an XML task statement. You can set values of local variables here and use them in your expression. LWM2M context","title":"Expressions sandbox"},{"location":"User_Guide/User_Interface_Reference/Administration/Expressions_Sandbox.html#expressions-sandbox","text":"Use Expressions sandbox to test your expressions in a safe, read-only mode without waiting for provisioning session with a device. You can create a context in which your expression will be evaluated.","title":"Expressions sandbox"},{"location":"User_Guide/User_Interface_Reference/Administration/Expressions_Sandbox.html#layout","text":"On the left side of the panel, you can specify your expression and you can see the results. On the right side of the panel, you can specify the context in which the expression will be executed. Select result type - use it to select a desired result type of an expression. The expression you write must return a value of a selected type. Write your expression - use it to write your expression here. If your expression is incorrect, then a background color of a text field will be red. To see error messages just hold the cursor over the text field. Click the icon on the right side of the field to open the text field as a pop-up. Evaluate expression - click this button to evaluate your expression. The results will be shown below. Select device - use it to execute the expression in a context of any device which exists in the system. Each device has its own device properties and data model parameters which you can use in the expression. Device navigation - use it to navigate through a devices list. Select task - use it to always execute the expression in a context of a task which exists on a selected device. The task has its own properties and report which you can use in the expression. Set local variables - an expression can use local variables which were defined, for example, in an XML task statement. You can set values of local variables here and use them in your expression. LWM2M context","title":"Layout"},{"location":"User_Guide/User_Interface_Reference/Administration/Importing_monitoring_groups_from_CSV.html","text":"Importing monitoring groups from CSV # Learn how to import monitoring groups from a CSV file to prepare a group structure for monitoring maps. To import monitoring groups from a CSV file: Go to Administration and select Import monitoring groups . Tip Before you import a file, take a look at a table that shows how a structure of the file should look like. You can also click the download sample CSV link to download a sample file and use it while creating the correct file. If the first line of the file is not important, select the Skip CSV header (first line) check box. To include Cell group , Cell ID , Azimuth and Beam , select the Base station like device check box. From the Number of levels list, select how many administrative levels you want to include (up to 10 are possible). Click the Upload button to upload the file from your disk. Importing is not performed at this point. Select a root for your groups by clicking the Select group link and clicking the selected group. Click the Perform import button. Tip If any entry is duplicated, the first set of data is imported. Go to Device groups and on the list of groups you should see you monitoring groups. Go to Profiles and you can see Latitude , Longitude , Azimuth and Beam as setting values. Tip If you cleared the Base station like device check box, then Azimuth and Beam will not be set as setting values and Cell group and Cell ID will not create additional administrative levels. If the Beam column is empty in your file, then its value is set to 60 . Values of Latitude and Longitude for a parent are average of values of its children, if there is more than one child in the group. See also: Monitoring map","title":"Importing monitoring groups from CSV"},{"location":"User_Guide/User_Interface_Reference/Administration/Importing_monitoring_groups_from_CSV.html#importing-monitoring-groups-from-csv","text":"Learn how to import monitoring groups from a CSV file to prepare a group structure for monitoring maps. To import monitoring groups from a CSV file: Go to Administration and select Import monitoring groups . Tip Before you import a file, take a look at a table that shows how a structure of the file should look like. You can also click the download sample CSV link to download a sample file and use it while creating the correct file. If the first line of the file is not important, select the Skip CSV header (first line) check box. To include Cell group , Cell ID , Azimuth and Beam , select the Base station like device check box. From the Number of levels list, select how many administrative levels you want to include (up to 10 are possible). Click the Upload button to upload the file from your disk. Importing is not performed at this point. Select a root for your groups by clicking the Select group link and clicking the selected group. Click the Perform import button. Tip If any entry is duplicated, the first set of data is imported. Go to Device groups and on the list of groups you should see you monitoring groups. Go to Profiles and you can see Latitude , Longitude , Azimuth and Beam as setting values. Tip If you cleared the Base station like device check box, then Azimuth and Beam will not be set as setting values and Cell group and Cell ID will not create additional administrative levels. If the Beam column is empty in your file, then its value is set to 60 . Values of Latitude and Longitude for a parent are average of values of its children, if there is more than one child in the group. See also: Monitoring map","title":"Importing monitoring groups from CSV"},{"location":"User_Guide/User_Interface_Reference/Administration/Licensing_Info.html","text":"Licensing info # Read this panel to learn basic information about the license. Vocabulary # This section contains information about common terms used in this chapter: License point - a point to be assigned to an incoming device, meaning that the device can be provisioned. Assignment can be permanent and is a one-time operation. Pool - a group of license points. Layout # System version - a system build version. Client identifier - a client identification data. License ID - a license unique ID. Generated at - the license generation date and time. Current time - a current date and time. Valid until - the license expiration date and time. Number of devices - a total number of devices in the system. Provisioned devices/Limit - a number of assigned license points/a maximum number of license points to be assigned (pool). Current/Licensed users count - an actual number of users in the system/a maximum number of users. License status - a status of the license: VALID - the license verification successful. NOT VALID - the license is invalid or expired. Additional functionalities - a list of additional features covered by this license. Click the Load license button, paste your license and confirm by clicking the Load button. Description # This section covers the main licensing module functionalities. The license is periodically verified by the system. Following locations are checked for license data: A file system ( only during startup ): file license.dat in the Coiote DM main directory. A database: [ump.globalProperties].acs.license If both locations contain license data, the preferred one is the newest one - containing the license with the newest generation data (it matters only during the system startup). If license data is missing or invalid, the system may allow only to log in and prompt you for entering proper data. The provisioning is stopped till the successful validation of the new license. You can change this behavior using the system property: acs.license.allowLoginWhenLicenseMissing . If by any reason at any time, license verification reports invalidity, device provisioning also stops (for every device in the system). The main causes of this situation: A license state changes into invalid. A manual change in the license was made. Reaching the limit mentioned in the number 8 will not stop the provisioning for already licensed devices. Moreover, new incoming devices will still be added to the system but they will not be provisioned (as there is no more license points left). Reclaiming a license point # You can reclaim (reassign) license points using one of the below options. To reclaim a license point: Option 1 : Use the additional license option called DEVICE_REMOVAL_ALLOWED that allows you to reclaim a license point after removing a device. Option 2 : If you have a proper license you can schedule a task that automates points removal for inactive devices. It will check if there are any inactive devices and if there are, it will reclaim license points from them. Open a license file and find the following license fields: inactivityDays - states for how many days a device should not report to Coiote DM. removalPeriod - states after how many days license points will be removed from inactive devices and can be used for another devices (a periodic task). Look at the example of the license fragment below: <License> <extensions> <extension>MULTITENANCY</extension> <extension>RESOURCE_CLUSTER</extension> <extension>DEVICE_REMOVAL_ALLOWED</extension> <extension>MASS_DEVICE_REMOVAL_ALLOWED</extension> <extension>MONITORING</extension> <extension>LIVE_TOUCH</extension> <extension>LIFETIME_LICENSE</extension> </extensions> <inactivityDays>120</inactivityDays> <removalPeriod>30</removalPeriod> <signature>example signature</signature> </License> Notice that this license states that after 30 days, license points for devices that were inactive for 120 days will be removed and they can be used for another devices. Note Notice that this task does not remove inactive devices from UMP. It only reclaims license points. Decide on proper values in the license fields. Optionally, configure a task that will remove inactive devices and automatically generate a report: Open the cdm.conf file that can be found in the Coiote DM installation directory - installdir/config/default and installdir/config/customername . In the file, find the following system properties in the acs.license fragment: removeDevices - removes devices along with reclaimed points. reportRemoval - generates a report from the removal procedure. Set both system properties to true . The below example show the fragment of the file you should find in cdm.conf : acs { license { #subsequent alert interval in hours removeDevices = true reportRemoval = true } } To see the report after task completion: Log into Coiote DM and go to Monitoring & Reporting \u2014> Reports . On the list of reports, find Device removal report . Note The task described above cannot be run on demand. Additional functionalities of the system that are included in the license # The following functionalities can be included in the license: A possibility to use a device removal to reassign the license point after device removal Multitenancy Monitoring A possibility to buy a lifetime license.","title":"Licensing info"},{"location":"User_Guide/User_Interface_Reference/Administration/Licensing_Info.html#licensing-info","text":"Read this panel to learn basic information about the license.","title":"Licensing info"},{"location":"User_Guide/User_Interface_Reference/Administration/Licensing_Info.html#vocabulary","text":"This section contains information about common terms used in this chapter: License point - a point to be assigned to an incoming device, meaning that the device can be provisioned. Assignment can be permanent and is a one-time operation. Pool - a group of license points.","title":"Vocabulary"},{"location":"User_Guide/User_Interface_Reference/Administration/Licensing_Info.html#layout","text":"System version - a system build version. Client identifier - a client identification data. License ID - a license unique ID. Generated at - the license generation date and time. Current time - a current date and time. Valid until - the license expiration date and time. Number of devices - a total number of devices in the system. Provisioned devices/Limit - a number of assigned license points/a maximum number of license points to be assigned (pool). Current/Licensed users count - an actual number of users in the system/a maximum number of users. License status - a status of the license: VALID - the license verification successful. NOT VALID - the license is invalid or expired. Additional functionalities - a list of additional features covered by this license. Click the Load license button, paste your license and confirm by clicking the Load button.","title":"Layout"},{"location":"User_Guide/User_Interface_Reference/Administration/Licensing_Info.html#description","text":"This section covers the main licensing module functionalities. The license is periodically verified by the system. Following locations are checked for license data: A file system ( only during startup ): file license.dat in the Coiote DM main directory. A database: [ump.globalProperties].acs.license If both locations contain license data, the preferred one is the newest one - containing the license with the newest generation data (it matters only during the system startup). If license data is missing or invalid, the system may allow only to log in and prompt you for entering proper data. The provisioning is stopped till the successful validation of the new license. You can change this behavior using the system property: acs.license.allowLoginWhenLicenseMissing . If by any reason at any time, license verification reports invalidity, device provisioning also stops (for every device in the system). The main causes of this situation: A license state changes into invalid. A manual change in the license was made. Reaching the limit mentioned in the number 8 will not stop the provisioning for already licensed devices. Moreover, new incoming devices will still be added to the system but they will not be provisioned (as there is no more license points left).","title":"Description"},{"location":"User_Guide/User_Interface_Reference/Administration/Licensing_Info.html#reclaiming-a-license-point","text":"You can reclaim (reassign) license points using one of the below options. To reclaim a license point: Option 1 : Use the additional license option called DEVICE_REMOVAL_ALLOWED that allows you to reclaim a license point after removing a device. Option 2 : If you have a proper license you can schedule a task that automates points removal for inactive devices. It will check if there are any inactive devices and if there are, it will reclaim license points from them. Open a license file and find the following license fields: inactivityDays - states for how many days a device should not report to Coiote DM. removalPeriod - states after how many days license points will be removed from inactive devices and can be used for another devices (a periodic task). Look at the example of the license fragment below: <License> <extensions> <extension>MULTITENANCY</extension> <extension>RESOURCE_CLUSTER</extension> <extension>DEVICE_REMOVAL_ALLOWED</extension> <extension>MASS_DEVICE_REMOVAL_ALLOWED</extension> <extension>MONITORING</extension> <extension>LIVE_TOUCH</extension> <extension>LIFETIME_LICENSE</extension> </extensions> <inactivityDays>120</inactivityDays> <removalPeriod>30</removalPeriod> <signature>example signature</signature> </License> Notice that this license states that after 30 days, license points for devices that were inactive for 120 days will be removed and they can be used for another devices. Note Notice that this task does not remove inactive devices from UMP. It only reclaims license points. Decide on proper values in the license fields. Optionally, configure a task that will remove inactive devices and automatically generate a report: Open the cdm.conf file that can be found in the Coiote DM installation directory - installdir/config/default and installdir/config/customername . In the file, find the following system properties in the acs.license fragment: removeDevices - removes devices along with reclaimed points. reportRemoval - generates a report from the removal procedure. Set both system properties to true . The below example show the fragment of the file you should find in cdm.conf : acs { license { #subsequent alert interval in hours removeDevices = true reportRemoval = true } } To see the report after task completion: Log into Coiote DM and go to Monitoring & Reporting \u2014> Reports . On the list of reports, find Device removal report . Note The task described above cannot be run on demand.","title":"Reclaiming a license point"},{"location":"User_Guide/User_Interface_Reference/Administration/Licensing_Info.html#additional-functionalities-of-the-system-that-are-included-in-the-license","text":"The following functionalities can be included in the license: A possibility to use a device removal to reassign the license point after device removal Multitenancy Monitoring A possibility to buy a lifetime license.","title":"Additional functionalities of the system that are included in the license"},{"location":"User_Guide/User_Interface_Reference/Administration/LwM2M_servers.html","text":"LwM2M servers # Use LwM2M servers menu to add LwM2M servers (both Bootstrap and Management) and use them later to configure a bootstrap procedure by using a task or a bootstrap profile. Tip By default, four preconfigured servers are created - Management with and without PSK, and Bootstrap with and without PSK. Layout # Search - use it to look for particular data by typing it into the field. Add - use it to add a new server. Table - use it to view server's settings or delete a server (after clicking the delete icon you will be informed if any tasks and task templates are assigned. You need to keep in mind, that they will be deleted with the server). Click a particular server to see its details and edit its settings. Configure a LwM2M server : Name - a name in a human-readable format. It will be used to refer to the server configuration in the Coiote DM system. When using a task it is better to refer to the server by its ID rather than name. Server type - a type of a server: Management or Bootstrap . Transport - a type of a protocol - TCP or UDP . SSID - an ID of the server from the device perspective. URI - the server hostname and port are specified in this field. The system automatically adds a schema (coap:// or coaps://) depending on a selected security mode. It is also not necessary to provide a port because the system appends a default one instantly. Client hold off time - a defined period of time to wait before initiating a Client Initiated Bootstrap once a device (LwM2M Client) has determined it should initiate this bootstrap mode. This option allows to perform Server Initiated Bootstrap within the defined time. Bootstrap-server account timeout - the device deletes the LwM2M Bootstrap Server Account after the defined timeout value. Binding - a type of a biding. Some of binding types has Queue Mode. When Queue Mode is set the server can send a request to the device only if it is online. The device is online immediately after the Registration request is sent and it lasts for ACK_TIMEOUT. Timeout is prolonged by ACK_TIMEOUT if during being online the device receives any request from the server. A value of ACK_TIMEOUT depends on device implementation (a default value is 2 seconds). The below types are available: U (UDP) - the server expects that the device is reachable via the UDP binding all the time it is registered (see the Lifetime description below). All communication between uses UDP binding. This is a standard mode of operation. UQ (UDP with Queue Mode) - the server queues all requests to the device and sends them via UDP when the device is online. All communication between uses the UDP binding. S (SMS) - the server expects that the device is reachable via the SMS binding all the time it is registered (see the Lifetime description below). All communication between uses the SMS binding. SQ (SMS with Queue Mode) - the server queues all requests to the device and sends them via UDP when the device is online. All communication between uses the SMS binding. US (UDP and SMS) - the server expects that the device is reachable via UDP and SMS bindings all the time it is registered (see the Lifetime description below). When communication is initialized using the UDP or SMS binging, a response must be sent over the same binding. UQS (UDP with Queue Mode and SMS) - the server queues all requests to the device and sends them via UDP when the device is online. The server expects that the device is reachable via the SMS binding at any time. If the server sends requests to the device using the UDP binding, a response is sent over the same biding. If the server sends requests to the device using the SMS binding, a response is sent over the same biding. The server may request the device to perform the Update operation via UDP by sending the Execute operation on the Registration Update Trigger resource via SMS. Lifetime - a meaning of this parameter depends on a binding type: For direct bindings, that is U , S and US it is a period of time after which the device is accessible after the Register or Update operation. If the device needs to be accessible the whole time, updates must be sent before time defined in the field elapses. The device can also send Deregister to inform that it will not be available anymore. For bindings with Queue Mode, that is UQ , SQ and USQ it is maximal time between consequent registrations. The device is accessible only when it is online (as described above). Additionally, in the USQ mode during a lifetime period LwM2M Server can send SMS to wake up the device (see the UQS binding description above). Note If traffic between the device and the server passes through a public network, the device may get inaccessible to the server before lifetime elapses. It happens because the device uses an ephemeral port to communicate, and NATs on the way may drop its association, and effectively drop all messages from the server to the device. Store notifications - use it to decide if the device should store notifications when it is in the Deregister phase and then send them to the server, or discard them. Security mode - use it to configure security mode: NoSec - no security mode is set, it could be used only in the test environment. Pre-Shared Key - communication between the device and the server will be encrypted. To decrypt the communication, PSK identity and PSK are needed. Note that the bootstrap procedure will set these values on the device, but not on the server. PSK identity - identification of the device during DTLS Handshake. It is recommended to use a default value (so that the device has the same PSK identity and the endpoint name). PSK - the actual key (password) shared between the device and the server. Note For greater security, you can use the ${string.secureRandom(enter any number)} expression by typing it into the PSK field. Support SMS - select it if the server supports communication over SMS. Note that this option is available only when S , SQ , US or UQS bindings are used. SMS number SMS security mode - use it to configure a security mode. Configure device on target server - use it to create device entity on target server via API and add it to the correct domain automatically. This option is required for the bootstrap procedure to work if adding devices automatically on the target server is off. Provision credentials to the server - use it to provide credentials to the server if the configured server is Coiote DM. AVSystem API URI - URI to the Rest API API user - an API user API password - a user password. Save / Cancel - use them to save or cancel an action you performed.","title":"LwM2M servers"},{"location":"User_Guide/User_Interface_Reference/Administration/LwM2M_servers.html#lwm2m-servers","text":"Use LwM2M servers menu to add LwM2M servers (both Bootstrap and Management) and use them later to configure a bootstrap procedure by using a task or a bootstrap profile. Tip By default, four preconfigured servers are created - Management with and without PSK, and Bootstrap with and without PSK.","title":"LwM2M servers"},{"location":"User_Guide/User_Interface_Reference/Administration/LwM2M_servers.html#layout","text":"Search - use it to look for particular data by typing it into the field. Add - use it to add a new server. Table - use it to view server's settings or delete a server (after clicking the delete icon you will be informed if any tasks and task templates are assigned. You need to keep in mind, that they will be deleted with the server). Click a particular server to see its details and edit its settings. Configure a LwM2M server : Name - a name in a human-readable format. It will be used to refer to the server configuration in the Coiote DM system. When using a task it is better to refer to the server by its ID rather than name. Server type - a type of a server: Management or Bootstrap . Transport - a type of a protocol - TCP or UDP . SSID - an ID of the server from the device perspective. URI - the server hostname and port are specified in this field. The system automatically adds a schema (coap:// or coaps://) depending on a selected security mode. It is also not necessary to provide a port because the system appends a default one instantly. Client hold off time - a defined period of time to wait before initiating a Client Initiated Bootstrap once a device (LwM2M Client) has determined it should initiate this bootstrap mode. This option allows to perform Server Initiated Bootstrap within the defined time. Bootstrap-server account timeout - the device deletes the LwM2M Bootstrap Server Account after the defined timeout value. Binding - a type of a biding. Some of binding types has Queue Mode. When Queue Mode is set the server can send a request to the device only if it is online. The device is online immediately after the Registration request is sent and it lasts for ACK_TIMEOUT. Timeout is prolonged by ACK_TIMEOUT if during being online the device receives any request from the server. A value of ACK_TIMEOUT depends on device implementation (a default value is 2 seconds). The below types are available: U (UDP) - the server expects that the device is reachable via the UDP binding all the time it is registered (see the Lifetime description below). All communication between uses UDP binding. This is a standard mode of operation. UQ (UDP with Queue Mode) - the server queues all requests to the device and sends them via UDP when the device is online. All communication between uses the UDP binding. S (SMS) - the server expects that the device is reachable via the SMS binding all the time it is registered (see the Lifetime description below). All communication between uses the SMS binding. SQ (SMS with Queue Mode) - the server queues all requests to the device and sends them via UDP when the device is online. All communication between uses the SMS binding. US (UDP and SMS) - the server expects that the device is reachable via UDP and SMS bindings all the time it is registered (see the Lifetime description below). When communication is initialized using the UDP or SMS binging, a response must be sent over the same binding. UQS (UDP with Queue Mode and SMS) - the server queues all requests to the device and sends them via UDP when the device is online. The server expects that the device is reachable via the SMS binding at any time. If the server sends requests to the device using the UDP binding, a response is sent over the same biding. If the server sends requests to the device using the SMS binding, a response is sent over the same biding. The server may request the device to perform the Update operation via UDP by sending the Execute operation on the Registration Update Trigger resource via SMS. Lifetime - a meaning of this parameter depends on a binding type: For direct bindings, that is U , S and US it is a period of time after which the device is accessible after the Register or Update operation. If the device needs to be accessible the whole time, updates must be sent before time defined in the field elapses. The device can also send Deregister to inform that it will not be available anymore. For bindings with Queue Mode, that is UQ , SQ and USQ it is maximal time between consequent registrations. The device is accessible only when it is online (as described above). Additionally, in the USQ mode during a lifetime period LwM2M Server can send SMS to wake up the device (see the UQS binding description above). Note If traffic between the device and the server passes through a public network, the device may get inaccessible to the server before lifetime elapses. It happens because the device uses an ephemeral port to communicate, and NATs on the way may drop its association, and effectively drop all messages from the server to the device. Store notifications - use it to decide if the device should store notifications when it is in the Deregister phase and then send them to the server, or discard them. Security mode - use it to configure security mode: NoSec - no security mode is set, it could be used only in the test environment. Pre-Shared Key - communication between the device and the server will be encrypted. To decrypt the communication, PSK identity and PSK are needed. Note that the bootstrap procedure will set these values on the device, but not on the server. PSK identity - identification of the device during DTLS Handshake. It is recommended to use a default value (so that the device has the same PSK identity and the endpoint name). PSK - the actual key (password) shared between the device and the server. Note For greater security, you can use the ${string.secureRandom(enter any number)} expression by typing it into the PSK field. Support SMS - select it if the server supports communication over SMS. Note that this option is available only when S , SQ , US or UQS bindings are used. SMS number SMS security mode - use it to configure a security mode. Configure device on target server - use it to create device entity on target server via API and add it to the correct domain automatically. This option is required for the bootstrap procedure to work if adding devices automatically on the target server is off. Provision credentials to the server - use it to provide credentials to the server if the configured server is Coiote DM. AVSystem API URI - URI to the Rest API API user - an API user API password - a user password. Save / Cancel - use them to save or cancel an action you performed.","title":"Layout"},{"location":"User_Guide/User_Interface_Reference/Administration/Predefined_Schedules_Editor.html","text":"Predefined schedules # Schedules are used in many cases in UMP. For example, you can select time periods when the server can execute a task or when a user can log in to the system. This document deals with predefined schedules. These are named, pre-configured, globally visible schedules. Layout # Use the Predefined schedules editor to manage all predefined schedules in the system. Go to Administration \u2014> Predefined schedules . The main table lists all existing predefined schedules in the system. You can select one, see its details, and modify or delete it. Use the buttons to add new or delete predefined schedules. Schedule details panel contains interface for editing the schedule. Schedules do not have to be unique in any way, but it is a good practice to give them unique descriptions. Warning Remember that editing predefined schedules has impact on devices to which these schedules are assigned so be careful while doing any modifications. There are several predefined schedules available by default. Active time periods (denoted by green boxes in the editor) are described here: Nights-enterprise - everyday (non-business hours) between 19:00 and 06:00 Nights-enterprise-weekends - a sum of nights-enterprise and weekends , that is, Monday to Friday between 19:00 and 06:00, Saturday and Sunday Nights-home - every night between 01:00 and 06:00 Weekends - Saturday and Sunday day and night (00:00-24:00) Note These schedules are maintained by the system - any changes will be lost after the next Coiote DM restart. Adding a new predefined schedule # To add a new predefined schedule: Click the New button. Enter a schedule description. Optional: Type start and end dates. To do this, select check boxes next to these fields. On a time map with 15 minutes resolution where green color denotes active (allowed) time periods, and red denotes not allowed ones, select proper time periods. You can change a color by clicking and dragging it. To revert your selection, click the Revert map button. Click the Save button. Editing the predefined schedule # To edit a predefined schedule: From the list, select a schedule. The panel in the bottom should display schedule details editing interface. Provide new details. Click the Save button. Deleting the predefined schedule # Tip You will not be able to delete a schedule that is assigned to task or task template, user or user template, or group action trigger. You will see a warning while trying to delete it. To delete a predefined schedule: From the list, select the schedule. Click the Delete button. The schedule will be deleted from the system after confirming this action. Where predefined schedules are used? # Look at the list below to see places where you can use predefined schedules: Group action trigger - you can select time periods when connections requests can be executed. Task templates - you can select time periods when a task based on a template can be executed.","title":"Predefined schedules"},{"location":"User_Guide/User_Interface_Reference/Administration/Predefined_Schedules_Editor.html#predefined-schedules","text":"Schedules are used in many cases in UMP. For example, you can select time periods when the server can execute a task or when a user can log in to the system. This document deals with predefined schedules. These are named, pre-configured, globally visible schedules.","title":"Predefined schedules"},{"location":"User_Guide/User_Interface_Reference/Administration/Predefined_Schedules_Editor.html#layout","text":"Use the Predefined schedules editor to manage all predefined schedules in the system. Go to Administration \u2014> Predefined schedules . The main table lists all existing predefined schedules in the system. You can select one, see its details, and modify or delete it. Use the buttons to add new or delete predefined schedules. Schedule details panel contains interface for editing the schedule. Schedules do not have to be unique in any way, but it is a good practice to give them unique descriptions. Warning Remember that editing predefined schedules has impact on devices to which these schedules are assigned so be careful while doing any modifications. There are several predefined schedules available by default. Active time periods (denoted by green boxes in the editor) are described here: Nights-enterprise - everyday (non-business hours) between 19:00 and 06:00 Nights-enterprise-weekends - a sum of nights-enterprise and weekends , that is, Monday to Friday between 19:00 and 06:00, Saturday and Sunday Nights-home - every night between 01:00 and 06:00 Weekends - Saturday and Sunday day and night (00:00-24:00) Note These schedules are maintained by the system - any changes will be lost after the next Coiote DM restart.","title":"Layout"},{"location":"User_Guide/User_Interface_Reference/Administration/Predefined_Schedules_Editor.html#adding-a-new-predefined-schedule","text":"To add a new predefined schedule: Click the New button. Enter a schedule description. Optional: Type start and end dates. To do this, select check boxes next to these fields. On a time map with 15 minutes resolution where green color denotes active (allowed) time periods, and red denotes not allowed ones, select proper time periods. You can change a color by clicking and dragging it. To revert your selection, click the Revert map button. Click the Save button.","title":"Adding a new predefined schedule"},{"location":"User_Guide/User_Interface_Reference/Administration/Predefined_Schedules_Editor.html#editing-the-predefined-schedule","text":"To edit a predefined schedule: From the list, select a schedule. The panel in the bottom should display schedule details editing interface. Provide new details. Click the Save button.","title":"Editing the predefined schedule"},{"location":"User_Guide/User_Interface_Reference/Administration/Predefined_Schedules_Editor.html#deleting-the-predefined-schedule","text":"Tip You will not be able to delete a schedule that is assigned to task or task template, user or user template, or group action trigger. You will see a warning while trying to delete it. To delete a predefined schedule: From the list, select the schedule. Click the Delete button. The schedule will be deleted from the system after confirming this action.","title":"Deleting the predefined schedule"},{"location":"User_Guide/User_Interface_Reference/Administration/Predefined_Schedules_Editor.html#where-predefined-schedules-are-used","text":"Look at the list below to see places where you can use predefined schedules: Group action trigger - you can select time periods when connections requests can be executed. Task templates - you can select time periods when a task based on a template can be executed.","title":"Where predefined schedules are used?"},{"location":"User_Guide/User_Interface_Reference/Administration/Resources.html","text":"Resources # Use this panel to browse, edit and add new resources to the system. Panel layout # There are three main elements of the panel layout: Search bar and navigation buttons The Add link Resources table Search bar and navigation buttons # Item display buttons (1-6) make navigation between objects easy and intuitive. Items per page - click it to select how many resources you want to see on a single page (25, 50, 100). Navigation arrows - click arrows to change pages. Show all resources - click it to display all types of resources. Show only firmware - click it to show only firmware. Show other resources than firmware - click it to show resources other than firmware (for example, logs or configuration files). Add - click it to upload a new file with certain properties. Resources details # Name - unique resource name. File Source - select if the resource is local or external. Local file means that the file will be stored on the server after you click the Upload and Save buttons. If you select the External URL option, you will see a field for a link to the resource. Upload - click it and select a local file which you want to upload. When the file is selected uploading starts immediately. Remember that the file cannot be bigger than a configured size limit. File name - this name is set automatically by Coiote DM based on a uploaded file name, it can be overwritten. Access - password and username to secure the resource. Domain - indicates a domain of system users that are allowed to see this resource. Visible for subtenants - select it if you want the resource to be visible for all your subtenants. This also applies, for example, to the static documentation category, which means that your subtenants will be able to view the files you include in the top menu Help . Category - category of the resource file. Note Select the static-documentation category to include the file into the top menu Help . Both external and internal files are accepted. After you upload the file, remember to log out and log in again to see the result. Static content - it gives a resource a static URL accessible outside the system. This check box is disabled by default but it can be enabled so that creating the static URL is possible. It can be done by changing one parameter value in configuration (learn how to do this in the Enabling generation of a static content section of Admin Guide). Description - file description. Device types - it allows you to bind the resource and the device type. To do so click the Add tab first, then select device types (you can select multiple with the Ctrl key). After that click Add selected . Important When you add firmware resources you need to add them to groups (preferably to device type groups), otherwise they will not be visible in DMC . Save/Cancel - after uploading a file and editing all necessary fields, click Save to add the resource or Cancel to discard changes. Resources table # ID - a database ID. Type - it indicates a resource type. Name - a name of the resource. File name - a name of a downloaded file. Size - a file size in B/kB/MB. Creation time - time when the resource was created. Description - a short description of the resource. Domain - it indicates system users that are allowed to see this resource. Delete - click it to delete that resource.","title":"Resources"},{"location":"User_Guide/User_Interface_Reference/Administration/Resources.html#resources","text":"Use this panel to browse, edit and add new resources to the system.","title":"Resources"},{"location":"User_Guide/User_Interface_Reference/Administration/Resources.html#panel-layout","text":"There are three main elements of the panel layout: Search bar and navigation buttons The Add link Resources table","title":"Panel layout"},{"location":"User_Guide/User_Interface_Reference/Administration/Resources.html#search-bar-and-navigation-buttons","text":"Item display buttons (1-6) make navigation between objects easy and intuitive. Items per page - click it to select how many resources you want to see on a single page (25, 50, 100). Navigation arrows - click arrows to change pages. Show all resources - click it to display all types of resources. Show only firmware - click it to show only firmware. Show other resources than firmware - click it to show resources other than firmware (for example, logs or configuration files). Add - click it to upload a new file with certain properties.","title":"Search bar and navigation buttons"},{"location":"User_Guide/User_Interface_Reference/Administration/Resources.html#resources-details","text":"Name - unique resource name. File Source - select if the resource is local or external. Local file means that the file will be stored on the server after you click the Upload and Save buttons. If you select the External URL option, you will see a field for a link to the resource. Upload - click it and select a local file which you want to upload. When the file is selected uploading starts immediately. Remember that the file cannot be bigger than a configured size limit. File name - this name is set automatically by Coiote DM based on a uploaded file name, it can be overwritten. Access - password and username to secure the resource. Domain - indicates a domain of system users that are allowed to see this resource. Visible for subtenants - select it if you want the resource to be visible for all your subtenants. This also applies, for example, to the static documentation category, which means that your subtenants will be able to view the files you include in the top menu Help . Category - category of the resource file. Note Select the static-documentation category to include the file into the top menu Help . Both external and internal files are accepted. After you upload the file, remember to log out and log in again to see the result. Static content - it gives a resource a static URL accessible outside the system. This check box is disabled by default but it can be enabled so that creating the static URL is possible. It can be done by changing one parameter value in configuration (learn how to do this in the Enabling generation of a static content section of Admin Guide). Description - file description. Device types - it allows you to bind the resource and the device type. To do so click the Add tab first, then select device types (you can select multiple with the Ctrl key). After that click Add selected . Important When you add firmware resources you need to add them to groups (preferably to device type groups), otherwise they will not be visible in DMC . Save/Cancel - after uploading a file and editing all necessary fields, click Save to add the resource or Cancel to discard changes.","title":"Resources details"},{"location":"User_Guide/User_Interface_Reference/Administration/Resources.html#resources-table","text":"ID - a database ID. Type - it indicates a resource type. Name - a name of the resource. File name - a name of a downloaded file. Size - a file size in B/kB/MB. Creation time - time when the resource was created. Description - a short description of the resource. Domain - it indicates system users that are allowed to see this resource. Delete - click it to delete that resource.","title":"Resources table"},{"location":"User_Guide/User_Interface_Reference/Administration/Task_Templates.html","text":"Task templates # Task templates are pre-configured tasks stencil that can be used as a foundation for specific task configuration. This is a feature intended to save your time, if you need to frequently schedule similar tasks or want to execute complicated ones. Common practice is to provide Quick Fix actions for common problems. The Task template editor is available in Administration \u2014> Task templates . Layout # Except setting Template settings (1), (notice the multitenancy domain - which allows you to create a template for a specific tenant, more in Managing multitenancy creating a task template is like creating a new task. A comprehensive description can be found in Tasks . Template settings - a template configuration. Template name - a unique name of a task template, it should briefly explain what the template is all about (as it is displayed in the Task type or template (4) section) (a required field). Template domain - a multitenancy domain string (more details in Managing multitenancy ). Description - a human readable description of a purpose of this template. Quick Fix action - select this field if you wish to make the Quick Fix from that template. It means that the template will be accessible from Device Management Center , Device groups details . To learn how to create the Quick Fix action from the task template, read the Creating Quick Fixes from a task template chapter. Action name - if the Quick Fix action is selected then you must provide a name for Quick Fix - it must be unique and will be displayed on UI, this name can be different than the template name (a required field). Require confirmation - select it to ask for confirmation before the task is executed. Connection request behavior - it indicates when a connection request should be executed, select one of the options: Never execute - Coiote DM never executes the connection request. Always ask - Coiote DM asks each time you select the action, if the connection request should be executed. Always execute - Coiote DM always executes the connection request to speed up the provisioning process. Action required permission - it informs if a particular permission is required to perform the task. Action icon - select an icon for the action (more details in Picking an icon for Quick Fix . Prefer restart - Coiote DM restarts the action instead of creating the new one. It is useful for frequently used actions. Tip If you select the Prefer restart option, a task history will contain only the last execution of Quick Fix , however all historic executions will be available in Historical analysis . Task type or template - use it to select an existing template, edit it or select the task type to add the new template. Task settings - use it to set settings of the task that will be created from that template (more details in Tasks . Actions - actions that can be performed on a currently edited task template: Save - use it to save the current template. Save as new template - use it to add a new task template (available if you modify the template settings). Delete - use it to delete the current template. Cancel - use it to cancel current edition without saving changes. Task type summary - detailed information about a task type (more details in Tasks and a currently selected task template. Task specific configuration - use it to configure a task. Task template parameters - a list of parameters that you must provide before a task will be created. Add parameter - use this button to configure additional parameters, click the Add to add a new entry. Task configuration - it contains an XML editor (more details in XML task editor . Adding a new task template # To add the task template go to Administration \u2014> Task templates and: Provide a name. Select a domain (more details in Managing multitenancy ). Add a template description. Optional: Select Quick Fix and fill required fields. Select the task type (you can use the search). Provide a task configuration. Save the task template form by clicking the Add new template button or discard changes by clicking the Cancel button. Picking an icon for Quick Fix # Search for an icon name. Click a row to select the icon. Click to close a window without selection. Template use # Templates can be used in the following contexts: Global - Device actions \u2014> Tasks \u2014> Add new task Group - Device groups \u2014> Group tasks \u2014> Add task Device - Device inventory \u2014> Device Management Center \u2014> Device tasks \u2014> Add new task Executing Quick Fix # Quick Fixes can be triggered form the Device inventory view or from the Customer Care view. If the Quick Fixes actions require an additional input, then a proper prompt will be displayed. An example of the Quick Fix action input: Saving a task as a template # Specify the task type. Optional: Select one of predefined task templates shown in a violet font. Configure task settings including general parameters of the task execution. More details in Tasks . Provide a task specific configuration including task commands. Tasks can be saved as a task template from the standard task editor by clicking the Save as template button. Clicking the Cancel button takes you to the previous view. Fill in all required template data as described above. To save the template click the Confirm button. To discard changes click the Cancel button.","title":"Task templates"},{"location":"User_Guide/User_Interface_Reference/Administration/Task_Templates.html#task-templates","text":"Task templates are pre-configured tasks stencil that can be used as a foundation for specific task configuration. This is a feature intended to save your time, if you need to frequently schedule similar tasks or want to execute complicated ones. Common practice is to provide Quick Fix actions for common problems. The Task template editor is available in Administration \u2014> Task templates .","title":"Task templates"},{"location":"User_Guide/User_Interface_Reference/Administration/Task_Templates.html#layout","text":"Except setting Template settings (1), (notice the multitenancy domain - which allows you to create a template for a specific tenant, more in Managing multitenancy creating a task template is like creating a new task. A comprehensive description can be found in Tasks . Template settings - a template configuration. Template name - a unique name of a task template, it should briefly explain what the template is all about (as it is displayed in the Task type or template (4) section) (a required field). Template domain - a multitenancy domain string (more details in Managing multitenancy ). Description - a human readable description of a purpose of this template. Quick Fix action - select this field if you wish to make the Quick Fix from that template. It means that the template will be accessible from Device Management Center , Device groups details . To learn how to create the Quick Fix action from the task template, read the Creating Quick Fixes from a task template chapter. Action name - if the Quick Fix action is selected then you must provide a name for Quick Fix - it must be unique and will be displayed on UI, this name can be different than the template name (a required field). Require confirmation - select it to ask for confirmation before the task is executed. Connection request behavior - it indicates when a connection request should be executed, select one of the options: Never execute - Coiote DM never executes the connection request. Always ask - Coiote DM asks each time you select the action, if the connection request should be executed. Always execute - Coiote DM always executes the connection request to speed up the provisioning process. Action required permission - it informs if a particular permission is required to perform the task. Action icon - select an icon for the action (more details in Picking an icon for Quick Fix . Prefer restart - Coiote DM restarts the action instead of creating the new one. It is useful for frequently used actions. Tip If you select the Prefer restart option, a task history will contain only the last execution of Quick Fix , however all historic executions will be available in Historical analysis . Task type or template - use it to select an existing template, edit it or select the task type to add the new template. Task settings - use it to set settings of the task that will be created from that template (more details in Tasks . Actions - actions that can be performed on a currently edited task template: Save - use it to save the current template. Save as new template - use it to add a new task template (available if you modify the template settings). Delete - use it to delete the current template. Cancel - use it to cancel current edition without saving changes. Task type summary - detailed information about a task type (more details in Tasks and a currently selected task template. Task specific configuration - use it to configure a task. Task template parameters - a list of parameters that you must provide before a task will be created. Add parameter - use this button to configure additional parameters, click the Add to add a new entry. Task configuration - it contains an XML editor (more details in XML task editor .","title":"Layout"},{"location":"User_Guide/User_Interface_Reference/Administration/Task_Templates.html#adding-a-new-task-template","text":"To add the task template go to Administration \u2014> Task templates and: Provide a name. Select a domain (more details in Managing multitenancy ). Add a template description. Optional: Select Quick Fix and fill required fields. Select the task type (you can use the search). Provide a task configuration. Save the task template form by clicking the Add new template button or discard changes by clicking the Cancel button.","title":"Adding a new task template"},{"location":"User_Guide/User_Interface_Reference/Administration/Task_Templates.html#picking-an-icon-for-quick-fix","text":"Search for an icon name. Click a row to select the icon. Click to close a window without selection.","title":"Picking an icon for Quick Fix"},{"location":"User_Guide/User_Interface_Reference/Administration/Task_Templates.html#template-use","text":"Templates can be used in the following contexts: Global - Device actions \u2014> Tasks \u2014> Add new task Group - Device groups \u2014> Group tasks \u2014> Add task Device - Device inventory \u2014> Device Management Center \u2014> Device tasks \u2014> Add new task","title":"Template use"},{"location":"User_Guide/User_Interface_Reference/Administration/Task_Templates.html#executing-quick-fix","text":"Quick Fixes can be triggered form the Device inventory view or from the Customer Care view. If the Quick Fixes actions require an additional input, then a proper prompt will be displayed. An example of the Quick Fix action input:","title":"Executing Quick Fix"},{"location":"User_Guide/User_Interface_Reference/Administration/Task_Templates.html#saving-a-task-as-a-template","text":"Specify the task type. Optional: Select one of predefined task templates shown in a violet font. Configure task settings including general parameters of the task execution. More details in Tasks . Provide a task specific configuration including task commands. Tasks can be saved as a task template from the standard task editor by clicking the Save as template button. Clicking the Cancel button takes you to the previous view. Fill in all required template data as described above. To save the template click the Confirm button. To discard changes click the Cancel button.","title":"Saving a task as a template"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Adding_CSV_export_configurations.html","text":"Adding CSV export configurations # Read this section to learn how to create a new export configuration. To add a CSV export configuration: Go to Administration and select CSV Import/Export templates . Click CSV export configuration . Click the Add icon. Provide a name for a configuration. From the list select whether you want to export devices or assets. Select one of editor modes: Simple - to add a column, click it in the Available operations table. Expressions - to add the column, click the Add column link and start typing expressions. To see expression suggestions for a device, use the Select representative of imported devices option. Plain text - to add the column, start typing expressions. You should type one column name and expression per line, for example, Identity,${device.id} . After adding all columns you can remove, edit or move them: To remove a column in the Expressions or Simple tab, click the Remove icon next to it. To edit the column, go to the Expressions or Plain text tab, and make necessary changes. To change an order of columns, go to the Simple tab, and use the drag and drop functionality. Click the Save button. What to do next: Use the newly created CSV export configuration, for example, to export devices to CSV in Device inventory .","title":"Adding CSV export configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Adding_CSV_export_configurations.html#adding-csv-export-configurations","text":"Read this section to learn how to create a new export configuration. To add a CSV export configuration: Go to Administration and select CSV Import/Export templates . Click CSV export configuration . Click the Add icon. Provide a name for a configuration. From the list select whether you want to export devices or assets. Select one of editor modes: Simple - to add a column, click it in the Available operations table. Expressions - to add the column, click the Add column link and start typing expressions. To see expression suggestions for a device, use the Select representative of imported devices option. Plain text - to add the column, start typing expressions. You should type one column name and expression per line, for example, Identity,${device.id} . After adding all columns you can remove, edit or move them: To remove a column in the Expressions or Simple tab, click the Remove icon next to it. To edit the column, go to the Expressions or Plain text tab, and make necessary changes. To change an order of columns, go to the Simple tab, and use the drag and drop functionality. Click the Save button. What to do next: Use the newly created CSV export configuration, for example, to export devices to CSV in Device inventory .","title":"Adding CSV export configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Adding_CSV_export_configurations_for_monitoring.html","text":"Adding CSV monitoring data export configurations # Read this section to learn how to create a new export configuration for monitoring data that you can use later to generate a report. To add a CSV monitoring data export configuration: Go to Administration and select CSV Import/Export templates . Click Monitoring data export configuration . Click the Add icon. Into the Name field, type a unique name for a configuration (it will be later visible in Reports ). To include some additional data (for example, domain, hardware version or other setting values) from other CSV export configurations, select a proper export configuration name. To learn how to add the CSV export configuration, that you can use in this procedure, read the Adding CSV export configurations chapter. Add as many monitoring resources as you need from different monitoring types by clicking the Add monitoring resources button. Configure each of resource in the following way: From the Monitoring (required) list, select a monitoring name. From the Resource (required) list, select a monitoring resource. From the Resource match type (required) list, select: Exact match if a resource selected from the Resource (required) list is an exact match. Prefix if a resource selected from the Resource (required) list is only a prefix of existing resources. Then all resources starting with this prefix will be exported. Into the Resource alias field, type a meaningful name for the column in which the selected resource will appear. It is recommended to include a type of aggregation in the name, for example, Maximum of received bytes . If you do not specify the name, then the raw name of the resource will be taken. From the Aggregation (required) list, select a way in which data should be aggregated. Available aggregation types depend on the type of the selected resource: For numerical parameters you will have: Average , Maximum , Minimum , Sum , and Sum of delta (for monitored numerical parameters, such as uptime or bytes sent or received, which data type is a counter in order to calculate an accurate sum in a data range, it is necessary to find a sum of peaks in data series and subtract the first and last value). For alerts you will have: Count (a number showing how many times the selected alert occurred) and Percentage (a percentage of alert samples). For textual parameters you will not be able to select aggregation because such values cannot be aggregated. You will see the - sign in a row. Tip To delete a particular resource, click the Remove button next to it. An aggregation type is not taken into consideration, if you select the Raw export type while scheduling the report. Click the Save button. What to do next: Use the newly created CSV monitoring data export configuration to schedule Advanced CSV Report in Monitoring & Reporting \u2192 Reports . Read how to do it in the Scheduling advanced CSV report chapter. See also: Scheduling advanced CSV report Adding CSV export configurations","title":"Adding CSV monitoring data export configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Adding_CSV_export_configurations_for_monitoring.html#adding-csv-monitoring-data-export-configurations","text":"Read this section to learn how to create a new export configuration for monitoring data that you can use later to generate a report. To add a CSV monitoring data export configuration: Go to Administration and select CSV Import/Export templates . Click Monitoring data export configuration . Click the Add icon. Into the Name field, type a unique name for a configuration (it will be later visible in Reports ). To include some additional data (for example, domain, hardware version or other setting values) from other CSV export configurations, select a proper export configuration name. To learn how to add the CSV export configuration, that you can use in this procedure, read the Adding CSV export configurations chapter. Add as many monitoring resources as you need from different monitoring types by clicking the Add monitoring resources button. Configure each of resource in the following way: From the Monitoring (required) list, select a monitoring name. From the Resource (required) list, select a monitoring resource. From the Resource match type (required) list, select: Exact match if a resource selected from the Resource (required) list is an exact match. Prefix if a resource selected from the Resource (required) list is only a prefix of existing resources. Then all resources starting with this prefix will be exported. Into the Resource alias field, type a meaningful name for the column in which the selected resource will appear. It is recommended to include a type of aggregation in the name, for example, Maximum of received bytes . If you do not specify the name, then the raw name of the resource will be taken. From the Aggregation (required) list, select a way in which data should be aggregated. Available aggregation types depend on the type of the selected resource: For numerical parameters you will have: Average , Maximum , Minimum , Sum , and Sum of delta (for monitored numerical parameters, such as uptime or bytes sent or received, which data type is a counter in order to calculate an accurate sum in a data range, it is necessary to find a sum of peaks in data series and subtract the first and last value). For alerts you will have: Count (a number showing how many times the selected alert occurred) and Percentage (a percentage of alert samples). For textual parameters you will not be able to select aggregation because such values cannot be aggregated. You will see the - sign in a row. Tip To delete a particular resource, click the Remove button next to it. An aggregation type is not taken into consideration, if you select the Raw export type while scheduling the report. Click the Save button. What to do next: Use the newly created CSV monitoring data export configuration to schedule Advanced CSV Report in Monitoring & Reporting \u2192 Reports . Read how to do it in the Scheduling advanced CSV report chapter. See also: Scheduling advanced CSV report Adding CSV export configurations","title":"Adding CSV monitoring data export configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Adding_CSV_import_configurations.html","text":"Adding CSV import configurations # Read this section to learn how to create a new import configuration. To add a CSV import configuration: Go to Administration and select CSV Import/Export templates . Click CSV import configuration . Click the Add icon. Provide a name for a configuration. From the list select whether you want to import devices. Select one of editor modes: Simple - to add a column, click it in the Available operations table. Expressions - to add the column, click the Add column link and start typing expressions. To see expression suggestions for a device, use the Select representative of imported devices option. Plain text - to add the column, start typing expressions. You should type one expression per line. Tip Remember to add a column that specifies an ID of a device. To set particular values for some columns and override values from a file, type them into the Forced value field. Before importing the CSV file, you can validate it. For example, you can check if IP addresses of devices (they are in the third column in the file) are correct by selecting Validate from Available operations and typing into the Forced value field the following expression: ${net.isIp(columns.get(2))} . If any IP address is incorrect, then the list will not be imported and a proper message will be shown in the Import log field. Add validation at the end of the import configuration if you do not want to skip content of any column from the CSV file or use this content as a validation condition. To use a current column content from the CSV file as the validation condition, use Validate with no value in the Forced value field. After adding all columns you can remove, edit or move them: To remove a column in the Expressions or Simple tab, click the Remove icon next to it. To edit the column, go to the Expressions or Plain text tab, and make necessary changes. To change an order of columns, go to the Simple tab, and use the drag and drop functionality. Click the Save button. What to do next: Use the newly created CSV import configuration, for example, to import devices from CSV in Device inventory .","title":"Adding CSV import configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Adding_CSV_import_configurations.html#adding-csv-import-configurations","text":"Read this section to learn how to create a new import configuration. To add a CSV import configuration: Go to Administration and select CSV Import/Export templates . Click CSV import configuration . Click the Add icon. Provide a name for a configuration. From the list select whether you want to import devices. Select one of editor modes: Simple - to add a column, click it in the Available operations table. Expressions - to add the column, click the Add column link and start typing expressions. To see expression suggestions for a device, use the Select representative of imported devices option. Plain text - to add the column, start typing expressions. You should type one expression per line. Tip Remember to add a column that specifies an ID of a device. To set particular values for some columns and override values from a file, type them into the Forced value field. Before importing the CSV file, you can validate it. For example, you can check if IP addresses of devices (they are in the third column in the file) are correct by selecting Validate from Available operations and typing into the Forced value field the following expression: ${net.isIp(columns.get(2))} . If any IP address is incorrect, then the list will not be imported and a proper message will be shown in the Import log field. Add validation at the end of the import configuration if you do not want to skip content of any column from the CSV file or use this content as a validation condition. To use a current column content from the CSV file as the validation condition, use Validate with no value in the Forced value field. After adding all columns you can remove, edit or move them: To remove a column in the Expressions or Simple tab, click the Remove icon next to it. To edit the column, go to the Expressions or Plain text tab, and make necessary changes. To change an order of columns, go to the Simple tab, and use the drag and drop functionality. Click the Save button. What to do next: Use the newly created CSV import configuration, for example, to import devices from CSV in Device inventory .","title":"Adding CSV import configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/CSV_templates_overview.html","text":"CSV Import/Export templates overview # Go through below sections to learn how to add, edit and delete CSV import and export configurations. Note This panel supports multitenancy, which means that: * CSV Import/Export templates configuration is visible as read only for subtenants. * Supertenants can see configurations of their subtenants. CSV import configurations: Adding CSV import configurations Editing CSV import configurations Deleting CSV import configurations CSV export configurations: Adding CSV export configurations Adding CSV monitoring data export configurations Editing CSV export configurations Deleting CSV export configurations","title":"CSV Import/Export templates overview"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/CSV_templates_overview.html#csv-importexport-templates-overview","text":"Go through below sections to learn how to add, edit and delete CSV import and export configurations. Note This panel supports multitenancy, which means that: * CSV Import/Export templates configuration is visible as read only for subtenants. * Supertenants can see configurations of their subtenants. CSV import configurations: Adding CSV import configurations Editing CSV import configurations Deleting CSV import configurations CSV export configurations: Adding CSV export configurations Adding CSV monitoring data export configurations Editing CSV export configurations Deleting CSV export configurations","title":"CSV Import/Export templates overview"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Deleting_CSV_export_configurations.html","text":"Deleting CSV export configurations # If you do not need a CSV export configuration, you can delete it from the system. To delete a CSV export configuration: Go to Administration and select CSV Import/Export templates . Click CSV export configuration . From the list, select a configuration you want to delete. Click the Delete button. Confirm your action by clicking the Yes button.","title":"Deleting CSV export configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Deleting_CSV_export_configurations.html#deleting-csv-export-configurations","text":"If you do not need a CSV export configuration, you can delete it from the system. To delete a CSV export configuration: Go to Administration and select CSV Import/Export templates . Click CSV export configuration . From the list, select a configuration you want to delete. Click the Delete button. Confirm your action by clicking the Yes button.","title":"Deleting CSV export configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Deleting_CSV_import_configurations.html","text":"Deleting CSV import configurations # If you do not need a CSV import configuration, you can delete it from the system. To delete a CSV import configuration: Go to Administration and select CSV Import/Export templates . Click CSV import configuration . From the list, select a configuration you want to delete. Click the Delete button. Confirm your action by clicking the Yes button.","title":"Deleting CSV import configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Deleting_CSV_import_configurations.html#deleting-csv-import-configurations","text":"If you do not need a CSV import configuration, you can delete it from the system. To delete a CSV import configuration: Go to Administration and select CSV Import/Export templates . Click CSV import configuration . From the list, select a configuration you want to delete. Click the Delete button. Confirm your action by clicking the Yes button.","title":"Deleting CSV import configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Editing_CSV_export_configurations.html","text":"Editing CSV export configurations # At any time you can make changes to a CSV export configuration. To edit a CSV export configuration: Go to Administration and select CSV Import/Export templates . Click CSV export configuration . From the list, select a configuration you want to edit. Click the Edit button. Select one of the editing modes and introduce necessary changes. Click the Save button.","title":"Editing CSV export configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Editing_CSV_export_configurations.html#editing-csv-export-configurations","text":"At any time you can make changes to a CSV export configuration. To edit a CSV export configuration: Go to Administration and select CSV Import/Export templates . Click CSV export configuration . From the list, select a configuration you want to edit. Click the Edit button. Select one of the editing modes and introduce necessary changes. Click the Save button.","title":"Editing CSV export configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Editing_CSV_import_configurations.html","text":"Editing CSV import configurations # At any time you can make changes to a CSV import configuration. To edit a CSV import configuration: Go to Administration and select CSV Import/Export templates . Click CSV import configuration . From the list, select a configuration you want to edit. Click the Edit button. Select one of the editing modes and introduce necessary changes. Click the Save button.","title":"Editing CSV import configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/CSV_Import_%26_Export_templates/Editing_CSV_import_configurations.html#editing-csv-import-configurations","text":"At any time you can make changes to a CSV import configuration. To edit a CSV import configuration: Go to Administration and select CSV Import/Export templates . Click CSV import configuration . From the list, select a configuration you want to edit. Click the Edit button. Select one of the editing modes and introduce necessary changes. Click the Save button.","title":"Editing CSV import configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Adding_new_object_definitions_to_device_dialects.html","text":"Adding new object definitions to device dialects # Read this chapter to learn how to add new object definitions to your device dialect tree. To add a new object definition: Go to Administration \u2014> Device dialects . In the Device dialects panel, click Import LwM2M object definition . In the window that opens, import the desired LwM2M object definition. You can paste an XML definition or an URL in the field, or use the Upload file button. Note The imported object definition will be validated. In the Validation status field, you will see errors associated with specific XML lines. After the definition is positively validated, click Import . The object definition is now added. Click Close . See also: Adding new object definitions","title":"Adding new object definitions to device dialects"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Adding_new_object_definitions_to_device_dialects.html#adding-new-object-definitions-to-device-dialects","text":"Read this chapter to learn how to add new object definitions to your device dialect tree. To add a new object definition: Go to Administration \u2014> Device dialects . In the Device dialects panel, click Import LwM2M object definition . In the window that opens, import the desired LwM2M object definition. You can paste an XML definition or an URL in the field, or use the Upload file button. Note The imported object definition will be validated. In the Validation status field, you will see errors associated with specific XML lines. After the definition is positively validated, click Import . The object definition is now added. Click Close . See also: Adding new object definitions","title":"Adding new object definitions to device dialects"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Device_dialects.html","text":"Device dialects # This chapter describes the user interface for dialect modification. For more information about dialects see the Dialects - Introduction section. This panel allows you to view and configure device dialects present in the system. Dialects are pieces of configuration which can be attached to a device description. They help mitigate differences which need to be taken into account when communicating with different types of devices. No changes made in this panel are saved until you click the Save all changes button. When dialects are saved, they are checked for structural errors (for example, syntax errors, incorrect include directive). Types and hierarchy # Dialects can be divided into three types: Static dialects - which are bundled with the system and cannot be modified. User-defined dialects - which can be added, modified and deleted. Default dialect - which is a special instance at the top of the tree that is automatically included in all other dialects. Dialects can also be abstract , which means that they cannot be put directly on devices, and can only be included in other dialects. Types of dialects are represented by icons, user-defined dialects are also marked with green: - an abstract user-defined dialect - an abstract static dialect - a default dialect - a user-defined dialect - a static dialect - a dialect contains unsaved changes To show all dialects in a compact way, they are put into a tree structure. Internally there is no hierarchy of dialects, but conventionally their names are split into components on dots. For display purposes these components are put into a tree, so that dialects a.b and a.c are displayed as: Layout # Search tool - it limits displayed dialects to ones containing a given text in their name. Dialect tree - it displays names of all dialects present in the system. Action toolbar : Save all changes - it saves and applies all changes to all currently modified dialects. Discard all - it discards all unsaved changes to dialects which also restores unsaved deletion. Delete - it deletes a currently selected dialect. The delete action is not immediately saved and can be discarded. If the dialect is included in other places, all places will be listed and you will be asked if you want to delete the dialect from all of them. Add - it adds a new empty dialect positioned inside a currently selected item in the tree. Validate all - it performs a dialect validation, displaying possible errors in a label on the right of this button. Import LwM2M object definition - it is available for LwM2M devices in the LwM2M dialect branch. It allows to import an XML file as a dialect. The XML file has to have a proper schema described in http://www.openmobilealliance.org/tech/profiles/LWM2M.xsd. If you want to include your new dialect into the lwm2m.object.users.global dialect, select the Add globally check box. Color scheme - use it to change a color scheme of the dialect in Contents . Update includes - use it if you want to update dialect's name in all places it is included. Details - it shows properties of a currently selected dialect: Dialect name - a name of the dialect with all but the last . - separated components are removed. Full dialect name - an actual name of the dialect. Is abstract - if the dialect is abstract, it cannot be used directly on devices, but can only serve as a template to be included in other dialects. Contents - it shows HOCON contents of the selected dialect (in an edit mode) or full contents of the dialect (in a preview mode). Preview properties - options for modifications of the preview display: Render comments - do not strip comments from an input. Render origin comments - it prints a comment above all config lines describing the name of the dialect and a line number in which they were defined. Render as JSON - it uses a JSON-like version of a HOCON syntax. If you do not select Render comments and Render origin comments check boxes, the preview of a valid JSON string will be displayed. Preview window - contents of the resulting dialect data structure. If more than one user edits any dialects and both want to save their changes, then the first user saves changes but the second will get a pop-up with three options: Cancel - clicking it gives up performing any actions. Discard changes and reload dialects - clicking it ignores performed changes and reloads all dialects. Reload dialects and reapply changes - clicking it keeps performed changes, reloads dialects and pastes a modified content. See also Dialects - Introduction","title":"Device dialects"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Device_dialects.html#device-dialects","text":"This chapter describes the user interface for dialect modification. For more information about dialects see the Dialects - Introduction section. This panel allows you to view and configure device dialects present in the system. Dialects are pieces of configuration which can be attached to a device description. They help mitigate differences which need to be taken into account when communicating with different types of devices. No changes made in this panel are saved until you click the Save all changes button. When dialects are saved, they are checked for structural errors (for example, syntax errors, incorrect include directive).","title":"Device dialects"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Device_dialects.html#types-and-hierarchy","text":"Dialects can be divided into three types: Static dialects - which are bundled with the system and cannot be modified. User-defined dialects - which can be added, modified and deleted. Default dialect - which is a special instance at the top of the tree that is automatically included in all other dialects. Dialects can also be abstract , which means that they cannot be put directly on devices, and can only be included in other dialects. Types of dialects are represented by icons, user-defined dialects are also marked with green: - an abstract user-defined dialect - an abstract static dialect - a default dialect - a user-defined dialect - a static dialect - a dialect contains unsaved changes To show all dialects in a compact way, they are put into a tree structure. Internally there is no hierarchy of dialects, but conventionally their names are split into components on dots. For display purposes these components are put into a tree, so that dialects a.b and a.c are displayed as:","title":"Types and hierarchy"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Device_dialects.html#layout","text":"Search tool - it limits displayed dialects to ones containing a given text in their name. Dialect tree - it displays names of all dialects present in the system. Action toolbar : Save all changes - it saves and applies all changes to all currently modified dialects. Discard all - it discards all unsaved changes to dialects which also restores unsaved deletion. Delete - it deletes a currently selected dialect. The delete action is not immediately saved and can be discarded. If the dialect is included in other places, all places will be listed and you will be asked if you want to delete the dialect from all of them. Add - it adds a new empty dialect positioned inside a currently selected item in the tree. Validate all - it performs a dialect validation, displaying possible errors in a label on the right of this button. Import LwM2M object definition - it is available for LwM2M devices in the LwM2M dialect branch. It allows to import an XML file as a dialect. The XML file has to have a proper schema described in http://www.openmobilealliance.org/tech/profiles/LWM2M.xsd. If you want to include your new dialect into the lwm2m.object.users.global dialect, select the Add globally check box. Color scheme - use it to change a color scheme of the dialect in Contents . Update includes - use it if you want to update dialect's name in all places it is included. Details - it shows properties of a currently selected dialect: Dialect name - a name of the dialect with all but the last . - separated components are removed. Full dialect name - an actual name of the dialect. Is abstract - if the dialect is abstract, it cannot be used directly on devices, but can only serve as a template to be included in other dialects. Contents - it shows HOCON contents of the selected dialect (in an edit mode) or full contents of the dialect (in a preview mode). Preview properties - options for modifications of the preview display: Render comments - do not strip comments from an input. Render origin comments - it prints a comment above all config lines describing the name of the dialect and a line number in which they were defined. Render as JSON - it uses a JSON-like version of a HOCON syntax. If you do not select Render comments and Render origin comments check boxes, the preview of a valid JSON string will be displayed. Preview window - contents of the resulting dialect data structure. If more than one user edits any dialects and both want to save their changes, then the first user saves changes but the second will get a pop-up with three options: Cancel - clicking it gives up performing any actions. Discard changes and reload dialects - clicking it ignores performed changes and reloads all dialects. Reload dialects and reapply changes - clicking it keeps performed changes, reloads dialects and pastes a modified content. See also Dialects - Introduction","title":"Layout"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Dialects_-_Introduction.html","text":"Dialects - Introduction # Dialects form a layer of advanced, low-level device provisioning configuration that is intended to mitigate differences in behavior of various device types provisioned by Coiote DM. Ideally, when dialects are properly configured, higher layers (provisioning tasks, monitoring, etc.) can assume uniform interface and behavior of all device types. In particular, dialects are used to: Configure various settings specific to particular provisioning protocols. Apply modifications and corrections to the data model exposed by devices. Apply modifications and corrections to data model operations issued on devices. Set up an uniform, virtualized data model for all device types. Each dialect is an independent piece of configuration. Coiote DM comes up with a set of predefined dialects. These are called static dialects and cannot be modified by Coiote DM users. In addition to predefined dialects, Coiote DM users can define their own dialects which can be added, modified and deleted at any time using a dedicated administration panel in the Coiote DM UI. These dialects are called the dynamic or user-defined dialects. The dialect can be selected independently for any single device or it may be applied on entire group of devices. Internally, this is controlled by the dialectName setting value. Coiote DM comes up with some sensible defaults, automatically having some basic dialects selected for devices provisioned with particular protocols. Structure of dialects # Every dialect is defined by a text document in the HOCON (Human Optimized Config Object Notation format. You should familiarize yourself with HOCON before doing any dialect configuration. In short, HOCON is similar to JSON, but much more powerful, with features like including other documents, substitutions (references), overriding and other facilities which enable easy reuse of configuration fragments. This allows to keep things concise and minimize duplication. Thanks to include clauses in HOCON, dialects can refer to each other by including contents of other dialects. At the same time, settings inherited from included dialects can be easily and selectively overridden. The set of HOCON documents that configure dialects can be divided into two subsets: Concrete dialect configurations - these represent actual dialects which can be set up on devices and device groups. Therefore, they are always required to be valid and are extensively checked for errors upon editing. Abstract dialect configurations - these are merely reusable common chunks of HOCON which can only be included by other dialects. Therefore, they are not validated and cannot be set up on devices and groups. Dialects also have a hierarchical structure, which is reflected by their names, for example, lwm2m , lwm2m.default . Tip The dialects hierarchy is simply a naming convention, completely independent of a way dialects include each other. In particular, remember that dialects do not automatically include their parents. Including and overriding example # The following example shows the structure of a dialect that includes some other dialect and selectively overrides some settings inherited from the included dialect. Suppose that there is a (simplified) dialect named lwm2m defined by the following HOCON document: lwm2m.conf : lwm2m { # Number of milliseconds that server will wait for a response from a device before failing the session messageTimeout = 90000 marshallingSettings { # Options affecting how boolean values are handled booleanRepresentations { # String representations of boolean values accepted by the device # Used for marshalling of ParameterValueStruct and SetParameterAttributesStruct # When null, no particular representation is enforced. nativeTrue = null nativeFalse = null } trimTagValues = true } // possibly more options... } This is a simplified version of a base dialect which configures the LwM2M protocol. Suppose now that we have a group of devices which use 0 and 1 to represent boolean values, instead of true and false . We need to provide that information in the dialect so that LwM2M implementation in Coiote DM knows which boolean representation to use. In order to do this, we create a new dialect, say lwm2m.zeroOneBooleans which includes the lwm2m dialect and overrides nativeTrue and nativeFalse settings with appropriate values: lwm2m.zeroOneBooleans.conf : // include clause works as if the lwm2m dialect was \"copied and pasted\" into this document include \"/lwm2m\" // we selectively override only these settings which we need, using compact syntax lwm2m.marshallingSettings.booleanRepresentations { nativeTrue = \"1\" nativeFalse = \"0\" } Note When using the include command, remember to insert domain name of the included dialect in slashes before specifying the dialect name. See also: Device dialects Selecting dialects for devices and groups","title":"Dialects - Introduction"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Dialects_-_Introduction.html#dialects-introduction","text":"Dialects form a layer of advanced, low-level device provisioning configuration that is intended to mitigate differences in behavior of various device types provisioned by Coiote DM. Ideally, when dialects are properly configured, higher layers (provisioning tasks, monitoring, etc.) can assume uniform interface and behavior of all device types. In particular, dialects are used to: Configure various settings specific to particular provisioning protocols. Apply modifications and corrections to the data model exposed by devices. Apply modifications and corrections to data model operations issued on devices. Set up an uniform, virtualized data model for all device types. Each dialect is an independent piece of configuration. Coiote DM comes up with a set of predefined dialects. These are called static dialects and cannot be modified by Coiote DM users. In addition to predefined dialects, Coiote DM users can define their own dialects which can be added, modified and deleted at any time using a dedicated administration panel in the Coiote DM UI. These dialects are called the dynamic or user-defined dialects. The dialect can be selected independently for any single device or it may be applied on entire group of devices. Internally, this is controlled by the dialectName setting value. Coiote DM comes up with some sensible defaults, automatically having some basic dialects selected for devices provisioned with particular protocols.","title":"Dialects - Introduction"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Dialects_-_Introduction.html#structure-of-dialects","text":"Every dialect is defined by a text document in the HOCON (Human Optimized Config Object Notation format. You should familiarize yourself with HOCON before doing any dialect configuration. In short, HOCON is similar to JSON, but much more powerful, with features like including other documents, substitutions (references), overriding and other facilities which enable easy reuse of configuration fragments. This allows to keep things concise and minimize duplication. Thanks to include clauses in HOCON, dialects can refer to each other by including contents of other dialects. At the same time, settings inherited from included dialects can be easily and selectively overridden. The set of HOCON documents that configure dialects can be divided into two subsets: Concrete dialect configurations - these represent actual dialects which can be set up on devices and device groups. Therefore, they are always required to be valid and are extensively checked for errors upon editing. Abstract dialect configurations - these are merely reusable common chunks of HOCON which can only be included by other dialects. Therefore, they are not validated and cannot be set up on devices and groups. Dialects also have a hierarchical structure, which is reflected by their names, for example, lwm2m , lwm2m.default . Tip The dialects hierarchy is simply a naming convention, completely independent of a way dialects include each other. In particular, remember that dialects do not automatically include their parents.","title":"Structure of dialects"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Dialects_-_Introduction.html#including-and-overriding-example","text":"The following example shows the structure of a dialect that includes some other dialect and selectively overrides some settings inherited from the included dialect. Suppose that there is a (simplified) dialect named lwm2m defined by the following HOCON document: lwm2m.conf : lwm2m { # Number of milliseconds that server will wait for a response from a device before failing the session messageTimeout = 90000 marshallingSettings { # Options affecting how boolean values are handled booleanRepresentations { # String representations of boolean values accepted by the device # Used for marshalling of ParameterValueStruct and SetParameterAttributesStruct # When null, no particular representation is enforced. nativeTrue = null nativeFalse = null } trimTagValues = true } // possibly more options... } This is a simplified version of a base dialect which configures the LwM2M protocol. Suppose now that we have a group of devices which use 0 and 1 to represent boolean values, instead of true and false . We need to provide that information in the dialect so that LwM2M implementation in Coiote DM knows which boolean representation to use. In order to do this, we create a new dialect, say lwm2m.zeroOneBooleans which includes the lwm2m dialect and overrides nativeTrue and nativeFalse settings with appropriate values: lwm2m.zeroOneBooleans.conf : // include clause works as if the lwm2m dialect was \"copied and pasted\" into this document include \"/lwm2m\" // we selectively override only these settings which we need, using compact syntax lwm2m.marshallingSettings.booleanRepresentations { nativeTrue = \"1\" nativeFalse = \"0\" } Note When using the include command, remember to insert domain name of the included dialect in slashes before specifying the dialect name. See also: Device dialects Selecting dialects for devices and groups","title":"Including and overriding example"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Managing_unknown_device_objects_in_the_Objects_panel.html","text":"Managing unknown device objects in the Objects panel # It is sometimes the case that devices may feature objects that are not defined by any of the dialects available by default in the platform. Read the instructions below to learn how to manage such unknown objects: Go to Device inventory and choose a device with objects that are not yet defined by the existing dialects. In the Objects panel, scroll down the list of objects until you see a notice about Objects without definition and a list of unknown objects beneath it (with names marked in blue). Now, you can either configure the available object instances manually or use the Import LwM2M object definition button to import the desired LwM2M object definitions. Note See the Adding new object definitions chapter for details on how to import the missing object definitions. For manual configuration, click on the chosen unknown object to view the list of its resources. In the Interpretation column, choose from among the following data formats to interpret the resource values: boolean integer float objlnk executable corelnk opaque unsigned integer time string Thus, you'll be able to define the previously unknown resource values and manage the object to some extent. Warning Support for objects without definition is incomplete. Please note that the system do not display names nor descriptions and that the device may reject actions taken on such objects.","title":"Managing unknown device objects in the Objects panel"},{"location":"User_Guide/User_Interface_Reference/Administration/Dialects/Managing_unknown_device_objects_in_the_Objects_panel.html#managing-unknown-device-objects-in-the-objects-panel","text":"It is sometimes the case that devices may feature objects that are not defined by any of the dialects available by default in the platform. Read the instructions below to learn how to manage such unknown objects: Go to Device inventory and choose a device with objects that are not yet defined by the existing dialects. In the Objects panel, scroll down the list of objects until you see a notice about Objects without definition and a list of unknown objects beneath it (with names marked in blue). Now, you can either configure the available object instances manually or use the Import LwM2M object definition button to import the desired LwM2M object definitions. Note See the Adding new object definitions chapter for details on how to import the missing object definitions. For manual configuration, click on the chosen unknown object to view the list of its resources. In the Interpretation column, choose from among the following data formats to interpret the resource values: boolean integer float objlnk executable corelnk opaque unsigned integer time string Thus, you'll be able to define the previously unknown resource values and manage the object to some extent. Warning Support for objects without definition is incomplete. Please note that the system do not display names nor descriptions and that the device may reject actions taken on such objects.","title":"Managing unknown device objects in the Objects panel"},{"location":"User_Guide/User_Interface_Reference/Administration/Import_Export/Adding_CSV_import_configurations.html","text":"Adding CSV import configurations # Read this section to learn how to create a new import configuration. To add a CSV import configuration: Go to Administration and select CSV Import/Export templates . Click CSV import configuration . Click the Add icon. Provide a name for a configuration. From the list select whether you want to import devices. Select one of editor modes: Simple - to add a column, click it in the Available operations table. Expressions - to add the column, click the Add column link and start typing expressions. To see expression suggestions for a device, use the Select representative of imported devices option. Plain text - to add the column, start typing expressions. You should type one expression per line. !!! tip: * Remember to add a column that specifies an ID of a device. * To set particular values for some columns and override values from a file, type them into the Forced value field. Before importing the CSV file, you can validate it. For example, you can check if IP addresses of devices (they are in the third column in the file) are correct by selecting Validate from Available operations and typing into the Forced value field the following expression: ${net.isIp(columns.get(2))} . If any IP address is incorrect, then the list will not be imported and a proper message will be shown in the Import log field. Add validation at the end of the import configuration if you do not want to skip content of any column from the CSV file or use this content as a validation condition. To use a current column content from the CSV file as the validation condition, use Validate with no value in the Forced value field. After adding all columns you can remove, edit or move them: To remove a column in the Expressions or Simple tab, click the Remove icon next to it. To edit the column, go to the Expressions or Plain text tab, and make necessary changes. To change an order of columns, go to the Simple tab, and use the drag and drop functionality. Click the Save button. What to do next: Use the newly created CSV import configuration, for example, to import devices from CSV in **Device inventory`.","title":"Adding CSV import configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/Import_Export/Adding_CSV_import_configurations.html#adding-csv-import-configurations","text":"Read this section to learn how to create a new import configuration. To add a CSV import configuration: Go to Administration and select CSV Import/Export templates . Click CSV import configuration . Click the Add icon. Provide a name for a configuration. From the list select whether you want to import devices. Select one of editor modes: Simple - to add a column, click it in the Available operations table. Expressions - to add the column, click the Add column link and start typing expressions. To see expression suggestions for a device, use the Select representative of imported devices option. Plain text - to add the column, start typing expressions. You should type one expression per line. !!! tip: * Remember to add a column that specifies an ID of a device. * To set particular values for some columns and override values from a file, type them into the Forced value field. Before importing the CSV file, you can validate it. For example, you can check if IP addresses of devices (they are in the third column in the file) are correct by selecting Validate from Available operations and typing into the Forced value field the following expression: ${net.isIp(columns.get(2))} . If any IP address is incorrect, then the list will not be imported and a proper message will be shown in the Import log field. Add validation at the end of the import configuration if you do not want to skip content of any column from the CSV file or use this content as a validation condition. To use a current column content from the CSV file as the validation condition, use Validate with no value in the Forced value field. After adding all columns you can remove, edit or move them: To remove a column in the Expressions or Simple tab, click the Remove icon next to it. To edit the column, go to the Expressions or Plain text tab, and make necessary changes. To change an order of columns, go to the Simple tab, and use the drag and drop functionality. Click the Save button. What to do next: Use the newly created CSV import configuration, for example, to import devices from CSV in **Device inventory`.","title":"Adding CSV import configurations"},{"location":"User_Guide/User_Interface_Reference/Administration/Import_Export/Exporting_entities.html","text":"Exporting entities # Read this procedure to learn how to export selected entities. To export a selected entity: Go to Administration \u2192 Import/export . Click the Export tab. From the list of entities, select an entity you want to export. Tip In a database Quick Fixes and task templates are separate entities so if you export only Quick Fixes but you lose task templates, then these Quick Fixes are useless. The same rule applies to setting value descriptors and setting value categories so if you export only setting value descriptors but you do not have setting value categories, then these setting value descriptors are useless. Select check boxes next to fields you want to export. You can see all fields that you selected in the Preview panel. To search through the result, use the Query field: To use the simple search, click the magnifying glass icon next to the column in which you want to search for results, type a proper value into the Query field and press Enter . For example, if you click the magnifying glass next to the ID column, then type the ID into the Query field. To use the advanced search, click the magnifying glass icon next to the Query field and use the search. Tip To learn more about searching read the Search section. Click the Export link. What to do next: Learn how to import entities.","title":"Exporting entities"},{"location":"User_Guide/User_Interface_Reference/Administration/Import_Export/Exporting_entities.html#exporting-entities","text":"Read this procedure to learn how to export selected entities. To export a selected entity: Go to Administration \u2192 Import/export . Click the Export tab. From the list of entities, select an entity you want to export. Tip In a database Quick Fixes and task templates are separate entities so if you export only Quick Fixes but you lose task templates, then these Quick Fixes are useless. The same rule applies to setting value descriptors and setting value categories so if you export only setting value descriptors but you do not have setting value categories, then these setting value descriptors are useless. Select check boxes next to fields you want to export. You can see all fields that you selected in the Preview panel. To search through the result, use the Query field: To use the simple search, click the magnifying glass icon next to the column in which you want to search for results, type a proper value into the Query field and press Enter . For example, if you click the magnifying glass next to the ID column, then type the ID into the Query field. To use the advanced search, click the magnifying glass icon next to the Query field and use the search. Tip To learn more about searching read the Search section. Click the Export link. What to do next: Learn how to import entities.","title":"Exporting entities"},{"location":"User_Guide/User_Interface_Reference/Administration/Import_Export/Import_Export.html","text":"Import/export # Use the import and export data module to: Easily manage application entities Import default data at the application launch Import/export is available in Administration \u2192 Import/export . Warning Use importing and exporting carefully because wrong usage can lead to database inconsistency. Supported entities # The below entities are supported in UMP: Alert type CSV import configuration Device Group Group dispatch rule Login message Monitoring configuration Quick fix Resource Schedule Security policy Service Setting value Setting value category Setting value descriptor Simple property Task Task report Task template User template Export # Look at the below picture to see how the Export panel looks like. :align: center Entity Name - a list of all supported entities. Export - use it to manage an export operation. Select all , Deselect all - use it to select or to clear all fields. Exported fields - a list of fields that will be exported. Query - use it to search for particular values of parameters. Reset , Previous , Next - use Previous` and Next icons to quickly go through all entities, use the Reset** icon to go back to the first page. Preview - use the table to preview entities. Export - use this link to export selected entities. Log - use this panel to see logs from your operation. Import # Look at the below picture to see how the Import panel looks like. Import - use it to manage an import operation. Paste here - a place where you can paste a source configuration. You can paste here up to 1 MB of a text. Import - use this button to import parameters. Upload file - use this button to upload the source configuration from a file. What to do next: Learn how to export and import entities.","title":"Import/export"},{"location":"User_Guide/User_Interface_Reference/Administration/Import_Export/Import_Export.html#importexport","text":"Use the import and export data module to: Easily manage application entities Import default data at the application launch Import/export is available in Administration \u2192 Import/export . Warning Use importing and exporting carefully because wrong usage can lead to database inconsistency.","title":"Import/export"},{"location":"User_Guide/User_Interface_Reference/Administration/Import_Export/Import_Export.html#supported-entities","text":"The below entities are supported in UMP: Alert type CSV import configuration Device Group Group dispatch rule Login message Monitoring configuration Quick fix Resource Schedule Security policy Service Setting value Setting value category Setting value descriptor Simple property Task Task report Task template User template","title":"Supported entities"},{"location":"User_Guide/User_Interface_Reference/Administration/Import_Export/Import_Export.html#export","text":"Look at the below picture to see how the Export panel looks like. :align: center Entity Name - a list of all supported entities. Export - use it to manage an export operation. Select all , Deselect all - use it to select or to clear all fields. Exported fields - a list of fields that will be exported. Query - use it to search for particular values of parameters. Reset , Previous , Next - use Previous` and Next icons to quickly go through all entities, use the Reset** icon to go back to the first page. Preview - use the table to preview entities. Export - use this link to export selected entities. Log - use this panel to see logs from your operation.","title":"Export"},{"location":"User_Guide/User_Interface_Reference/Administration/Import_Export/Import_Export.html#import","text":"Look at the below picture to see how the Import panel looks like. Import - use it to manage an import operation. Paste here - a place where you can paste a source configuration. You can paste here up to 1 MB of a text. Import - use this button to import parameters. Upload file - use this button to upload the source configuration from a file. What to do next: Learn how to export and import entities.","title":"Import"},{"location":"User_Guide/User_Interface_Reference/Administration/Import_Export/Importing_entities.html","text":"Importing entities # Read this procedure to learn how to import selected entities. To import a selected entity: Go to Administration \u2192 Import/export . From the list of entities, select an entity you want to import. To select all entities click All . Click the Import tab. Use one of the options to import entities: Option 1: Paste a source configuration into the Paste here field. Click the Import button. Option 2: Click the Upload file button and select a file from your disc. The Options window opens and you need to decide what you want to do with entities: Option New value Duplicated value Add new Saved Skipped Update existing Saved Updated Add new and updated existing Saved Updated Skip Skipped Skipped To see a preview of first entities, click the magnifying glass icon. Click the Accept button. What to do next: Learn how to export entities.","title":"Importing entities"},{"location":"User_Guide/User_Interface_Reference/Administration/Import_Export/Importing_entities.html#importing-entities","text":"Read this procedure to learn how to import selected entities. To import a selected entity: Go to Administration \u2192 Import/export . From the list of entities, select an entity you want to import. To select all entities click All . Click the Import tab. Use one of the options to import entities: Option 1: Paste a source configuration into the Paste here field. Click the Import button. Option 2: Click the Upload file button and select a file from your disc. The Options window opens and you need to decide what you want to do with entities: Option New value Duplicated value Add new Saved Skipped Update existing Saved Updated Add new and updated existing Saved Updated Skip Skipped Skipped To see a preview of first entities, click the magnifying glass icon. Click the Accept button. What to do next: Learn how to export entities.","title":"Importing entities"}]}