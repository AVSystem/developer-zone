{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Getting started # Interoperability tests guide # This guide will walk you through the LwM2M protocol interoperability tests module available as part of Coiote IoT Device Management platform. Interoperability tests guide Azure IoT integration guide # With Coiote IoT Device Management platform, you can integrate your LwM2M devices with the Microsoft Azure IoT Hub and Azure IoT Central. This guide will take you on a step-by-step journey through the integration process to make it seamless and efficient. Here\u2019s how you can get started with the Coiote DM \u2013 Azure IoT integration: Configure integration with Azure IoT Central Configure integration with Azure IoT Hub AWS integration guide # Integrate Coiote DM with the Amazon Web Services and gain new opportunities to leverage your IoT data. Configure integration with AWS","title":"Getting started"},{"location":"index.html#getting-started","text":"","title":"Getting started"},{"location":"index.html#interoperability-tests-guide","text":"This guide will walk you through the LwM2M protocol interoperability tests module available as part of Coiote IoT Device Management platform. Interoperability tests guide","title":"Interoperability tests guide"},{"location":"index.html#azure-iot-integration-guide","text":"With Coiote IoT Device Management platform, you can integrate your LwM2M devices with the Microsoft Azure IoT Hub and Azure IoT Central. This guide will take you on a step-by-step journey through the integration process to make it seamless and efficient. Here\u2019s how you can get started with the Coiote DM \u2013 Azure IoT integration: Configure integration with Azure IoT Central Configure integration with Azure IoT Hub","title":"Azure IoT integration guide"},{"location":"index.html#aws-integration-guide","text":"Integrate Coiote DM with the Amazon Web Services and gain new opportunities to leverage your IoT data. Configure integration with AWS","title":"AWS integration guide"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html","text":"Configuring the integration # Follow this section to integrate your AWS services with Coiote DM. Prerequisites # An active AWS subscription. A Coiote DM user account with the Cloud admin role. The Git tool ( https://git-scm.com/book/en/v2/Getting-Started-Installing-Git ). The AWS CLI ( https://aws.amazon.com/cli/ ). Terraform CLI ( https://learn.hashicorp.com/tutorials/terraform/install-cli ). Create a Coiote DM REST user # To start integrating AWS with Coiote DM, you first need to create a user account that will be used to authorize and authenticate API calls from AWS in Coiote DM. To do that: Go to your Coiote DM account and from the Administration menu, select Users management . Select Add user and in fill in the form: Provide Email for new user (which will be its user name) and select your domain from the Domain path drop-down list. Remember to switch on the User Verified and User Enabled toggle buttons. In the Client Roles field, pick the admin-cli role. Click Save . Go to the Credentials tab, type a password for your user (twice), select Set password , then confirm by clicking Set password in the pop-up. Copy tasks and provide credentials for your device group in Coiote DM # The Coiote DM-side configuration of the integration is located in the dedicated AWSiotCore device group. To complete this side of the integration, log in as the user with the Cloud admin role and follow the steps below: Go to the Device groups panel and select a group: For the default setting, select the AWSiotCore group which already contains all the necessary tasks and setting values. Alternatively, create a new group and migrate the required tasks and setting values: Select the Add button, name your group and click Add . Migrate all the six tasks that have the AWS prefix in their task name: Select the AWSiotCore group and go to Group tasks , select the first AWS task and click Copy . In the pop-up window, click Select group in the Task target field and choose your custom integration group from the list. In the Actions field, select Add new task . Repeat the action for the remaining five tasks. Migrate all the five setting values that have the AWS prefix in their task name: Select your custom integration group and go to Profiles , then select Copy from . In the pop-up window, click Select group and select the AWSiotCore group. Pick all the five AWS setting values from the list by checking them in the Selected column, then click Copy . Enter your AWS subscription credentials in Coiote DM: Go to Device groups , select your custom integration group (or the AWSiotCore group, depending on the previous step) and go to Profiles . Complete the AWS setting values with your AWS credentials: For AWSaccessKeyID and AWSsecretAccessKey : Go to AWS Identity and Access Management , click Users and select your user name from the list. Select the Security credentials tab and, under the Access keys section, click Create access key . Copy the generated Access key ID and Secret access key . In Coiote DM, go to the Profiles tab of your integration group and paste the credentials as values for AWSaccessKeyID and AWSsecretAccessKey . Click Save . For AWSregion : While in AWS IoT Core, click on your region name in the top navigation bar to expand the list of regions. Then, copy the hyphenated region name (e.g. us-east-1 ). In Coiote DM, go to the Profiles tab of your integration group and paste the region name as the value for AWSregion . Click Save . For AWScontrolPlaneEndpointAddress : Go to AWS documentation : https://docs.aws.amazon.com/general/latest/gr/iot-core.html . From the Control Plane API Endpoints section, find the endpoint that matches your region (e.g. iot.us-east-1.amazonaws.com ) and copy it. In Coiote DM, go to the Profiles tab of your integration group and paste the credentials as the value for AWScontrolPlaneEndpointAddress . Click Save . For AWSdataPlaneEndpointAddress : Open your command line and run the following command: aws iot describe-endpoint --endpoint-type iot:Data-ATS Copy the returned result. In Coiote DM, go to the Profiles tab of your integration group and paste the result as the value for AWSdataPlaneEndpointAddress . Click Save . Optionally, you may now add your LwM2M devices to the integration device group so that they are ready once the integration setup is complete. Add AWS resources using the integration repository # All the AWS-side configuration needed for the integration to work is stored in a publicly available git repository ( https://github.com/AVSystem/iot-examples/tree/main/coiote-aws-iot-terraform ). To add the resources needed for the integration to your AWS services: Clone the repository into your local drive and check out on the coiote-aws-iot-terraform branch: Run your command line and paste the following commands: git clone --no-checkout https://github.com/AVSystem/iot-examples.git cd iot-examples git sparse-checkout set coiote-aws-iot-terraform git checkout main cd coiote-aws-iot-terraform Insert your REST user credentials into the vars.py file: In the catalog of your local repository, find the vars.py file and open it using a program that enables file edition. Change the default values of the variables to the credentials of your REST user created in a previous step. For coioteDMrestURL , provide the URL address and port of your Coiote DM installation. By default, it's https://lwm2m-test.avsystem.io:8087. For coioteDMrestPassword , provide the password set for your Coiote DM REST user. For coioteDMrestUsername , provide your Coiote DM REST user login (email address). Save the file. Run Terraform: Go back to your command line and paste the following: terraform init terraform apply Run the command. It will copy all the 16 resources contained in the main.tf file from the repository into your AWS services. Among the key resources that enable the integration, there are: the iam_for_lambda role, the lwm2mOperation Lambda function, and the operationRequest and operationResponse rules. See the contents of the main.tf file below or refer to the Concepts chapter for more details. resource \"aws_iam_role\" \"iam_for_lambda\" { na me = \"iam_for_lambda\" assume_role_policy = <<EOF { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Action\" : \"sts:AssumeRole\" , \"Principal\" : { \"Service\" : \"lambda.amazonaws.com\" }, \"Effect\" : \"Allow\" } ] } EOF } resource \"aws_iam_policy_attachment\" \"policy_attachment\" { na me = \"attachment\" roles = [ aws_iam_role.iam_ f or_lambda. na me ] policy_ar n = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\" } resource \"random_string\" \"r\" { le n g t h = 16 special = false } da ta \"archive_file\" \"lambda_zip\" { t ype = \"zip\" source_dir = \"lwm2mOperation\" ou t pu t _pa t h = \"lwm2mOperation.zip\" depe n ds_o n = [ ra n dom_s tr i n g.r ] } resource \"aws_lambda_function\" \"lwm2mOperation\" { f ile na me = \"lwm2mOperation.zip\" fun c t io n _ na me = \"lwm2mOperation\" role = aws_iam_role.iam_ f or_lambda.ar n ha n dler = \"lambda_function.lambda_handler\" source_code_hash = da ta .archive_ f ile.lambda_zip.ou t pu t _base 64 sha 256 ru nt ime = \"python3.8\" e n viro n me nt { variables = { coio te DMres t Password = var.coio te DMres t Password coio te DMres t Uri = var.coio te DMres t URL coio te DMres t User na me = var.coio te DMres t User na me } } } module \"iot_rule_1\" { na me = \"operationRequest\" sql_query = \"SELECT state.desired.operation AS operation, state.desired.keys AS keys, state.desired.values AS values, state.desired.attributes AS attributes, state.desired.arguments AS arguments, topic(3) AS thingName FROM '$aws/things/+/shadow/name/operation/update/accepted' WHERE isUndefined(state.desired.operation) = false\" source = \"git::https://github.com/Passarinho4/terraform-aws-iot-topic-rule.git?ref=master\" lambda = [ \"lwm2mOperation\" ] depe n ds_o n = [ aws_lambda_ fun c t io n .lwm 2 mOpera t io n ] } module \"iot_rule_2\" { na me = \"operationResponse\" sql_query = \"SELECT state.reported.result AS state.reported FROM '$aws/things/+/shadow/name/operation/update/accepted' WHERE (CASE isUndefined(state.reported.operation) WHEN true THEN false ELSE CASE state.reported.operation = 'read' OR state.reported.operation = 'write' OR state.reported.operation = 'readComposite' when true THEN true ELSE false END END) = true\" source = \"git::https://github.com/Passarinho4/terraform-aws-iot-topic-rule.git?ref=master\" republish = [{ t opic = \"$$aws/things/$${topic(3)}/shadow/name/datamodel/update\" }] Once the Terraform command is executed successfully, the devices in your integration group will be automatically migrated to the AWS IoT Core. To check if your integration works correctly, go to AWS IoT Core, and from the menu, select Manage > Things , then see if your devices are listed as in here: Next steps # To learn how to perform operations on your devices, please see the Performing LwM2M operations chapter.","title":"Configuring the integration"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#configuring-the-integration","text":"Follow this section to integrate your AWS services with Coiote DM.","title":"Configuring the integration"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#prerequisites","text":"An active AWS subscription. A Coiote DM user account with the Cloud admin role. The Git tool ( https://git-scm.com/book/en/v2/Getting-Started-Installing-Git ). The AWS CLI ( https://aws.amazon.com/cli/ ). Terraform CLI ( https://learn.hashicorp.com/tutorials/terraform/install-cli ).","title":"Prerequisites"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#create-a-coiote-dm-rest-user","text":"To start integrating AWS with Coiote DM, you first need to create a user account that will be used to authorize and authenticate API calls from AWS in Coiote DM. To do that: Go to your Coiote DM account and from the Administration menu, select Users management . Select Add user and in fill in the form: Provide Email for new user (which will be its user name) and select your domain from the Domain path drop-down list. Remember to switch on the User Verified and User Enabled toggle buttons. In the Client Roles field, pick the admin-cli role. Click Save . Go to the Credentials tab, type a password for your user (twice), select Set password , then confirm by clicking Set password in the pop-up.","title":"Create a Coiote DM REST user"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#copy-tasks-and-provide-credentials-for-your-device-group-in-coiote-dm","text":"The Coiote DM-side configuration of the integration is located in the dedicated AWSiotCore device group. To complete this side of the integration, log in as the user with the Cloud admin role and follow the steps below: Go to the Device groups panel and select a group: For the default setting, select the AWSiotCore group which already contains all the necessary tasks and setting values. Alternatively, create a new group and migrate the required tasks and setting values: Select the Add button, name your group and click Add . Migrate all the six tasks that have the AWS prefix in their task name: Select the AWSiotCore group and go to Group tasks , select the first AWS task and click Copy . In the pop-up window, click Select group in the Task target field and choose your custom integration group from the list. In the Actions field, select Add new task . Repeat the action for the remaining five tasks. Migrate all the five setting values that have the AWS prefix in their task name: Select your custom integration group and go to Profiles , then select Copy from . In the pop-up window, click Select group and select the AWSiotCore group. Pick all the five AWS setting values from the list by checking them in the Selected column, then click Copy . Enter your AWS subscription credentials in Coiote DM: Go to Device groups , select your custom integration group (or the AWSiotCore group, depending on the previous step) and go to Profiles . Complete the AWS setting values with your AWS credentials: For AWSaccessKeyID and AWSsecretAccessKey : Go to AWS Identity and Access Management , click Users and select your user name from the list. Select the Security credentials tab and, under the Access keys section, click Create access key . Copy the generated Access key ID and Secret access key . In Coiote DM, go to the Profiles tab of your integration group and paste the credentials as values for AWSaccessKeyID and AWSsecretAccessKey . Click Save . For AWSregion : While in AWS IoT Core, click on your region name in the top navigation bar to expand the list of regions. Then, copy the hyphenated region name (e.g. us-east-1 ). In Coiote DM, go to the Profiles tab of your integration group and paste the region name as the value for AWSregion . Click Save . For AWScontrolPlaneEndpointAddress : Go to AWS documentation : https://docs.aws.amazon.com/general/latest/gr/iot-core.html . From the Control Plane API Endpoints section, find the endpoint that matches your region (e.g. iot.us-east-1.amazonaws.com ) and copy it. In Coiote DM, go to the Profiles tab of your integration group and paste the credentials as the value for AWScontrolPlaneEndpointAddress . Click Save . For AWSdataPlaneEndpointAddress : Open your command line and run the following command: aws iot describe-endpoint --endpoint-type iot:Data-ATS Copy the returned result. In Coiote DM, go to the Profiles tab of your integration group and paste the result as the value for AWSdataPlaneEndpointAddress . Click Save . Optionally, you may now add your LwM2M devices to the integration device group so that they are ready once the integration setup is complete.","title":"Copy tasks and provide credentials for your device group in Coiote DM"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#add-aws-resources-using-the-integration-repository","text":"All the AWS-side configuration needed for the integration to work is stored in a publicly available git repository ( https://github.com/AVSystem/iot-examples/tree/main/coiote-aws-iot-terraform ). To add the resources needed for the integration to your AWS services: Clone the repository into your local drive and check out on the coiote-aws-iot-terraform branch: Run your command line and paste the following commands: git clone --no-checkout https://github.com/AVSystem/iot-examples.git cd iot-examples git sparse-checkout set coiote-aws-iot-terraform git checkout main cd coiote-aws-iot-terraform Insert your REST user credentials into the vars.py file: In the catalog of your local repository, find the vars.py file and open it using a program that enables file edition. Change the default values of the variables to the credentials of your REST user created in a previous step. For coioteDMrestURL , provide the URL address and port of your Coiote DM installation. By default, it's https://lwm2m-test.avsystem.io:8087. For coioteDMrestPassword , provide the password set for your Coiote DM REST user. For coioteDMrestUsername , provide your Coiote DM REST user login (email address). Save the file. Run Terraform: Go back to your command line and paste the following: terraform init terraform apply Run the command. It will copy all the 16 resources contained in the main.tf file from the repository into your AWS services. Among the key resources that enable the integration, there are: the iam_for_lambda role, the lwm2mOperation Lambda function, and the operationRequest and operationResponse rules. See the contents of the main.tf file below or refer to the Concepts chapter for more details. resource \"aws_iam_role\" \"iam_for_lambda\" { na me = \"iam_for_lambda\" assume_role_policy = <<EOF { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Action\" : \"sts:AssumeRole\" , \"Principal\" : { \"Service\" : \"lambda.amazonaws.com\" }, \"Effect\" : \"Allow\" } ] } EOF } resource \"aws_iam_policy_attachment\" \"policy_attachment\" { na me = \"attachment\" roles = [ aws_iam_role.iam_ f or_lambda. na me ] policy_ar n = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\" } resource \"random_string\" \"r\" { le n g t h = 16 special = false } da ta \"archive_file\" \"lambda_zip\" { t ype = \"zip\" source_dir = \"lwm2mOperation\" ou t pu t _pa t h = \"lwm2mOperation.zip\" depe n ds_o n = [ ra n dom_s tr i n g.r ] } resource \"aws_lambda_function\" \"lwm2mOperation\" { f ile na me = \"lwm2mOperation.zip\" fun c t io n _ na me = \"lwm2mOperation\" role = aws_iam_role.iam_ f or_lambda.ar n ha n dler = \"lambda_function.lambda_handler\" source_code_hash = da ta .archive_ f ile.lambda_zip.ou t pu t _base 64 sha 256 ru nt ime = \"python3.8\" e n viro n me nt { variables = { coio te DMres t Password = var.coio te DMres t Password coio te DMres t Uri = var.coio te DMres t URL coio te DMres t User na me = var.coio te DMres t User na me } } } module \"iot_rule_1\" { na me = \"operationRequest\" sql_query = \"SELECT state.desired.operation AS operation, state.desired.keys AS keys, state.desired.values AS values, state.desired.attributes AS attributes, state.desired.arguments AS arguments, topic(3) AS thingName FROM '$aws/things/+/shadow/name/operation/update/accepted' WHERE isUndefined(state.desired.operation) = false\" source = \"git::https://github.com/Passarinho4/terraform-aws-iot-topic-rule.git?ref=master\" lambda = [ \"lwm2mOperation\" ] depe n ds_o n = [ aws_lambda_ fun c t io n .lwm 2 mOpera t io n ] } module \"iot_rule_2\" { na me = \"operationResponse\" sql_query = \"SELECT state.reported.result AS state.reported FROM '$aws/things/+/shadow/name/operation/update/accepted' WHERE (CASE isUndefined(state.reported.operation) WHEN true THEN false ELSE CASE state.reported.operation = 'read' OR state.reported.operation = 'write' OR state.reported.operation = 'readComposite' when true THEN true ELSE false END END) = true\" source = \"git::https://github.com/Passarinho4/terraform-aws-iot-topic-rule.git?ref=master\" republish = [{ t opic = \"$$aws/things/$${topic(3)}/shadow/name/datamodel/update\" }] Once the Terraform command is executed successfully, the devices in your integration group will be automatically migrated to the AWS IoT Core. To check if your integration works correctly, go to AWS IoT Core, and from the menu, select Manage > Things , then see if your devices are listed as in here:","title":"Add AWS resources using the integration repository"},{"location":"AWS_Integration_Guide/Configuring_AWS_integration.html#next-steps","text":"To learn how to perform operations on your devices, please see the Performing LwM2M operations chapter.","title":"Next steps"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html","text":"How AWS integration works # Here's a walkthrough of the main concepts related to the AWS IoT Core - Coiote DM integration that will help you understand the role of each of the integration components and how they are employed for the benefit of LwM2M device management via the AWS services. Things # Within the AWS IoT Core - Coiote DM integration, things are the AWS representations of LwM2M device entities managed by the Coiote DM platform. They are used to mirror device state, as well as collect, process and act upon device data on the fly using a connection protocol of your choice. Note Things are automatically added to AWS IoT Core upon completing the integration setup and successful device connection. Thing types # Thing types are containers that store configuration and other device-related information shared by all Things of the same type to simplify their bulk management. Within the integration, they are created automatically when a new device is added to AWS from Coiote DM and they are based on device Manufacturer and Model name . In case a new device with a specific Manufacturer and model name pair can be matched with an existing thing type, then it will be associated with it automatically. Note Note that you cannot modify a once created thing type, but you can deprecate (allowing no new devices to be associated with it) or delete it when there are no things associated with a given Thing type. Device Shadows # A device shadow is a structure that stores the device state and represents it in the form of a JSON file, making the device data available to applications and services regardless of device connection to Coiote DM. To synchronize device state information between the Coiote DM and AWS IoT Core, shadows feature the mechanism of reported and desired values. Reported values section - presents the current device state as reported by the device itself (and mediated by Coiote DM) in a JSON file structure within a device shadow. Desired values section - used for requesting changes in the reported section of the device Operation shadow . For the purposes of the integration, a default of three different shadows is established for each connected thing: an unnamed shadow, a datamodel shadow and an operation shadow. Classic Shadow # The Classic shadow (also unnamed shadow) is used for storing connectivity parameters of a LwM2M device (such as registered lifetime, last lifetime refresh, queue mode, LwM2M URI, device registration status etc.). The reported state refreshes upon each change in these parameters that is reported by Coiote DM ( Register or Update message from device). Operation Shadow # The Operation Shadow is where you request your LwM2M operations to be executed. To this end, the desired values of the device state are used. Thus, you can perform any LwM2M 1.0 operation on the device by defining it inside the desired values section. Also, to check if the operation execution was successful, the reported values section of the Operation Shadow is used (but only in case of the READ, WRITE and READ COMPOSITE operations). Communication flow # A value change using the desired device state is formulated as the one below: { \"state\" : { \"desired\" : { \"operation\" : \"write\" , \"keys\" : [ \"LwM2M Server.1.Lifetime\" , \"Device.0.UTC Offset\" ], \"values\" : [ 68 , \"+02:00\" ] } } } Once a value change in the desired section of the operation shadow is saved, a chain of events starts: A change in the desired section triggers the operationRequest rule. The operationRequest rule sends a request to AWS Lambda . AWS Lambda validates the request and forwards it as an event to Coiote DM, making it schedule a task and initiate a device session. Coiote DM communicates with the device. The device responds to Coiote DM with the operation result. Coiote DM forwards the device response back to the Operation Shadow and the results are published in the reported section. The change in the reported section triggers the operationResponse rule. The results are then republished using the operationResponse rule to the Datamodel shadow (but only in case of the READ, WRITE and READ COMPOSITE operations). Datamodel Shadow # The Datamodel Shadow is the place where the cashed data model of the LwM2M device is stored. What this means is that it is a \"read-only shadow\" that keeps the most recent record of the device state as it has been reported by Coiote DM - no device operations can be performed from here. The Datamodel Shadow is updated in case of the following events: Device Register message that comes from Coiote DM, Device Notify and Send messages, Republishing operation results from the Operation shadow to the Datamodel shadow using the operationResponse rule. CloudWatch logs # CloudWatch collects and keeps a record of all the logs generated on the AWS-side of the integration. You can use these data for analysis and troubleshooting in case of all the AWS integration components: Device Shadows (the data plane), Things and Thing types (the control plane), The Rules mechanism, AWS Lambda.","title":"How AWS integration works"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#how-aws-integration-works","text":"Here's a walkthrough of the main concepts related to the AWS IoT Core - Coiote DM integration that will help you understand the role of each of the integration components and how they are employed for the benefit of LwM2M device management via the AWS services.","title":"How AWS integration works"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#things","text":"Within the AWS IoT Core - Coiote DM integration, things are the AWS representations of LwM2M device entities managed by the Coiote DM platform. They are used to mirror device state, as well as collect, process and act upon device data on the fly using a connection protocol of your choice. Note Things are automatically added to AWS IoT Core upon completing the integration setup and successful device connection.","title":"Things"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#thing-types","text":"Thing types are containers that store configuration and other device-related information shared by all Things of the same type to simplify their bulk management. Within the integration, they are created automatically when a new device is added to AWS from Coiote DM and they are based on device Manufacturer and Model name . In case a new device with a specific Manufacturer and model name pair can be matched with an existing thing type, then it will be associated with it automatically. Note Note that you cannot modify a once created thing type, but you can deprecate (allowing no new devices to be associated with it) or delete it when there are no things associated with a given Thing type.","title":"Thing types"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#device-shadows","text":"A device shadow is a structure that stores the device state and represents it in the form of a JSON file, making the device data available to applications and services regardless of device connection to Coiote DM. To synchronize device state information between the Coiote DM and AWS IoT Core, shadows feature the mechanism of reported and desired values. Reported values section - presents the current device state as reported by the device itself (and mediated by Coiote DM) in a JSON file structure within a device shadow. Desired values section - used for requesting changes in the reported section of the device Operation shadow . For the purposes of the integration, a default of three different shadows is established for each connected thing: an unnamed shadow, a datamodel shadow and an operation shadow.","title":"Device Shadows"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#classic-shadow","text":"The Classic shadow (also unnamed shadow) is used for storing connectivity parameters of a LwM2M device (such as registered lifetime, last lifetime refresh, queue mode, LwM2M URI, device registration status etc.). The reported state refreshes upon each change in these parameters that is reported by Coiote DM ( Register or Update message from device).","title":"Classic Shadow"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#operation-shadow","text":"The Operation Shadow is where you request your LwM2M operations to be executed. To this end, the desired values of the device state are used. Thus, you can perform any LwM2M 1.0 operation on the device by defining it inside the desired values section. Also, to check if the operation execution was successful, the reported values section of the Operation Shadow is used (but only in case of the READ, WRITE and READ COMPOSITE operations).","title":"Operation Shadow"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#communication-flow","text":"A value change using the desired device state is formulated as the one below: { \"state\" : { \"desired\" : { \"operation\" : \"write\" , \"keys\" : [ \"LwM2M Server.1.Lifetime\" , \"Device.0.UTC Offset\" ], \"values\" : [ 68 , \"+02:00\" ] } } } Once a value change in the desired section of the operation shadow is saved, a chain of events starts: A change in the desired section triggers the operationRequest rule. The operationRequest rule sends a request to AWS Lambda . AWS Lambda validates the request and forwards it as an event to Coiote DM, making it schedule a task and initiate a device session. Coiote DM communicates with the device. The device responds to Coiote DM with the operation result. Coiote DM forwards the device response back to the Operation Shadow and the results are published in the reported section. The change in the reported section triggers the operationResponse rule. The results are then republished using the operationResponse rule to the Datamodel shadow (but only in case of the READ, WRITE and READ COMPOSITE operations).","title":"Communication flow"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#datamodel-shadow","text":"The Datamodel Shadow is the place where the cashed data model of the LwM2M device is stored. What this means is that it is a \"read-only shadow\" that keeps the most recent record of the device state as it has been reported by Coiote DM - no device operations can be performed from here. The Datamodel Shadow is updated in case of the following events: Device Register message that comes from Coiote DM, Device Notify and Send messages, Republishing operation results from the Operation shadow to the Datamodel shadow using the operationResponse rule.","title":"Datamodel Shadow"},{"location":"AWS_Integration_Guide/Concepts/AWS_Integration_concepts.html#cloudwatch-logs","text":"CloudWatch collects and keeps a record of all the logs generated on the AWS-side of the integration. You can use these data for analysis and troubleshooting in case of all the AWS integration components: Device Shadows (the data plane), Things and Thing types (the control plane), The Rules mechanism, AWS Lambda.","title":"CloudWatch logs"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html","text":"Performing LwM2M operations # This section will give you an overview of how to perform LwM2M operations on devices in AWS IoT Core and check AWS CloudWatch logs. Prerequisites # A configured AWS integration. An active LwM2M device already migrated to AWS IoT Core. Execute LwM2M operations on device # Within the AWS - Coiote DM integration, LwM2M operations on devices are triggered by modifying the desired section of a device Operation Shadow . The changes, upon successful execution, are then reported back by Coiote DM and repopulated to the reported section of a device Datamodel Shadow . The integration supports the following LwM2M operations: READ # To send a request for a READ operation to a device: Enter AWS IoT Core and go to Manage > Things . From the list, select your device. Go to the Device Shadows section and select the operation Shadow. Click Edit and formulate the request inside the Device Shadow state field based on the example input given below: In the operation section, type the operation name In the keys section, type the LwM2M object and resource paths for which you want to execute the operation. In the values section, type the values for the specified keys (only for some operations). Read_request { \"state\": { \"desired\": { \"operation\": \"read\", \"keys\": [ \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array.4\" ] } } } Click Save . To see the operation results, check the reported section of the operation Shadow. An example response looks like this: Read_result { \"reported\": { \"operation\": \"read\", \"failedKeys\": [ \"\" ], \"result\": { \"Device\": { \"0\": { \"UTC Offset\": \"+02:00\" } }, \"LwM2M Server\": { \"1\": { \"Lifetime\": \"68\" } }, \"Portfolio\": { \"5\": { \"Identity\": { \"1\": \"AVS\" } }, \"11\": { \"Identity\": { \"1\": \"your_ID\" } } }, \"Test object\": { \"0\": { \"Integer array\": { \"4\": \"256\" } } } } } } Note To execute a READ operation on all the readable resources, enter \"\"/\"\" or \"\"all\"\" as the value in the keys section of the request. WRITE # To request a WRITE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Write_request { \"state\": { \"desired\": { \"operation\": \"write\", \"keys\": [ \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array.4\" ], \"values\": [ 68, \"your_ID\", \"random_value\", \"+02:00\", 256 ] } } } OBSERVE # To request a OBSERVE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Observe_request { \"state\": { \"desired\": { \"operation\": \"observe\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ {\"epmin\":5,\"gt\":-65.5,\"lt\":-105.5,\"st\":4.0}, {\"pmin\":30,\"pmax\":35}, {}, {\"epmax\":40}, {}, {\"pmax\":20} ] } } } Note In the attributes section, you need to specify the full attribute list with their corresponding values for a given key, as the attributes that are left out will be overwritten with null (except for the con attribute). Alternatively, you can provide an empty value {} so that no attribute values are changed. On the other hand, if you only specify the con attribute for a given key, it will not affect any other attributes and their existing values won't be changed also. To check the results of the OBSERVE operation, go to the datamodel Shadow of your device and see the reported section. EXECUTE # To request an EXECUTE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Execute_request { \"state\": { \"desired\": { \"operation\": \"execute\", \"keys\": [ \"Device.0.Reboot\" ] } } } Note With the EXECUTE operation, you can specify only one key for each request. Other operations # Here are example inputs for other operations supported by the integration: READ COMPOSITE, OBSERVE COMPOSITE, WRITE ATTRIBUTES, CANCEL OBSERVE, CANCEL OBSERVE COMPOSITE. Cancel Observe # Cancel_observe { \"state\": { \"desired\": { \"operation\": \"cancelObserve\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } } Note To cancel all the current OBSERVE requests, type \"all\" in the keys section. Write Attributes # Write_attributes { \"state\": { \"desired\": { \"operation\": \"writeAttributes\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ { \"epmin\": 5, \"gt\": -65.5, \"lt\": -105.5, \"st\": 4, \"con\": 1 }, { \"pmin\": 30, \"pmax\": 35, \"con\": \"\" }, {}, { \"epmax\": 40 }, { \"con\": null }, { \"pmax\": 20 } ] } } } Observe-Composite # Observe_composite { \"state\": { \"desired\": { \"operation\": \"observeComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ { \"epmin\": 5, \"gt\": -65.5, \"lt\": -105.5, \"st\": 4, \"con\": 1 }, { \"pmin\": 30, \"pmax\": 35, \"con\": \"\" }, {}, { \"epmax\": 40 }, { \"con\": null }, { \"pmax\": 20 } ] } } } Read-Composite # Read_composite { \"state\": { \"desired\": { \"operation\": \"readComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } } Cancel Observe-Composite # Cancelobserve_composite { \"state\": { \"desired\": { \"operation\": \"cancelObserveComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } } Check logs in CloudWatch # If you encounter difficulties when forwarding your requests to Coiote DM, it may be helpful to check the logs collected by AWS CloudWatch for all the components of the integration. To check logs for AWS Lambda: Go to AWS CloudWatch and select Logs > Log groups . From the Log groups list, select the /aws/lambda/lwm2mOperation group. To check logs for all integration components in one place: Go to AWS CloudWatch and select Logs > Log groups . From the Log groups list, select the AWSIotLogsV2 group. Select all the logs from the list by checking the box next to Log stream and click Search all . Expand a log stream to see its details by clicking the arrow icon > .","title":"Performing LwM2M operations"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#performing-lwm2m-operations","text":"This section will give you an overview of how to perform LwM2M operations on devices in AWS IoT Core and check AWS CloudWatch logs.","title":"Performing LwM2M operations"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#prerequisites","text":"A configured AWS integration. An active LwM2M device already migrated to AWS IoT Core.","title":"Prerequisites"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#execute-lwm2m-operations-on-device","text":"Within the AWS - Coiote DM integration, LwM2M operations on devices are triggered by modifying the desired section of a device Operation Shadow . The changes, upon successful execution, are then reported back by Coiote DM and repopulated to the reported section of a device Datamodel Shadow . The integration supports the following LwM2M operations:","title":"Execute LwM2M operations on device"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#read","text":"To send a request for a READ operation to a device: Enter AWS IoT Core and go to Manage > Things . From the list, select your device. Go to the Device Shadows section and select the operation Shadow. Click Edit and formulate the request inside the Device Shadow state field based on the example input given below: In the operation section, type the operation name In the keys section, type the LwM2M object and resource paths for which you want to execute the operation. In the values section, type the values for the specified keys (only for some operations). Read_request { \"state\": { \"desired\": { \"operation\": \"read\", \"keys\": [ \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array.4\" ] } } } Click Save . To see the operation results, check the reported section of the operation Shadow. An example response looks like this: Read_result { \"reported\": { \"operation\": \"read\", \"failedKeys\": [ \"\" ], \"result\": { \"Device\": { \"0\": { \"UTC Offset\": \"+02:00\" } }, \"LwM2M Server\": { \"1\": { \"Lifetime\": \"68\" } }, \"Portfolio\": { \"5\": { \"Identity\": { \"1\": \"AVS\" } }, \"11\": { \"Identity\": { \"1\": \"your_ID\" } } }, \"Test object\": { \"0\": { \"Integer array\": { \"4\": \"256\" } } } } } } Note To execute a READ operation on all the readable resources, enter \"\"/\"\" or \"\"all\"\" as the value in the keys section of the request.","title":"READ"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#write","text":"To request a WRITE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Write_request { \"state\": { \"desired\": { \"operation\": \"write\", \"keys\": [ \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array.4\" ], \"values\": [ 68, \"your_ID\", \"random_value\", \"+02:00\", 256 ] } } }","title":"WRITE"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#observe","text":"To request a OBSERVE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Observe_request { \"state\": { \"desired\": { \"operation\": \"observe\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ {\"epmin\":5,\"gt\":-65.5,\"lt\":-105.5,\"st\":4.0}, {\"pmin\":30,\"pmax\":35}, {}, {\"epmax\":40}, {}, {\"pmax\":20} ] } } } Note In the attributes section, you need to specify the full attribute list with their corresponding values for a given key, as the attributes that are left out will be overwritten with null (except for the con attribute). Alternatively, you can provide an empty value {} so that no attribute values are changed. On the other hand, if you only specify the con attribute for a given key, it will not affect any other attributes and their existing values won't be changed also. To check the results of the OBSERVE operation, go to the datamodel Shadow of your device and see the reported section.","title":"OBSERVE"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#execute","text":"To request an EXECUTE operation for a device, follow the steps 1-5 from the READ subsection, but using the following example: Execute_request { \"state\": { \"desired\": { \"operation\": \"execute\", \"keys\": [ \"Device.0.Reboot\" ] } } } Note With the EXECUTE operation, you can specify only one key for each request.","title":"EXECUTE"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#other-operations","text":"Here are example inputs for other operations supported by the integration: READ COMPOSITE, OBSERVE COMPOSITE, WRITE ATTRIBUTES, CANCEL OBSERVE, CANCEL OBSERVE COMPOSITE.","title":"Other operations"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#cancel-observe","text":"Cancel_observe { \"state\": { \"desired\": { \"operation\": \"cancelObserve\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } } Note To cancel all the current OBSERVE requests, type \"all\" in the keys section.","title":"Cancel Observe"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#write-attributes","text":"Write_attributes { \"state\": { \"desired\": { \"operation\": \"writeAttributes\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ { \"epmin\": 5, \"gt\": -65.5, \"lt\": -105.5, \"st\": 4, \"con\": 1 }, { \"pmin\": 30, \"pmax\": 35, \"con\": \"\" }, {}, { \"epmax\": 40 }, { \"con\": null }, { \"pmax\": 20 } ] } } }","title":"Write Attributes"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#observe-composite","text":"Observe_composite { \"state\": { \"desired\": { \"operation\": \"observeComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], \"attributes\": [ { \"epmin\": 5, \"gt\": -65.5, \"lt\": -105.5, \"st\": 4, \"con\": 1 }, { \"pmin\": 30, \"pmax\": 35, \"con\": \"\" }, {}, { \"epmax\": 40 }, { \"con\": null }, { \"pmax\": 20 } ] } } }","title":"Observe-Composite"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#read-composite","text":"Read_composite { \"state\": { \"desired\": { \"operation\": \"readComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } }","title":"Read-Composite"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#cancel-observe-composite","text":"Cancelobserve_composite { \"state\": { \"desired\": { \"operation\": \"cancelObserveComposite\", \"keys\": [ \"Connectivity Monitoring.0.Radio Signal Strength\", \"LwM2M Server.1.Lifetime\", \"Portfolio.11.Identity.1\", \"Portfolio.5.Identity.1\", \"Device.0.UTC Offset\", \"Test object.0.Integer array\" ], } } }","title":"Cancel Observe-Composite"},{"location":"AWS_Integration_Guide/Device_operations/Operation_types.html#check-logs-in-cloudwatch","text":"If you encounter difficulties when forwarding your requests to Coiote DM, it may be helpful to check the logs collected by AWS CloudWatch for all the components of the integration. To check logs for AWS Lambda: Go to AWS CloudWatch and select Logs > Log groups . From the Log groups list, select the /aws/lambda/lwm2mOperation group. To check logs for all integration components in one place: Go to AWS CloudWatch and select Logs > Log groups . From the Log groups list, select the AWSIotLogsV2 group. Select all the logs from the list by checking the box next to Log stream and click Search all . Expand a log stream to see its details by clicking the arrow icon > .","title":"Check logs in CloudWatch"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html","text":"Configuring integration extension # To enable communication and data flow between the Azure IoT Central and Coiote DM platforms, you first need to integrate them using the dedicated extension module in Coiote DM. Follow the instruction below to learn how to do it. Prerequisites: # An active IoT Central with hub owner access permissions. A Coiote DM user account with permissions to use the integration extension. Get the Azure IoT Central integration credentials # In your Azure IoT Central account view, go to Administration : Under Your application , copy the full Application URL (along with '.azureiotcentral.com') into Notepad or other place to keep it for later. From the Administration menu, select API tokens and click generate token . In the pop-up window that appears, click the copy icon for the newly generated token. Now you need to use the obtained credentials in the Coiote DM platform. Set up the Azure IoT Hub Extension using credentials. # In your Coiote DM user account, go to Administration --> Extensions . Find the Azure IoT Central tab and click Setup . Inside the tab: paste the previously copied Azure IoT Central Application URL , provide the API token and, if needed, enter your Device Provisioning Service hostname (however, the default address provided is sufficient in most cases). use Test connection to see if the connection can be established correctly. click Save to keep the setting. Next steps # Importing devices to Coiote DM Exporting devices to Azure IoT Central","title":"Configuring integration extension"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html#configuring-integration-extension","text":"To enable communication and data flow between the Azure IoT Central and Coiote DM platforms, you first need to integrate them using the dedicated extension module in Coiote DM. Follow the instruction below to learn how to do it.","title":"Configuring integration extension"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html#prerequisites","text":"An active IoT Central with hub owner access permissions. A Coiote DM user account with permissions to use the integration extension.","title":"Prerequisites:"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html#get-the-azure-iot-central-integration-credentials","text":"In your Azure IoT Central account view, go to Administration : Under Your application , copy the full Application URL (along with '.azureiotcentral.com') into Notepad or other place to keep it for later. From the Administration menu, select API tokens and click generate token . In the pop-up window that appears, click the copy icon for the newly generated token. Now you need to use the obtained credentials in the Coiote DM platform.","title":"Get the Azure IoT Central integration credentials"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html#set-up-the-azure-iot-hub-extension-using-credentials","text":"In your Coiote DM user account, go to Administration --> Extensions . Find the Azure IoT Central tab and click Setup . Inside the tab: paste the previously copied Azure IoT Central Application URL , provide the API token and, if needed, enter your Device Provisioning Service hostname (however, the default address provided is sufficient in most cases). use Test connection to see if the connection can be established correctly. click Save to keep the setting.","title":"Set up the Azure IoT Hub Extension using credentials."},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Configuring_Azure_IoT_Central_integration_extension.html#next-steps","text":"Importing devices to Coiote DM Exporting devices to Azure IoT Central","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html","text":"Exporting devices to Azure IoT Central # If you have device entities in Coiote DM that you would like to manage via the Azure IoT Central, you may use the export functionality. Follow the instruction below to learn how to do it in four basic steps: Create a device Create a group of devices for export Export your Coiote DM devices to CSV Import the CSV file to Azure IoT Central Create a device entity in Coiote DM # If you don't have any devices in your Coiote DM Device Inventory , follow these instructions to add one or more devices. In the Coiote DM Device Inventory , select Device Creator . In the next screen, choose the Connect your LwM2M device directly via the Management server . In the Device credentials step, provide a name for your device, then select NoSec from the Security mode list and click Add device . In the pop-up window, click Confirm to add your device entity. Now it should be listed in Device Inventory . Create a group of devices for export # Now that you have some devices added, you need to insert all the devices to be exported into a common group for ease of configuration. In Coiote DM, go to Device Inventory , filter the devices you would like to export and use the Add to group action. In the pop-up window that appears, select Add to new group , provide a name for the group and click Confirm . Export your devices to CSV # You are now ready to export your devices. In the Device groups panel, select your group of devices for export and click the Actions tab. Under Management , select the Export devices to Azure IoT Central . In the pop-up window: mark Skip already exported devices optionally if you have already exported some of the devices belonging to this group. select Export to CSV . After a moment, the export operation should finish and a CSV file should start downloading. Import the CSV file to Azure IoT Central # Once you have the CSV file downloaded, you can use it to import the devices into Azure IoT Central. From the left pane of your Azure IoT Central account, choose Devices and select a device template into which you want to import the devices. Select Import . In the pop-up that appears, select the previously downloaded CSV file. The import process should start. Its status can be tracked in the Device Operations panel in the top right-hand corner. Once the import process is complete, a success message should appear. If there are any errors, a log file will be generated in Device Operations that you can download. Note To learn more about importing device entities to Azure IoT Central, click here . Next steps #","title":"Exporting devices to Azure IoT Central"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#exporting-devices-to-azure-iot-central","text":"If you have device entities in Coiote DM that you would like to manage via the Azure IoT Central, you may use the export functionality. Follow the instruction below to learn how to do it in four basic steps: Create a device Create a group of devices for export Export your Coiote DM devices to CSV Import the CSV file to Azure IoT Central","title":"Exporting devices to Azure IoT Central"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#create-a-device-entity-in-coiote-dm","text":"If you don't have any devices in your Coiote DM Device Inventory , follow these instructions to add one or more devices. In the Coiote DM Device Inventory , select Device Creator . In the next screen, choose the Connect your LwM2M device directly via the Management server . In the Device credentials step, provide a name for your device, then select NoSec from the Security mode list and click Add device . In the pop-up window, click Confirm to add your device entity. Now it should be listed in Device Inventory .","title":"Create a device entity in Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#create-a-group-of-devices-for-export","text":"Now that you have some devices added, you need to insert all the devices to be exported into a common group for ease of configuration. In Coiote DM, go to Device Inventory , filter the devices you would like to export and use the Add to group action. In the pop-up window that appears, select Add to new group , provide a name for the group and click Confirm .","title":"Create a group of devices for export"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#export-your-devices-to-csv","text":"You are now ready to export your devices. In the Device groups panel, select your group of devices for export and click the Actions tab. Under Management , select the Export devices to Azure IoT Central . In the pop-up window: mark Skip already exported devices optionally if you have already exported some of the devices belonging to this group. select Export to CSV . After a moment, the export operation should finish and a CSV file should start downloading.","title":"Export your devices to CSV"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#import-the-csv-file-to-azure-iot-central","text":"Once you have the CSV file downloaded, you can use it to import the devices into Azure IoT Central. From the left pane of your Azure IoT Central account, choose Devices and select a device template into which you want to import the devices. Select Import . In the pop-up that appears, select the previously downloaded CSV file. The import process should start. Its status can be tracked in the Device Operations panel in the top right-hand corner. Once the import process is complete, a success message should appear. If there are any errors, a log file will be generated in Device Operations that you can download. Note To learn more about importing device entities to Azure IoT Central, click here .","title":"Import the CSV file to Azure IoT Central"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Exporting_devices_to_Azure_IoT_Central.html#next-steps","text":"","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html","text":"Importing devices to Coiote DM # If you would like to migrate any device entities from your Azure IoT Central to the Coiote DM platform for full management possibilities, follow the instruction below. Prerequisites # Configured and working Azure IoT Hub integration extension (see Configuring the Azure IoT Central integration extension for details). Add devices to Azure IoT Central # If you don't have any device entities added in your Azure IoT Central, follow these steps to learn how to do it: In your Azure IoT Central account, go to Devices , select All Devices and click +New . In the panel, click +New . Provide your device name and ID in the relevant field and click Create . Sync your devices # In order to establish communication and data flow between device entities in Azure IoT Central and their Coiote DM counterparts, you need to sync them. Go to Device inventory , click the Sync with IoT platform button and select Azure IoT Central . In the pop-up window: from the list, select the devices for synchronization. click Sync devices to start the synchronization. After a successful sync, the devices should be listed in Device inventory . Next steps #","title":"Importing devices to Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html#importing-devices-to-coiote-dm","text":"If you would like to migrate any device entities from your Azure IoT Central to the Coiote DM platform for full management possibilities, follow the instruction below.","title":"Importing devices to Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html#prerequisites","text":"Configured and working Azure IoT Hub integration extension (see Configuring the Azure IoT Central integration extension for details).","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html#add-devices-to-azure-iot-central","text":"If you don't have any device entities added in your Azure IoT Central, follow these steps to learn how to do it: In your Azure IoT Central account, go to Devices , select All Devices and click +New . In the panel, click +New . Provide your device name and ID in the relevant field and click Create .","title":"Add devices to Azure IoT Central"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html#sync-your-devices","text":"In order to establish communication and data flow between device entities in Azure IoT Central and their Coiote DM counterparts, you need to sync them. Go to Device inventory , click the Sync with IoT platform button and select Azure IoT Central . In the pop-up window: from the list, select the devices for synchronization. click Sync devices to start the synchronization. After a successful sync, the devices should be listed in Device inventory .","title":"Sync your devices"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Importing_devices_to_Coiote_DM.html#next-steps","text":"","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Overview.html","text":"Overview # How synchronization works # Coiote DM provides zero-touch provisioning for synchronized devices from Azure IoT Central. This means that device entities are automatically created within Coiote DM upon synchronization with the Azure IoT Central and this is repeated periodically for any new devices that appear. Therefore, after one successful synchronization, you can be sure that any devices that have been added to Azure IoT Central at a later time will also be migrated to Coiote DM.","title":"Overview"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Overview.html#overview","text":"","title":"Overview"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Central_integration/Device_operations/Overview.html#how-synchronization-works","text":"Coiote DM provides zero-touch provisioning for synchronized devices from Azure IoT Central. This means that device entities are automatically created within Coiote DM upon synchronization with the Azure IoT Central and this is repeated periodically for any new devices that appear. Therefore, after one successful synchronization, you can be sure that any devices that have been added to Azure IoT Central at a later time will also be migrated to Coiote DM.","title":"How synchronization works"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html","text":"Configuring integration extension # To enable communication and data flow between the Azure IoT Hub and Coiote DM platforms, you first need to integrate them using the dedicated extension module in Coiote DM. Follow the instruction below to learn how to do it. Prerequisites # An active IoT Hub with hub owner access permissions. Check here how to create a hub. A Coiote DM user account with permissions to use the integration extension. Optionally, an active Azure Blob Storage account. Get the IoT Hub connection string # In your IoT Hub general view, go to Shared access policies : From the list of policies, select the iothubowner policy. Under Shared access keys , click the copy icon for the Connection string -- primary key to save the value. Info For detailed information about the IoT Hub permissions, please visit the Control access to IoT Hub section of the Azure IoT Hub documentation. Now you need to use the credential in the Coiote DM platform. Set up the Azure IoT Hub Extension using credentials # In your Coiote DM user account, go to Administration --> Extensions . Find the Azure IoT Hub tab and click Setup . In the tab, paste the previously copied IoT Hub connection string. check Enable automatic synchronization to periodically synchronize any new devices that appear in the Azure IoT Hub. use Test connection to see if the connection can be established correctly. click Save to keep the setting. Optionally, you can also provide the Azure Blob Storage connection string that will be required in case you would like to export devices from Coiote DM to Azure IoT Hub. Click here to learn how to obtain and apply it. Next steps # Importing Azure IoT Hub devices to Coiote DM Exporting devices to Azure IoT Hub","title":"Configuring integration extension"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html#configuring-integration-extension","text":"To enable communication and data flow between the Azure IoT Hub and Coiote DM platforms, you first need to integrate them using the dedicated extension module in Coiote DM. Follow the instruction below to learn how to do it.","title":"Configuring integration extension"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html#prerequisites","text":"An active IoT Hub with hub owner access permissions. Check here how to create a hub. A Coiote DM user account with permissions to use the integration extension. Optionally, an active Azure Blob Storage account.","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html#get-the-iot-hub-connection-string","text":"In your IoT Hub general view, go to Shared access policies : From the list of policies, select the iothubowner policy. Under Shared access keys , click the copy icon for the Connection string -- primary key to save the value. Info For detailed information about the IoT Hub permissions, please visit the Control access to IoT Hub section of the Azure IoT Hub documentation. Now you need to use the credential in the Coiote DM platform.","title":"Get the IoT Hub connection string"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html#set-up-the-azure-iot-hub-extension-using-credentials","text":"In your Coiote DM user account, go to Administration --> Extensions . Find the Azure IoT Hub tab and click Setup . In the tab, paste the previously copied IoT Hub connection string. check Enable automatic synchronization to periodically synchronize any new devices that appear in the Azure IoT Hub. use Test connection to see if the connection can be established correctly. click Save to keep the setting. Optionally, you can also provide the Azure Blob Storage connection string that will be required in case you would like to export devices from Coiote DM to Azure IoT Hub. Click here to learn how to obtain and apply it.","title":"Set up the Azure IoT Hub Extension using credentials"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Configuring_Azure_IoT_Hub_integration_extension.html#next-steps","text":"Importing Azure IoT Hub devices to Coiote DM Exporting devices to Azure IoT Hub","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html","text":"Exporting devices to Azure IoT Hub # If you have device entities in Coiote DM that you would like to manage via the Azure IoT Hub, you may use the export functionality. Follow the instruction below to learn how to do it in four basic steps: Create a device Create a group of devices for export Get the Azure Blob storage connection string Export your devices Prerequisites # An active Azure Blob Storage account. Click here to learn more. Create a device entity in Coiote DM # If you don't have any devices in your Coiote DM Device Inventory , follow these instructions to add one or more devices. In the Coiote DM Device Inventory , select Device Creator . In the next screen, choose the Connect your LwM2M device directly via the Management server . In the Device credentials step, provide a name for your device, then select NoSec from the Security mode list and click Add device . In the pop-up window, click Confirm to add your device entity. Now it should be listed in Device Inventory . Create a group of devices for export # Now that you have some devices added, you need to insert all the devices to be exported into a common group for ease of configuration. In Coiote DM, go to Device Inventory , filter the devices you would like to export and use the Add to group action. In the pop-up window that appears, select Add to new group , provide a name for the group and click Confirm . Get the Azure Blob storage connection string # An Azure Blob storage connection string is required in the export process. Here is how to obtain it: In your Azure Blob storage account, go to Access keys . Click Show keys and copy the connection string to your clipboard. In your Coiote DM user account, go to Administration --> Extensions Find the Azure IoT Hub tab and click Setup . In the tab, paste the previously copied Azure Blob storage connection string. use Test connection to see if the connection can be established correctly. click Save to keep the setting. Export your devices # Now you are ready to export your devices. In the Device groups panel, select your group of devices for export and click the Actions tab. Under Management , select the Export devices to Azure IoT Hub . In the pop-up window: mark Skip already exported devices optionally if you have already exported some of the devices belonging to this group. select Start export . After a moment, the export operation should finish successfully. If there are any errors, you can check the credentials that you provided in the Azure IoT Hub extension setup. Next steps #","title":"Exporting devices to Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#exporting-devices-to-azure-iot-hub","text":"If you have device entities in Coiote DM that you would like to manage via the Azure IoT Hub, you may use the export functionality. Follow the instruction below to learn how to do it in four basic steps: Create a device Create a group of devices for export Get the Azure Blob storage connection string Export your devices","title":"Exporting devices to Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#prerequisites","text":"An active Azure Blob Storage account. Click here to learn more.","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#create-a-device-entity-in-coiote-dm","text":"If you don't have any devices in your Coiote DM Device Inventory , follow these instructions to add one or more devices. In the Coiote DM Device Inventory , select Device Creator . In the next screen, choose the Connect your LwM2M device directly via the Management server . In the Device credentials step, provide a name for your device, then select NoSec from the Security mode list and click Add device . In the pop-up window, click Confirm to add your device entity. Now it should be listed in Device Inventory .","title":"Create a device entity in Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#create-a-group-of-devices-for-export","text":"Now that you have some devices added, you need to insert all the devices to be exported into a common group for ease of configuration. In Coiote DM, go to Device Inventory , filter the devices you would like to export and use the Add to group action. In the pop-up window that appears, select Add to new group , provide a name for the group and click Confirm .","title":"Create a group of devices for export"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#get-the-azure-blob-storage-connection-string","text":"An Azure Blob storage connection string is required in the export process. Here is how to obtain it: In your Azure Blob storage account, go to Access keys . Click Show keys and copy the connection string to your clipboard. In your Coiote DM user account, go to Administration --> Extensions Find the Azure IoT Hub tab and click Setup . In the tab, paste the previously copied Azure Blob storage connection string. use Test connection to see if the connection can be established correctly. click Save to keep the setting.","title":"Get the Azure Blob storage connection string"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#export-your-devices","text":"Now you are ready to export your devices. In the Device groups panel, select your group of devices for export and click the Actions tab. Under Management , select the Export devices to Azure IoT Hub . In the pop-up window: mark Skip already exported devices optionally if you have already exported some of the devices belonging to this group. select Start export . After a moment, the export operation should finish successfully. If there are any errors, you can check the credentials that you provided in the Azure IoT Hub extension setup.","title":"Export your devices"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Exporting_devices_to_Azure_IoT_Hub.html#next-steps","text":"","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html","text":"Importing devices to Coiote DM # If you would like to migrate any device entities from your Azure IoT to the Coiote DM platform for full management possibilities, follow the instruction below. Prerequisites # Configured and working Azure IoT Hub integration extension (see Configuring the Azure IoT Hub integration extension for details). Add devices to Azure IoT Hub # If you don't have any device entities added in your Azure IoT Hub, follow these steps to learn how to do it: In your Azure IoT Hub account, under Explorers , select IoT devices . In the panel, click +New . Provide device ID in the relevant field and click Save . Your added devices should be visible in IoT devices under Explorers : Sync your devices # In order to establish communication and data flow between device entities in Azure IoT Hub and their Coiote DM counterparts, you need to sync them. Go to Device inventory , click the Sync with IoT platform button and select Azure IoT Hub . In the pop-up window: provide the WHERE clause of the device twin SQL query to filter your devices using chosen tags and properties (to read more about SQL query, check the IoT Hub query language section of Azure IoT Hub documentation. For instance, you can filter by device location region and device status with the following clause: tags.location.region = 'US' AND status = 'enabled' click Count queried devices to check the number of devices that meet the specified conditions (the number is shown inside the Sync devices button) to skip filtering and synchronize all the available devices, leave the WHERE clause input field empty. click Sync devices to start the synchronization. After successful import, the devices should be listed in Device inventory . Now that your devices are synchronized, after their successful connection to the Coiote DM platform, you should be able to see the updated device twin properties in Azure IoT Hub. Tip If the device twin parameters are not up-to-date after syncing, try the refresh data model action on the device. Next steps #","title":"Importing devices to Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html#importing-devices-to-coiote-dm","text":"If you would like to migrate any device entities from your Azure IoT to the Coiote DM platform for full management possibilities, follow the instruction below.","title":"Importing devices to Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html#prerequisites","text":"Configured and working Azure IoT Hub integration extension (see Configuring the Azure IoT Hub integration extension for details).","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html#add-devices-to-azure-iot-hub","text":"If you don't have any device entities added in your Azure IoT Hub, follow these steps to learn how to do it: In your Azure IoT Hub account, under Explorers , select IoT devices . In the panel, click +New . Provide device ID in the relevant field and click Save . Your added devices should be visible in IoT devices under Explorers :","title":"Add devices to Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html#sync-your-devices","text":"In order to establish communication and data flow between device entities in Azure IoT Hub and their Coiote DM counterparts, you need to sync them. Go to Device inventory , click the Sync with IoT platform button and select Azure IoT Hub . In the pop-up window: provide the WHERE clause of the device twin SQL query to filter your devices using chosen tags and properties (to read more about SQL query, check the IoT Hub query language section of Azure IoT Hub documentation. For instance, you can filter by device location region and device status with the following clause: tags.location.region = 'US' AND status = 'enabled' click Count queried devices to check the number of devices that meet the specified conditions (the number is shown inside the Sync devices button) to skip filtering and synchronize all the available devices, leave the WHERE clause input field empty. click Sync devices to start the synchronization. After successful import, the devices should be listed in Device inventory . Now that your devices are synchronized, after their successful connection to the Coiote DM platform, you should be able to see the updated device twin properties in Azure IoT Hub. Tip If the device twin parameters are not up-to-date after syncing, try the refresh data model action on the device.","title":"Sync your devices"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Importing_devices_to_Coiote_DM.html#next-steps","text":"","title":"Next steps"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Overview.html","text":"Overview # How synchronization works # Coiote DM provides zero-touch provisioning for synchronized devices from Azure IoT Hub. This means that device entities are automatically created within Coiote DM upon synchronization with the Azure IoT Hub and this is repeated periodically for any new devices that appear. Therefore, after one successful synchronization, you can be sure that any devices that have been added to Azure IoT Hub at a later time will also be migrated to Coiote DM.","title":"Overview"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Overview.html#overview","text":"","title":"Overview"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Overview.html#how-synchronization-works","text":"Coiote DM provides zero-touch provisioning for synchronized devices from Azure IoT Hub. This means that device entities are automatically created within Coiote DM upon synchronization with the Azure IoT Hub and this is repeated periodically for any new devices that appear. Therefore, after one successful synchronization, you can be sure that any devices that have been added to Azure IoT Hub at a later time will also be migrated to Coiote DM.","title":"How synchronization works"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html","text":"Upgrading device firmware # If you would like to upgrade the firmware of devices using the Azure IoT Hub, follow the instruction below. Prerequisites # At least one device with active Coiote DM - Azure IoT Hub synchronization . A firmware file hosted on an HTTP server that is reachable by the Coiote DM server. Note In this stage of integration, no authentication method is supported for this endpoint - it is required that the firmware is publicly available (or hosted in a private network but with access granted for the Coiote DM server). Scheduling a firmware upgrade # Introduction # The process of upgrading device firmware for Azure IoT Hub devices synchronized with Coiote DM is based on two main elements: the Azure Direct Method mechanism and the Coiote DM Firmware Upgrade task. In the process, the Azure scheduleFirmwareUpdate direct method is invoked, enabling the Coiote DM to download the specified firmware file and add it to its resources. Then, an XML task is scheduled in Coiote DM and the upgrade is performed on the device. Info For firmware file recognition in Coiote, global identifiers are used. This means that it is recommended to name your firmware files using the format: yourdomainName + randomized value. If the same firmware file name is used again, then Coiote DM will be able to utilize the once downloaded resource without the need to download it again. Step 1: Invoking the Azure scheduleFirmwareUpdate direct method # To initiate the firmware upgrade procedure for your device: Go to your Azure hub account and under Explorers , select IoT devices . From the list, choose the device for which you want to upgrade the firmware. In the device view, select the Direct Method tab. Provide data for the following fields: Method Name - paste the scheduleFirmwareUpdate direct method name here. Payload - use the following payload with firmware upgrade parameters (remember to replace the example values where needed): { \"name\": \"anjay-firmware\", \"firmwareUrl\": \"https://example.repository.com/artifactory/gitlfs/demo.fw-pkg\", // optional - default=\"1200s\", any valid duration in format \"<length><unit>\" \"timeout\": \"1200s\", // optional - default=\"COAP\" \"protocolType\": \"COAP\", // optional - default=null <-> keep firmware file forever, any valid duration in format \"<length><unit>\" or null \"retentionPeriod\": \"300s\", // optional - default=\"\" \"description\": \"This is anjay demo firmware\", // optional - default=false \"useQuota\": false, // optional - default=false \"useCachedData\": false, // optional - default=false \"resumeAfterDownlinkFailure\": false, // optional - default=\"pull\", possible values = [\"pull\", \"push\"] \"imageDeliveryMethod\": \"pull\", // optional - default=\"WithoutObservations\", possible values = [\"ObservationTrigger\", \"WithoutObservations\", \"ObservationBased\", \"SendBased\"] \"upgradeStrategy\": \"WithoutObservations\", // optional - default=\"always\", possible values = [\"always\", \"weekends\", \"nights-home\", \"nights-enterprise-weekends\", \"nights-enterprise\", user-defined schedules] \"schedule\": \"always\" } Connection timeout - specify a timeout for the Azure - Coiote DM connection (the recommended value is not less than 5 seconds). Method timeout - specify a timeout for direct method result notification. Once you have provided the required data, click Invoke method . After a short moment, you should be able to see the direct method result in the Result field. The 200 as the \"status\" parameter value means that the firmware upgrade task was completed successfully. Importantly, the result \"payload\" value will be needed for other FOTA actions like status check or cancellation, so be sure to copy it to your clipboard if needed. Tip Out of all the parameters provided in Firmware upgrade direct method payload, only two are mandatory: name - the unique file name used for firmware identification. firmwareUrl - the URL used by Coiote DM to download the firmware file and include it as a resource. Therefore it is correct to include only those two in the payload, as in here: { \"name\": \"anjay-firmware\", \"firmwareUrl\": \"https://example.repository.com/artifactory/gitlfs/demo.fw-pkg\", } Step 2: Checking the firmware upgrade result # To check the status of a scheduled firmware upgrade, follow these steps: In the Direct Method tab of your device, provide data for the following fields: Method Name - paste the checkFirmwareUpdateStatus direct method name here. Payload - use the payload displayed in the Firmware upgrade result field (remember to replace the placeholder value with your copied value): { \"fotaId\": \"fotaIdReturnedByScheduleOperation\" } Click Invoke method . Check the direct method status in the Result field: Step 3: Checking Coiote DM FOTA task execution # Once you have executed the Azure-side steps of the procedure, you can check its status from the side of Coiote DM. Go to your Coiote DM account and in the Device Inventory , select your device. In the Device Management Center, enter the LwM2M firmware tab. Check the status of the FOTA task execution for your device: In the Current firmware section, check if the device firmware is updated to the newest version. In the Installation history section, check if the lwm2mFirmwareUpdate task invoked earlier by the Azure scheduleFirmwareUpdate direct method has been completed with success. Cancelling the firmware upgrade procedure # To cancel the firmware upgrade procedure, follow these steps: In the Direct Method tab of your device, provide data for the following fields: Method Name - paste the cancelFirmwareUpdate direct method name here. Payload - use the payload displayed in the Firmware upgrade result field (remember to replace the placeholder value with your copied value): { \"fotaId\": \"fotaIdReturnedByScheduleOperation\" } Click Invoke method . Check the direct method status in the Result field: See also # See the relevant section of LwM2M mappings to learn the details of how Azure IoT Hub Direct Methods are mapped in Coiote DM.","title":"Upgrading device firmware"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#upgrading-device-firmware","text":"If you would like to upgrade the firmware of devices using the Azure IoT Hub, follow the instruction below.","title":"Upgrading device firmware"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#prerequisites","text":"At least one device with active Coiote DM - Azure IoT Hub synchronization . A firmware file hosted on an HTTP server that is reachable by the Coiote DM server. Note In this stage of integration, no authentication method is supported for this endpoint - it is required that the firmware is publicly available (or hosted in a private network but with access granted for the Coiote DM server).","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#scheduling-a-firmware-upgrade","text":"","title":"Scheduling a firmware upgrade"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#introduction","text":"The process of upgrading device firmware for Azure IoT Hub devices synchronized with Coiote DM is based on two main elements: the Azure Direct Method mechanism and the Coiote DM Firmware Upgrade task. In the process, the Azure scheduleFirmwareUpdate direct method is invoked, enabling the Coiote DM to download the specified firmware file and add it to its resources. Then, an XML task is scheduled in Coiote DM and the upgrade is performed on the device. Info For firmware file recognition in Coiote, global identifiers are used. This means that it is recommended to name your firmware files using the format: yourdomainName + randomized value. If the same firmware file name is used again, then Coiote DM will be able to utilize the once downloaded resource without the need to download it again.","title":"Introduction"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#step-1-invoking-the-azure-schedulefirmwareupdate-direct-method","text":"To initiate the firmware upgrade procedure for your device: Go to your Azure hub account and under Explorers , select IoT devices . From the list, choose the device for which you want to upgrade the firmware. In the device view, select the Direct Method tab. Provide data for the following fields: Method Name - paste the scheduleFirmwareUpdate direct method name here. Payload - use the following payload with firmware upgrade parameters (remember to replace the example values where needed): { \"name\": \"anjay-firmware\", \"firmwareUrl\": \"https://example.repository.com/artifactory/gitlfs/demo.fw-pkg\", // optional - default=\"1200s\", any valid duration in format \"<length><unit>\" \"timeout\": \"1200s\", // optional - default=\"COAP\" \"protocolType\": \"COAP\", // optional - default=null <-> keep firmware file forever, any valid duration in format \"<length><unit>\" or null \"retentionPeriod\": \"300s\", // optional - default=\"\" \"description\": \"This is anjay demo firmware\", // optional - default=false \"useQuota\": false, // optional - default=false \"useCachedData\": false, // optional - default=false \"resumeAfterDownlinkFailure\": false, // optional - default=\"pull\", possible values = [\"pull\", \"push\"] \"imageDeliveryMethod\": \"pull\", // optional - default=\"WithoutObservations\", possible values = [\"ObservationTrigger\", \"WithoutObservations\", \"ObservationBased\", \"SendBased\"] \"upgradeStrategy\": \"WithoutObservations\", // optional - default=\"always\", possible values = [\"always\", \"weekends\", \"nights-home\", \"nights-enterprise-weekends\", \"nights-enterprise\", user-defined schedules] \"schedule\": \"always\" } Connection timeout - specify a timeout for the Azure - Coiote DM connection (the recommended value is not less than 5 seconds). Method timeout - specify a timeout for direct method result notification. Once you have provided the required data, click Invoke method . After a short moment, you should be able to see the direct method result in the Result field. The 200 as the \"status\" parameter value means that the firmware upgrade task was completed successfully. Importantly, the result \"payload\" value will be needed for other FOTA actions like status check or cancellation, so be sure to copy it to your clipboard if needed. Tip Out of all the parameters provided in Firmware upgrade direct method payload, only two are mandatory: name - the unique file name used for firmware identification. firmwareUrl - the URL used by Coiote DM to download the firmware file and include it as a resource. Therefore it is correct to include only those two in the payload, as in here: { \"name\": \"anjay-firmware\", \"firmwareUrl\": \"https://example.repository.com/artifactory/gitlfs/demo.fw-pkg\", }","title":"Step 1: Invoking the Azure scheduleFirmwareUpdate direct method"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#step-2-checking-the-firmware-upgrade-result","text":"To check the status of a scheduled firmware upgrade, follow these steps: In the Direct Method tab of your device, provide data for the following fields: Method Name - paste the checkFirmwareUpdateStatus direct method name here. Payload - use the payload displayed in the Firmware upgrade result field (remember to replace the placeholder value with your copied value): { \"fotaId\": \"fotaIdReturnedByScheduleOperation\" } Click Invoke method . Check the direct method status in the Result field:","title":"Step 2: Checking the firmware upgrade result"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#step-3-checking-coiote-dm-fota-task-execution","text":"Once you have executed the Azure-side steps of the procedure, you can check its status from the side of Coiote DM. Go to your Coiote DM account and in the Device Inventory , select your device. In the Device Management Center, enter the LwM2M firmware tab. Check the status of the FOTA task execution for your device: In the Current firmware section, check if the device firmware is updated to the newest version. In the Installation history section, check if the lwm2mFirmwareUpdate task invoked earlier by the Azure scheduleFirmwareUpdate direct method has been completed with success.","title":"Step 3: Checking Coiote DM FOTA task execution"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#cancelling-the-firmware-upgrade-procedure","text":"To cancel the firmware upgrade procedure, follow these steps: In the Direct Method tab of your device, provide data for the following fields: Method Name - paste the cancelFirmwareUpdate direct method name here. Payload - use the payload displayed in the Firmware upgrade result field (remember to replace the placeholder value with your copied value): { \"fotaId\": \"fotaIdReturnedByScheduleOperation\" } Click Invoke method . Check the direct method status in the Result field:","title":"Cancelling the firmware upgrade procedure"},{"location":"Azure_IoT_Integration_Guide/Azure_IoT_Hub_integration/Device_operations/Upgrading_firmware.html#see-also","text":"See the relevant section of LwM2M mappings to learn the details of how Azure IoT Hub Direct Methods are mapped in Coiote DM.","title":"See also"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html","text":"LwM2M mappings # In this section you'll get to know how the mappings are arranged between the LwM2M protocol as used in Coiote DM and the data retrieval and processing mechanisms of the Azure IoT Hub, such as Device Twins, Direct Method and Device-to-cloud messaging. Introduction # The LwM2M protocol data model is organized as a three-level tree that has the following structure: object (e.g. a 'temperature sensor') object instance (e.g. 'temperature sensor #1', 'temperature sensor #2' etc.) resource (e.g. 'current temperature value') In terms of operations that can be performed on an LwM2M Client, an LwM2M Server can READ all of the data model entities, and, depending on their characteristics, may also WRITE to some of them, and EXECUTE some of them. Additionally, an LwM2M Server can also OBSERVE selected resources. Info If you would like to dive deeper into the details of the Lightweight M2M protocol, please refer to our brief introduction to LwM2M . This division into readable, writable, executable and observable data model entities is the basis for the mapping of LwM2M resources (as interpreted by Coiote DM) into Azure IoT Hub data processing mechanisms. LwM2M readable and writable resources # Within the Coiote DM - Azure IoT Hub integration, readable and writable resources are usually interpreted as part of Azure Device twin data structure. Note To learn more about Device twins, go to the Understand and use Device twins section of the Azure IoT Hub documentation. For instance, the sample JSON snippet below is a tree with nested resources to represent a fragment of the LwM2M data model with path /3/1/1 : { \"deviceId\": \"airquality-0\", ... \"properties\": { \"reported\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 90 }, \"4\": {}, \"6\": {}, \"7\": {}, \"8\": {} } }, \"3\": { \"1\": { \"1\": { \"value\": \"airquality-0-Valparaiso\" } } }, ... READ - Communication flow # Data model resources that are read-only, such as Manufacturer (with ID 3/0/0 ) will be mapped into the Device twin as a reported property. WRITE - Communication flow # On the other hand, a writable resource, such as Lifetime (with ID 1/0/1 ), apart from being represented as a reported property, can be additionally mapped as a desired property. This enables you to synchronize the device data model and configuration between Azure and Coiote DM. Changing the value of a writable resource involves creating a properly formatted JSON snippet in the desired property field within the Device twin that introduces a value change: ... \"properties\": { \"desired\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 30 } } } }, ... After JSON is saved, Azure notifies Coiote DM of the desired change which is then transferred to the device in form of a WRITE command. Once the value is changed on the device, Coiote DM reports back to Azure that the value of the corresponding reported property should be updated in the Device twin JSON structure. LwM2M executable resources # As a rule, LwM2M resources that can be executable translate into Direct methods in Azure IoT Hub. This means that by invoking a direct method from Azure, you can trigger an EXECUTE operation on a chosen resource available for your device and the request will be transferred immediately by the LwM2M Server to the device. Note To learn more about Direct methods, go to the Understand Direct methods section of the Azure IoT Hub documentation. An executable LwM2M resource ID is mapped to a direct method in the following way: method name: execute { path: \"object.objectInstance.resource\", [args: \"optional arguments to execute\"] } Thus, for instance, to execute a factory reset on a device, you need to invoke a direct method with the execute name and the following payload: { path: \"3.0.5\" } EXECUTE - Communication flow # Invoking a direct method from Azure IoT Hub and handling it by Coiote DM in the form of an EXECUTE operation passed to the device has the following flow: LwM2M observable resources # In Coiote DM, some of the resources within the device data model can be observed for changes in value. These are generally resources related to telemetry data or other measurements. Their value changes can be monitored by Coiote DM and reported to the Azure IoT Hub Device-to-cloud mechanism. Note To learn more about the Azure Device-to-cloud, go to sending device-to-cloud messages section of the Azure IoT Hub documentation. Observe - Communication flow # Setting an Observe operation on a resource in Coiote DM, for instance a temperature reading, will result in a Notify message sent by the device upon value change that Coiote DM will transfer to the Device-to-cloud mechanism of Azure IoT Hub. What is more, you can set observations on LwM2M resources from the Azure IoT Hub level by adding appropriate attributes to the resource as a Device twin desired property. For instance, an Observe operation on resource ID 3303/1/5700 is set in the following way: ... \"properties\": { \"desired\": { \"lwm2m\": { \"3303\": { \"1\": { \"5700\": { \"observed\": true, \"attributes\": { \"pmin\": 60 } } } } } ... After JSON is saved, Azure notifies Coiote DM of the desired attribute setting which is then transferred to the device in form of an Observe operation. Once Coiote DM is notified of a value change, it is reported to the Azure Device-to-cloud mechanism.","title":"LwM2M mappings"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#lwm2m-mappings","text":"In this section you'll get to know how the mappings are arranged between the LwM2M protocol as used in Coiote DM and the data retrieval and processing mechanisms of the Azure IoT Hub, such as Device Twins, Direct Method and Device-to-cloud messaging.","title":"LwM2M mappings"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#introduction","text":"The LwM2M protocol data model is organized as a three-level tree that has the following structure: object (e.g. a 'temperature sensor') object instance (e.g. 'temperature sensor #1', 'temperature sensor #2' etc.) resource (e.g. 'current temperature value') In terms of operations that can be performed on an LwM2M Client, an LwM2M Server can READ all of the data model entities, and, depending on their characteristics, may also WRITE to some of them, and EXECUTE some of them. Additionally, an LwM2M Server can also OBSERVE selected resources. Info If you would like to dive deeper into the details of the Lightweight M2M protocol, please refer to our brief introduction to LwM2M . This division into readable, writable, executable and observable data model entities is the basis for the mapping of LwM2M resources (as interpreted by Coiote DM) into Azure IoT Hub data processing mechanisms.","title":"Introduction"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#lwm2m-readable-and-writable-resources","text":"Within the Coiote DM - Azure IoT Hub integration, readable and writable resources are usually interpreted as part of Azure Device twin data structure. Note To learn more about Device twins, go to the Understand and use Device twins section of the Azure IoT Hub documentation. For instance, the sample JSON snippet below is a tree with nested resources to represent a fragment of the LwM2M data model with path /3/1/1 : { \"deviceId\": \"airquality-0\", ... \"properties\": { \"reported\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 90 }, \"4\": {}, \"6\": {}, \"7\": {}, \"8\": {} } }, \"3\": { \"1\": { \"1\": { \"value\": \"airquality-0-Valparaiso\" } } }, ...","title":"LwM2M readable and writable resources"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#read-communication-flow","text":"Data model resources that are read-only, such as Manufacturer (with ID 3/0/0 ) will be mapped into the Device twin as a reported property.","title":"READ - Communication flow"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#write-communication-flow","text":"On the other hand, a writable resource, such as Lifetime (with ID 1/0/1 ), apart from being represented as a reported property, can be additionally mapped as a desired property. This enables you to synchronize the device data model and configuration between Azure and Coiote DM. Changing the value of a writable resource involves creating a properly formatted JSON snippet in the desired property field within the Device twin that introduces a value change: ... \"properties\": { \"desired\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 30 } } } }, ... After JSON is saved, Azure notifies Coiote DM of the desired change which is then transferred to the device in form of a WRITE command. Once the value is changed on the device, Coiote DM reports back to Azure that the value of the corresponding reported property should be updated in the Device twin JSON structure.","title":"WRITE - Communication flow"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#lwm2m-executable-resources","text":"As a rule, LwM2M resources that can be executable translate into Direct methods in Azure IoT Hub. This means that by invoking a direct method from Azure, you can trigger an EXECUTE operation on a chosen resource available for your device and the request will be transferred immediately by the LwM2M Server to the device. Note To learn more about Direct methods, go to the Understand Direct methods section of the Azure IoT Hub documentation. An executable LwM2M resource ID is mapped to a direct method in the following way: method name: execute { path: \"object.objectInstance.resource\", [args: \"optional arguments to execute\"] } Thus, for instance, to execute a factory reset on a device, you need to invoke a direct method with the execute name and the following payload: { path: \"3.0.5\" }","title":"LwM2M executable resources"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#execute-communication-flow","text":"Invoking a direct method from Azure IoT Hub and handling it by Coiote DM in the form of an EXECUTE operation passed to the device has the following flow:","title":"EXECUTE - Communication flow"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#lwm2m-observable-resources","text":"In Coiote DM, some of the resources within the device data model can be observed for changes in value. These are generally resources related to telemetry data or other measurements. Their value changes can be monitored by Coiote DM and reported to the Azure IoT Hub Device-to-cloud mechanism. Note To learn more about the Azure Device-to-cloud, go to sending device-to-cloud messages section of the Azure IoT Hub documentation.","title":"LwM2M observable resources"},{"location":"Azure_IoT_Integration_Guide/Concepts/LwM2M_mappings.html#observe-communication-flow","text":"Setting an Observe operation on a resource in Coiote DM, for instance a temperature reading, will result in a Notify message sent by the device upon value change that Coiote DM will transfer to the Device-to-cloud mechanism of Azure IoT Hub. What is more, you can set observations on LwM2M resources from the Azure IoT Hub level by adding appropriate attributes to the resource as a Device twin desired property. For instance, an Observe operation on resource ID 3303/1/5700 is set in the following way: ... \"properties\": { \"desired\": { \"lwm2m\": { \"3303\": { \"1\": { \"5700\": { \"observed\": true, \"attributes\": { \"pmin\": 60 } } } } } ... After JSON is saved, Azure notifies Coiote DM of the desired attribute setting which is then transferred to the device in form of an Observe operation. Once Coiote DM is notified of a value change, it is reported to the Azure Device-to-cloud mechanism.","title":"Observe - Communication flow"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html","text":"Air quality monitoring - tutorial # The Coiote DM and Azure IoT Hub integration lets you create custom use cases with data visualization. See the video and have a sneak peek at the possibilities that the Coiote DM - Azure IoT Hub integration offers you. In the tutorial, you will see how to leverage the integration to create an air quality monitoring in just a few steps. The text version of the tutorial, complete with the necessary steps and code snippets, is available below: Prerequisites # An active Azure subscription. An active Coiote DM account. Please refer to Coiote DM home page for details on how to get it. An active Microsoft Power BI account. An OpenWeatherMap account with a free API token. An active and configured Azure CLI - please refer to the Azure CLI installation guide for details. Creating and configuring an Azure IoT hub and storage account # First you need to add a new IoT hub and a storage account in Azure. Here's how to do it: Creating an IoT hub # In your Azure portal home view, go to IoT Hub and select Add . In the Basics tab: select your subscription and resource group, pick your region, provide a name for your IoT hub. In the Management tab: in Pricing and scale tier select, optionally, turn off Defender for IoT . In the Review + create tab, click Create . Creating a storage account # While your new IoT hub is deploying, you can add a new storage account: In the Azure portal, go to Storage accounts and select Add . In the Basics tab: select your subscription and resource group, provide a name for your storage account, pick your location. In the Review + create tab, click Create . Configuring the Azure IoT Hub integration extension # Once the deployments are complete, go to Coiote DM to set up the Azure IoT Hub extension. If you haven't done this yet, please follow the instruction for the Azure IoT Hub integration configuration . Adding and connecting LwM2M air quality meter simulators to Coiote DM and Azure IoT Hub # Go to your Azure IoT Hub and add new devices: Under Explorers , select IoT Devices and click + New . Provide the name for your first device: air-quality-meter-example-0 . Click Save . Repeat the procedure for the other 5 devices (increase the number included in the device name). Go to Coiote DM and sync the previously added devices: In Device inventory , select Sync with IoT platform -> Azure IoT Hub . In the pop-up, click Sync devices . Devices should then be visible in Device inventory Go to your command line and register the device simulators: Paste and run the following command to create a container group: az container create -g coiote-dm-experiments --name air-quality-meter-example-0 --image avsystemcom/air-quality-meter-example --environment-variables DEVICEID=air-quality-meter-example-0 SERVER_ADDRESS=eu.iot.avsystem.cloud OPEN_WEATHER_API_TOKEN=exampletoken Note Remember to change the command parameters accordingly so that they are in line with your naming and credentials. once the command is executed, you should see a JSON payload that describes the content of the container instance. Go back to Coiote DM and in Device inventory , check if the devices have registered to the platform and if their data model has been updated. Click the Refresh data icon if needed. Click on a device and in the Device Management Center , select the Actions panel. Select the Refresh data model from device link and confirm by clicking Yes, execute task now . Go to the Objects panel to see if the data model for the device has been updated. You should be able to see objects such as 3 Device (along with the Model number resource which shows the name of the city of the temperature reading), 3303 Temperature , and 3428 Air quality . Bidirectional communication using Device Twin # From Coiote DM to Azure IoT Hub # In your Coiote DM account, go to Device inventory , select a device. In the Device Management Center , go to the Objects panel. In the 1 LwM2M Server object, find the Lifetime resource. Click the pen icon next to it, change the lifetime value and click the Apply link. Go to your Azure IoT hub, select IoT devices , click your device and select the Device Twin panel. Click Refresh and check in the JSON payload if the reported property for the 1/0/1 (Lifetime) resource has changed. From Azure IoT Hub to Coiote DM # Note To read more about how the Device Twins work in the Coiote DM - Azure IoT Hub integration, please refer to the LwM2M Mappings section . In your Azure IoT hub, select IoT devices , click one of your added devices and select the Device Twin panel. To change the Lifetime resource in Coiote DM, you need to modify the relevant Device Twin desired property. under the properties tag in the Device Twin JSON payload, paste the following nested structure: \"reported\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 45 } } } } }, - Click Save and Refresh . The value of the resource should now be changed in the Device Twin reported properties as well as in the Coiote DM Objects panel, in the Lifetime resource of the 1 LwM2M Server object. Passing telemetry to Azure IoT Hub # Setting group value tracking on resources in Coiote DM # In Coiote DM, go to Device inventory and use the search option to display your air quality meter devices. Then, click the Add to group icon. In the pop-up, click Add to new group , provide a name for your group (following the pattern root.iothubexample.airqualitymeter), click Confirm and Yes . Go to the Group management panel, select your group and click Devices to see if all of your devices are added to the group. Go to the Value tracking panel and click Add new . In the pop-up: Add value tracking for the Temperature resource: Provide the resource path: Temperature.1.Sensor Value . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Add value tracking for the Air quality PM10 resource: Provide the resource path: Air quality.1.PM10 . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Add value tracking for the Air quality PM2.5 resource: Provide the resource path: Air quality.1.PM2_5 . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Go back to Device inventory and select a device of your group. In the Dashboard view , you should be able to see the value tracking parameters as in the picture below: Configuring message routing for sending telemetry data in Azure IoT Hub # Go to your Azure IoT hub and add message routing: Under Messaging , select Message routing and click + Add . Provide a name for your event, for example EventRoute . From the Endpoint drop-down list, select events . In the Routing query , paste the following: IS_DEFINED($body.lwm2m.3303.1.5700.value) OR IS_DEFINED($body.lwm2m.3428.1.1.value) OR IS_DEFINED($body.lwm2m.3428.1.3.value) Click Save . While in the Message routing panel, go to the Enrich messages tab to set up location tracking: For latitude: Name - type lat Value - copy and paste $twin.properties.reported.lwm2m.6.1.0.value Endpoint(s) - select events For longitude: Name - type lon Value - copy and paste $twin.properties.reported.lwm2m.6.1.1.value Endpoint(s) - select events For longitude: Name - type deviceId Value - copy and paste $twin.properties.reported.lwm2m.3.1.1.value Endpoint(s) - select events Use search to go to Stream analytics jobs and create a job for transferring the gathered data to Power BI. Click + Add and provide the following: Job name - e.g. avsystem-iot-hub-to-powerbi . Resource group - pick your resource group. Click Create . Once your deployment is complete, click Go to resource . While in your Stream Analytics job panel, add a stream input and output and write a query: Under Job topology , select Inputs . From the + Add stream input drop-down list, select Iot Hub and provide the following: Input alias - e.g. avsystem-iot-hub-input . Consumer group - pick the $Default group. Click Save . Under Job topology , select Outputs . From the + Add drop-down list, select Power BI and click Authorize . Log in to Power BI using your Azure account. In the Power BI right-hand side panel, provide the following: Output alias - e.g. avsystem-iot-hub-output Dataset name - e.g. AVSystemIoTHubDataSet Table name - e.g. Data Click Save . Under Job topology , select Query . Paste the following query into the query input field (remember to adjust your naming inside the query if needed): SELECT CAST(lwm2m.\"3303.\"1\".\"5700\".value as float) as temperature, CAST(lwm2m.\"3428.\"1\".\"1\".value as float) as pm10, CAST(lwm2m.\"3428.\"1\".\"3\".value as float) as pm25, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User].[lat]') as lat, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User],[lon]') as lon, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User],[deviceId]') as deviceId2, EventProcessedUtcTime as processedTimestamp, IoTHub.EnqueuedTime as iotHubTimestamp, IoTHub.ConnectionDeviceId as deviceId INTO \"avsystem-iot-hub-output\" FROM \"avsystem-iot-hub-input\" Click Save query . In your Stream analytics job, go to Overview and click Start and confirm by clicking Start in the Start job window to run the created query. Data visualization using Power BI # Once the query is finished, you can go to Power BI to create a visualization for the data you have gathered. Go to https://powerbi.microsoft.com/ and sign in to your account. Go to My workspace and find your recently created dataset. Click the more options icon and select Create report From the Visualizations menu, select the table icon and drag and drop it to the work space. From the Fields menu, select the deviceId2 , temperature , pm10 and pm25 parameters. In the Values submenu, expand the drop-down list for the temperature , pm10 and pm25 parameters and select Average for each. Create a map with air quality indicators: From the Visualizations menu, click the get more visuals icon and select Get more visuals . Use search to find the Heatmap and click Add . From the Visualizations menu, click the Heatmap icon. Add the relevant parameters to the map data fields: To the Latitude data field, drag and drop the lat parameter from the Fields menu. To the Longitude data field, drag and drop the lon parameter from the Fields menu. To the Value data field, drag and drop the pm10 parameter from the Fields menu. In the Value data field, expand the drop-down list and select Average . To refresh the displayed data, click the Refresh button located in the upper navigation bar.","title":"Air quality monitoring - tutorial"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#air-quality-monitoring-tutorial","text":"The Coiote DM and Azure IoT Hub integration lets you create custom use cases with data visualization. See the video and have a sneak peek at the possibilities that the Coiote DM - Azure IoT Hub integration offers you. In the tutorial, you will see how to leverage the integration to create an air quality monitoring in just a few steps. The text version of the tutorial, complete with the necessary steps and code snippets, is available below:","title":"Air quality monitoring - tutorial"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#prerequisites","text":"An active Azure subscription. An active Coiote DM account. Please refer to Coiote DM home page for details on how to get it. An active Microsoft Power BI account. An OpenWeatherMap account with a free API token. An active and configured Azure CLI - please refer to the Azure CLI installation guide for details.","title":"Prerequisites"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#creating-and-configuring-an-azure-iot-hub-and-storage-account","text":"First you need to add a new IoT hub and a storage account in Azure. Here's how to do it:","title":"Creating and configuring an Azure IoT hub and storage account"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#creating-an-iot-hub","text":"In your Azure portal home view, go to IoT Hub and select Add . In the Basics tab: select your subscription and resource group, pick your region, provide a name for your IoT hub. In the Management tab: in Pricing and scale tier select, optionally, turn off Defender for IoT . In the Review + create tab, click Create .","title":"Creating an IoT hub"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#creating-a-storage-account","text":"While your new IoT hub is deploying, you can add a new storage account: In the Azure portal, go to Storage accounts and select Add . In the Basics tab: select your subscription and resource group, provide a name for your storage account, pick your location. In the Review + create tab, click Create .","title":"Creating a storage account"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#configuring-the-azure-iot-hub-integration-extension","text":"Once the deployments are complete, go to Coiote DM to set up the Azure IoT Hub extension. If you haven't done this yet, please follow the instruction for the Azure IoT Hub integration configuration .","title":"Configuring the Azure IoT Hub integration extension"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#adding-and-connecting-lwm2m-air-quality-meter-simulators-to-coiote-dm-and-azure-iot-hub","text":"Go to your Azure IoT Hub and add new devices: Under Explorers , select IoT Devices and click + New . Provide the name for your first device: air-quality-meter-example-0 . Click Save . Repeat the procedure for the other 5 devices (increase the number included in the device name). Go to Coiote DM and sync the previously added devices: In Device inventory , select Sync with IoT platform -> Azure IoT Hub . In the pop-up, click Sync devices . Devices should then be visible in Device inventory Go to your command line and register the device simulators: Paste and run the following command to create a container group: az container create -g coiote-dm-experiments --name air-quality-meter-example-0 --image avsystemcom/air-quality-meter-example --environment-variables DEVICEID=air-quality-meter-example-0 SERVER_ADDRESS=eu.iot.avsystem.cloud OPEN_WEATHER_API_TOKEN=exampletoken Note Remember to change the command parameters accordingly so that they are in line with your naming and credentials. once the command is executed, you should see a JSON payload that describes the content of the container instance. Go back to Coiote DM and in Device inventory , check if the devices have registered to the platform and if their data model has been updated. Click the Refresh data icon if needed. Click on a device and in the Device Management Center , select the Actions panel. Select the Refresh data model from device link and confirm by clicking Yes, execute task now . Go to the Objects panel to see if the data model for the device has been updated. You should be able to see objects such as 3 Device (along with the Model number resource which shows the name of the city of the temperature reading), 3303 Temperature , and 3428 Air quality .","title":"Adding and connecting LwM2M air quality meter simulators to Coiote DM and Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#bidirectional-communication-using-device-twin","text":"","title":"Bidirectional communication using Device Twin"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#from-coiote-dm-to-azure-iot-hub","text":"In your Coiote DM account, go to Device inventory , select a device. In the Device Management Center , go to the Objects panel. In the 1 LwM2M Server object, find the Lifetime resource. Click the pen icon next to it, change the lifetime value and click the Apply link. Go to your Azure IoT hub, select IoT devices , click your device and select the Device Twin panel. Click Refresh and check in the JSON payload if the reported property for the 1/0/1 (Lifetime) resource has changed.","title":"From Coiote DM to Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#from-azure-iot-hub-to-coiote-dm","text":"Note To read more about how the Device Twins work in the Coiote DM - Azure IoT Hub integration, please refer to the LwM2M Mappings section . In your Azure IoT hub, select IoT devices , click one of your added devices and select the Device Twin panel. To change the Lifetime resource in Coiote DM, you need to modify the relevant Device Twin desired property. under the properties tag in the Device Twin JSON payload, paste the following nested structure: \"reported\": { \"lwm2m\": { \"1\": { \"0\": { \"0\": {}, \"1\": { \"value\": 45 } } } } }, - Click Save and Refresh . The value of the resource should now be changed in the Device Twin reported properties as well as in the Coiote DM Objects panel, in the Lifetime resource of the 1 LwM2M Server object.","title":"From Azure IoT Hub to Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#passing-telemetry-to-azure-iot-hub","text":"","title":"Passing telemetry to Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#setting-group-value-tracking-on-resources-in-coiote-dm","text":"In Coiote DM, go to Device inventory and use the search option to display your air quality meter devices. Then, click the Add to group icon. In the pop-up, click Add to new group , provide a name for your group (following the pattern root.iothubexample.airqualitymeter), click Confirm and Yes . Go to the Group management panel, select your group and click Devices to see if all of your devices are added to the group. Go to the Value tracking panel and click Add new . In the pop-up: Add value tracking for the Temperature resource: Provide the resource path: Temperature.1.Sensor Value . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Add value tracking for the Air quality PM10 resource: Provide the resource path: Air quality.1.PM10 . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Add value tracking for the Air quality PM2.5 resource: Provide the resource path: Air quality.1.PM2_5 . In the Notification frequency section, provide the following values: At least once every - set it to 10 seconds. Not more often than once every - set it to 5 seconds. Click Add new . Go back to Device inventory and select a device of your group. In the Dashboard view , you should be able to see the value tracking parameters as in the picture below:","title":"Setting group value tracking on resources in Coiote DM"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#configuring-message-routing-for-sending-telemetry-data-in-azure-iot-hub","text":"Go to your Azure IoT hub and add message routing: Under Messaging , select Message routing and click + Add . Provide a name for your event, for example EventRoute . From the Endpoint drop-down list, select events . In the Routing query , paste the following: IS_DEFINED($body.lwm2m.3303.1.5700.value) OR IS_DEFINED($body.lwm2m.3428.1.1.value) OR IS_DEFINED($body.lwm2m.3428.1.3.value) Click Save . While in the Message routing panel, go to the Enrich messages tab to set up location tracking: For latitude: Name - type lat Value - copy and paste $twin.properties.reported.lwm2m.6.1.0.value Endpoint(s) - select events For longitude: Name - type lon Value - copy and paste $twin.properties.reported.lwm2m.6.1.1.value Endpoint(s) - select events For longitude: Name - type deviceId Value - copy and paste $twin.properties.reported.lwm2m.3.1.1.value Endpoint(s) - select events Use search to go to Stream analytics jobs and create a job for transferring the gathered data to Power BI. Click + Add and provide the following: Job name - e.g. avsystem-iot-hub-to-powerbi . Resource group - pick your resource group. Click Create . Once your deployment is complete, click Go to resource . While in your Stream Analytics job panel, add a stream input and output and write a query: Under Job topology , select Inputs . From the + Add stream input drop-down list, select Iot Hub and provide the following: Input alias - e.g. avsystem-iot-hub-input . Consumer group - pick the $Default group. Click Save . Under Job topology , select Outputs . From the + Add drop-down list, select Power BI and click Authorize . Log in to Power BI using your Azure account. In the Power BI right-hand side panel, provide the following: Output alias - e.g. avsystem-iot-hub-output Dataset name - e.g. AVSystemIoTHubDataSet Table name - e.g. Data Click Save . Under Job topology , select Query . Paste the following query into the query input field (remember to adjust your naming inside the query if needed): SELECT CAST(lwm2m.\"3303.\"1\".\"5700\".value as float) as temperature, CAST(lwm2m.\"3428.\"1\".\"1\".value as float) as pm10, CAST(lwm2m.\"3428.\"1\".\"3\".value as float) as pm25, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User].[lat]') as lat, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User],[lon]') as lon, GetMetadataPropertyValue(\"avsystem-iot-hub-input\", '[User],[deviceId]') as deviceId2, EventProcessedUtcTime as processedTimestamp, IoTHub.EnqueuedTime as iotHubTimestamp, IoTHub.ConnectionDeviceId as deviceId INTO \"avsystem-iot-hub-output\" FROM \"avsystem-iot-hub-input\" Click Save query . In your Stream analytics job, go to Overview and click Start and confirm by clicking Start in the Start job window to run the created query.","title":"Configuring message routing for sending telemetry data in Azure IoT Hub"},{"location":"Azure_IoT_Integration_Guide/Tutorials/Air_quality_monitoring_tutorial.html#data-visualization-using-power-bi","text":"Once the query is finished, you can go to Power BI to create a visualization for the data you have gathered. Go to https://powerbi.microsoft.com/ and sign in to your account. Go to My workspace and find your recently created dataset. Click the more options icon and select Create report From the Visualizations menu, select the table icon and drag and drop it to the work space. From the Fields menu, select the deviceId2 , temperature , pm10 and pm25 parameters. In the Values submenu, expand the drop-down list for the temperature , pm10 and pm25 parameters and select Average for each. Create a map with air quality indicators: From the Visualizations menu, click the get more visuals icon and select Get more visuals . Use search to find the Heatmap and click Add . From the Visualizations menu, click the Heatmap icon. Add the relevant parameters to the map data fields: To the Latitude data field, drag and drop the lat parameter from the Fields menu. To the Longitude data field, drag and drop the lon parameter from the Fields menu. To the Value data field, drag and drop the pm10 parameter from the Fields menu. In the Value data field, expand the drop-down list and select Average . To refresh the displayed data, click the Refresh button located in the upper navigation bar.","title":"Data visualization using Power BI"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html","text":"Configuring test cases # Introduction # This chapter covers the configuration aspects of the interoperability tests. It explains how to list and view the configuration of test cases, and how to add, edit, delete, import, and export them. Note The configuration of test cases is device-independent, which means that all the configured test cases can be applied for all the devices that have registered to the platform. Interoperability tests configuration panel # In this section you will learn about the layout and main features of the Protocol tests configuration panel. To enter the panel, in the navigation menu, select Protocol tests configuration . Search \u2013 use it to search the test case list. Import \u2013 use it to import test cases. Add a new test case \u2013 use it to add a new test case to the list. 'Select all' checkbox \u2013 use it to select or deselect all test cases visible in the list. 'Delete selected' button \u2013 use it to delete selected test cases. 'Export selected' button - use it to export selected test cases. Test case list \u2013 it features all the test cases available for you at the moment, or all the test cases meeting the search criteria (if entered). Domain name \u2013 it shows the names of domains and subdomains to which your test cases belong. Export icon \u2013 use it to export a single test case. Trash bin icon \u2013 use it to delete a single test case. Listing test cases # The test cases appearing in the test cases panel are presented in the form of a searchable alphabetical list to ensure their convenient viewing and management. Read this section to learn how to use the search to list your test cases. Using the search # To search the list of configured test cases start typing your entry into the search field. The matching items will appear in the list. Tip Note that if you select a test case from the filtered list, and then erase your entry from the search field, the selection will be carried over to the complete list view. Similarly, if you use the select all checkbox in the full list view, and then filter the list using the search, the selection will be carried over to the filtered list view. Viewing test case configuration # Read this section to learn how to view the configuration of an individual test case: From the navigation menu, select Protocol tests configuration . In the list, find the test case you want to view and click on its name. In the action list, expand the action items by clicking the \u02c5 icon. To expand or collapse the complete action list, use the Expand all and Collapse all buttons. Optionally, you can use the Edit test case button to edit your test case or click the trash bin icon to delete it. Adding new test cases # Read this section to learn how to add a new test case. From the navigation menu, select Protocol tests configuration . Click the Add a new test case button in the top-right corner: Configure your test case: Enter your Test case name (this field is mandatory). Enter your Test case description (this field is optional). Select your Reference device (this field is optional). You can either: type the exact device name in the Reference device search field and hit \u2018Enter\u2019, click Select reference device and select your device from the pop-up list. If you cannot see your device in the list, start typing its name in the search field to get matching results. In the Action list , specify your actions: To add your first action item, choose its name from the drop-down list, or type its name in the Specify action field. Within the action, fill in the mandatory attributes field. To add another action item, use the Add action button and specify your next action. To change the order of actions within the test case, drag and drop the action item you want to move by using the drag icon. To copy an action item, click the copy icon (except for the Loop action). To delete an action item, click the trash bin icon. If your test case is ready and all the mandatory fields are filled, click Add a new test case . Note To learn more about individual test actions, see the Test case action description chapter. Editing test cases # Read this section to learn how to edit a test case. Note If you edit a test case that was executed before, the existing historical results for this test case will no longer be available. From the navigation menu, select Protocol tests configuration . From the list, choose the test case you want to edit and click on its name. Click the Edit test case button in the top-right corner. Edit your test case: Modify your Test case name (this field is mandatory). Modify your Test case description (this field is optional). Change or add your Reference device (this field is optional). You can either: type the exact device ID in the Reference device search field and hit Enter , click Select reference device and select your device from the pop-up list. If you cannot see your device in the list, start typing its name in the search field to get matching results. In the Action list, edit your actions: Edit an existing action item by changing its name, modifying its attributes. Add another action item using the Add action button. Change the order of actions within the test case by dragging and dropping the action item you want to move using the drag icon. Copy an action item by clicking on the copy icon (except for the Loop action). Delete an action item by clicking on the trash bin icon. If you are done editing your test case and all the mandatory fields remain filled, click Save changes . Deleting test cases # Read this section to learn how to delete test cases. To delete individual test cases: From the navigation menu, select Protocol tests configuration . From the list, choose the test case you want to delete. Click the trash bin icon located on the right of the test case entry. In the pop-up that appears, click Confirm . To delete multiple test cases: From the navigation menu, select Protocol tests configuration . From the test case list, choose the test case you want to delete and click the 'Delete selected' button. In the pop-up that appears, click Confirm . Importing test cases # Read this section to learn how to import test cases. From the navigation menu, select Protocol tests configuration . Select the Import button, choose your file from the pop-up window and click Open . Your imported test cases will appear in the list with the status New . Exporting test cases # Read this section to learn how to export test cases. From the navigation menu, select Protocol tests configuration . From the list, select the test case(s) you want to export: If you want to export a single test case, just select the test case and click on the export icon on the right of the test case line item. If you want to export a group of test cases, select all the test cases and click on the export icon appearing at the top of the list. The test case(s) will be downloaded in the .conf format. Tip Edit the exported test cases using Windows Notepad or other standard text editor.","title":"Configuring test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#configuring-test-cases","text":"","title":"Configuring test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#introduction","text":"This chapter covers the configuration aspects of the interoperability tests. It explains how to list and view the configuration of test cases, and how to add, edit, delete, import, and export them. Note The configuration of test cases is device-independent, which means that all the configured test cases can be applied for all the devices that have registered to the platform.","title":"Introduction"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#interoperability-tests-configuration-panel","text":"In this section you will learn about the layout and main features of the Protocol tests configuration panel. To enter the panel, in the navigation menu, select Protocol tests configuration . Search \u2013 use it to search the test case list. Import \u2013 use it to import test cases. Add a new test case \u2013 use it to add a new test case to the list. 'Select all' checkbox \u2013 use it to select or deselect all test cases visible in the list. 'Delete selected' button \u2013 use it to delete selected test cases. 'Export selected' button - use it to export selected test cases. Test case list \u2013 it features all the test cases available for you at the moment, or all the test cases meeting the search criteria (if entered). Domain name \u2013 it shows the names of domains and subdomains to which your test cases belong. Export icon \u2013 use it to export a single test case. Trash bin icon \u2013 use it to delete a single test case.","title":"Interoperability tests configuration panel"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#listing-test-cases","text":"The test cases appearing in the test cases panel are presented in the form of a searchable alphabetical list to ensure their convenient viewing and management. Read this section to learn how to use the search to list your test cases.","title":"Listing test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#using-the-search","text":"To search the list of configured test cases start typing your entry into the search field. The matching items will appear in the list. Tip Note that if you select a test case from the filtered list, and then erase your entry from the search field, the selection will be carried over to the complete list view. Similarly, if you use the select all checkbox in the full list view, and then filter the list using the search, the selection will be carried over to the filtered list view.","title":"Using the search"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#viewing-test-case-configuration","text":"Read this section to learn how to view the configuration of an individual test case: From the navigation menu, select Protocol tests configuration . In the list, find the test case you want to view and click on its name. In the action list, expand the action items by clicking the \u02c5 icon. To expand or collapse the complete action list, use the Expand all and Collapse all buttons. Optionally, you can use the Edit test case button to edit your test case or click the trash bin icon to delete it.","title":"Viewing test case configuration"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#adding-new-test-cases","text":"Read this section to learn how to add a new test case. From the navigation menu, select Protocol tests configuration . Click the Add a new test case button in the top-right corner: Configure your test case: Enter your Test case name (this field is mandatory). Enter your Test case description (this field is optional). Select your Reference device (this field is optional). You can either: type the exact device name in the Reference device search field and hit \u2018Enter\u2019, click Select reference device and select your device from the pop-up list. If you cannot see your device in the list, start typing its name in the search field to get matching results. In the Action list , specify your actions: To add your first action item, choose its name from the drop-down list, or type its name in the Specify action field. Within the action, fill in the mandatory attributes field. To add another action item, use the Add action button and specify your next action. To change the order of actions within the test case, drag and drop the action item you want to move by using the drag icon. To copy an action item, click the copy icon (except for the Loop action). To delete an action item, click the trash bin icon. If your test case is ready and all the mandatory fields are filled, click Add a new test case . Note To learn more about individual test actions, see the Test case action description chapter.","title":"Adding new test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#editing-test-cases","text":"Read this section to learn how to edit a test case. Note If you edit a test case that was executed before, the existing historical results for this test case will no longer be available. From the navigation menu, select Protocol tests configuration . From the list, choose the test case you want to edit and click on its name. Click the Edit test case button in the top-right corner. Edit your test case: Modify your Test case name (this field is mandatory). Modify your Test case description (this field is optional). Change or add your Reference device (this field is optional). You can either: type the exact device ID in the Reference device search field and hit Enter , click Select reference device and select your device from the pop-up list. If you cannot see your device in the list, start typing its name in the search field to get matching results. In the Action list, edit your actions: Edit an existing action item by changing its name, modifying its attributes. Add another action item using the Add action button. Change the order of actions within the test case by dragging and dropping the action item you want to move using the drag icon. Copy an action item by clicking on the copy icon (except for the Loop action). Delete an action item by clicking on the trash bin icon. If you are done editing your test case and all the mandatory fields remain filled, click Save changes .","title":"Editing test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#deleting-test-cases","text":"Read this section to learn how to delete test cases. To delete individual test cases: From the navigation menu, select Protocol tests configuration . From the list, choose the test case you want to delete. Click the trash bin icon located on the right of the test case entry. In the pop-up that appears, click Confirm . To delete multiple test cases: From the navigation menu, select Protocol tests configuration . From the test case list, choose the test case you want to delete and click the 'Delete selected' button. In the pop-up that appears, click Confirm .","title":"Deleting test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#importing-test-cases","text":"Read this section to learn how to import test cases. From the navigation menu, select Protocol tests configuration . Select the Import button, choose your file from the pop-up window and click Open . Your imported test cases will appear in the list with the status New .","title":"Importing test cases"},{"location":"Interoperability_tests_guide/Configuring_test_cases.html#exporting-test-cases","text":"Read this section to learn how to export test cases. From the navigation menu, select Protocol tests configuration . From the list, select the test case(s) you want to export: If you want to export a single test case, just select the test case and click on the export icon on the right of the test case line item. If you want to export a group of test cases, select all the test cases and click on the export icon appearing at the top of the list. The test case(s) will be downloaded in the .conf format. Tip Edit the exported test cases using Windows Notepad or other standard text editor.","title":"Exporting test cases"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html","text":"Device data model and variables # Displaying device data model and running simple actions # Coiote DM gives you the possibility to view and perform actions on the data model of individual devices defined by the LwM2M protocol. This view is available under the Objects panel of your device. Read this chapter to learn how to use the panel. Search - use it to find a particular object. To find the object, type its name. If checked, the changes you make to device objects will be applied immediately. Otherwise, you will have to wait for the device to trigger action execution or use the Execute tasks button (for devices in non-queue mode). !!! note The Apply immediately option is only available for devices in non-queue mode. Use this button to add a new LwM2M object definition. Division into objects. The info icon - click it to see the object description. Managing instances: [A] - Use it to select another instance of an object if the object has instances. [B] - Use it to add a new instance if an object allows it. [C] - Use it to select another instance or remove it. Search - use it to find a particular resource. To find the resource, type its name. Use it to refresh data, track values (send an Observe task) and add additional attributes to a selected instance. Use it to refresh data, track values (send an Observe task) and add additional attributes to a selected object. The table with resources of an object instance. Note The icon displaying the status of execution is available after clicking on one of the action buttons located in the Actions column. If you click it, you will see additional information about execution. Execution status icon Use it to refresh the resource. Value tracking - use it to send an Observe task to the device and configure monitoring to collect data. Attributes - use it to edit resource attributes or add new ones. Use it to edit a value of a resource. Execute - use it to send an Execute task to the device. Click the icon next to the button to add additional parameters. Managing device variables # Use the Variables panel to add custom variables onto your device for the purpose of protocol tests and view the existing variables that the device has inherited. To enter the Variables panel, go to Device Management Center by clicking on a selected device name and choose the Variables tab. The Custom device variables list shows the variables that belong to this particular device. To add a variable, click on Add , provide its name and value, and click Save . Note that every custom variable that you add will have the VARIABLE_ prefix. To delete a previously added variable, click the Trash bin icon and click Save . The Inherited variables list shows only the variables that the device inherits from the groups of devices that is belongs to. The list is view-only. To add a variable to this list, go to Device Groups and, in the Profiles panel, add an entry with the name beginning with VARIABLE_ . Using variables in test case actions # To use device variables, enter the expression context by typing ${variable.<variableName>} while defining a test case action. Remember that each variable is treated as a string, therefore, to use it as a different data type, you will have to cast it to the appropriate type.\u2003 Using variables - example # Learn how to use device variables in Interoperability tests in a few steps: Use case: Testing the WRITE action on the LwM2M Server.1.Lifetime resource. Add the variable: In Device inventory , click on a selected device name to enter its Device Management Center . Select the Variables tab. Tip If the Variables tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Click on Add and provide the following: Name: lifetime120 . Value: 120 . Click Save . Create a test case and include the new variable in the appropriate format: To add a new test case, follow the steps in Creating your first test case section, but including the adjustments below: For example purposes, pick only the Write action. In the Parameter name field, type LwM2M Server.1.Lifetime (note that the path may vary slightly depending on your device data model). In the Value field, type ${variable.lifetime120.toInt} . Tip By default, the variable value is rendered as a string data type. To cast it to the integer data type, .toInt suffix is added to the created expression, as seen above. Run the created test case and check if the variable works correctly: To run the test case, follow the steps in Running the test case on device using the test case created in the previous step. After the test case is finished, check if the Lifetime resource value has changed on the device: Go to the Objects panel of your device and under the LwM2M Server object, look for the Lifetime resource value: If the value has changed accordingly, the variable can be now reused and populated to any other test cases.","title":"Device data model and variables"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html#device-data-model-and-variables","text":"","title":"Device data model and variables"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html#displaying-device-data-model-and-running-simple-actions","text":"Coiote DM gives you the possibility to view and perform actions on the data model of individual devices defined by the LwM2M protocol. This view is available under the Objects panel of your device. Read this chapter to learn how to use the panel. Search - use it to find a particular object. To find the object, type its name. If checked, the changes you make to device objects will be applied immediately. Otherwise, you will have to wait for the device to trigger action execution or use the Execute tasks button (for devices in non-queue mode). !!! note The Apply immediately option is only available for devices in non-queue mode. Use this button to add a new LwM2M object definition. Division into objects. The info icon - click it to see the object description. Managing instances: [A] - Use it to select another instance of an object if the object has instances. [B] - Use it to add a new instance if an object allows it. [C] - Use it to select another instance or remove it. Search - use it to find a particular resource. To find the resource, type its name. Use it to refresh data, track values (send an Observe task) and add additional attributes to a selected instance. Use it to refresh data, track values (send an Observe task) and add additional attributes to a selected object. The table with resources of an object instance. Note The icon displaying the status of execution is available after clicking on one of the action buttons located in the Actions column. If you click it, you will see additional information about execution. Execution status icon Use it to refresh the resource. Value tracking - use it to send an Observe task to the device and configure monitoring to collect data. Attributes - use it to edit resource attributes or add new ones. Use it to edit a value of a resource. Execute - use it to send an Execute task to the device. Click the icon next to the button to add additional parameters.","title":"Displaying device data model and running simple actions"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html#managing-device-variables","text":"Use the Variables panel to add custom variables onto your device for the purpose of protocol tests and view the existing variables that the device has inherited. To enter the Variables panel, go to Device Management Center by clicking on a selected device name and choose the Variables tab. The Custom device variables list shows the variables that belong to this particular device. To add a variable, click on Add , provide its name and value, and click Save . Note that every custom variable that you add will have the VARIABLE_ prefix. To delete a previously added variable, click the Trash bin icon and click Save . The Inherited variables list shows only the variables that the device inherits from the groups of devices that is belongs to. The list is view-only. To add a variable to this list, go to Device Groups and, in the Profiles panel, add an entry with the name beginning with VARIABLE_ .","title":"Managing device variables"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html#using-variables-in-test-case-actions","text":"To use device variables, enter the expression context by typing ${variable.<variableName>} while defining a test case action. Remember that each variable is treated as a string, therefore, to use it as a different data type, you will have to cast it to the appropriate type.","title":"Using variables in test case actions"},{"location":"Interoperability_tests_guide/Data_model_and_variables.html#using-variables-example","text":"Learn how to use device variables in Interoperability tests in a few steps: Use case: Testing the WRITE action on the LwM2M Server.1.Lifetime resource. Add the variable: In Device inventory , click on a selected device name to enter its Device Management Center . Select the Variables tab. Tip If the Variables tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Click on Add and provide the following: Name: lifetime120 . Value: 120 . Click Save . Create a test case and include the new variable in the appropriate format: To add a new test case, follow the steps in Creating your first test case section, but including the adjustments below: For example purposes, pick only the Write action. In the Parameter name field, type LwM2M Server.1.Lifetime (note that the path may vary slightly depending on your device data model). In the Value field, type ${variable.lifetime120.toInt} . Tip By default, the variable value is rendered as a string data type. To cast it to the integer data type, .toInt suffix is added to the created expression, as seen above. Run the created test case and check if the variable works correctly: To run the test case, follow the steps in Running the test case on device using the test case created in the previous step. After the test case is finished, check if the Lifetime resource value has changed on the device: Go to the Objects panel of your device and under the LwM2M Server object, look for the Lifetime resource value: If the value has changed accordingly, the variable can be now reused and populated to any other test cases.","title":"Using variables - example"},{"location":"Interoperability_tests_guide/Getting_started.html","text":"Getting started # Start using the Interoperability tests feature right away. This short instruction will help you create your first test case, run it on a device and see the execution logs. Prerequisites # A device that is added and registered in the platform. Create your first test case # From the navigation menu on the left, select Protocol tests configuration . Click the Add a new test case button in the top-right corner. Configure your test case: Provide a name for your test case. Under the Action list , click the Add action button and select Write from the drop down list and provide data for the following fields: Parameter name : Device.0.Manufacturer , Expected value : Example_manufacturer , Expected response code : 4.05 MethodNotAllowed . Under the Action list , select Read from the drop down list and provide data for the following fields: Parameter name : LwM2M Server.1.Binding , Expected value : U , Expected response code : 2.05 Content . Select the Add a new test case button. Run the test case on device # In the Device inventory , select a currently registered device and enter its Device Management Center . In Device Management Center , select the Protocol tests tab. Note If the Protocol tests tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Tick the test case you have just created and click Run selected (1) . After a few moments, the execution should end and test case status changes from In progress to Success . Tip The Success status of a test case is a measure of the correctness of the device response against the expected test case parameters. Depending on the device and tester's needs, there may be test cases that are successful when the device responds with a Failure message (similarly to the example presented in this section). Check test execution details # To see test execution logs for your test case: While in the Protocol tests panel, find your test case and click on its name. Expand the Logs section using the ^ arrow icon to see execution details. 3. Use the Check logs button for each action inside the test case to see the highlighted results for this action.","title":"Getting started"},{"location":"Interoperability_tests_guide/Getting_started.html#getting-started","text":"Start using the Interoperability tests feature right away. This short instruction will help you create your first test case, run it on a device and see the execution logs.","title":"Getting started"},{"location":"Interoperability_tests_guide/Getting_started.html#prerequisites","text":"A device that is added and registered in the platform.","title":"Prerequisites"},{"location":"Interoperability_tests_guide/Getting_started.html#create-your-first-test-case","text":"From the navigation menu on the left, select Protocol tests configuration . Click the Add a new test case button in the top-right corner. Configure your test case: Provide a name for your test case. Under the Action list , click the Add action button and select Write from the drop down list and provide data for the following fields: Parameter name : Device.0.Manufacturer , Expected value : Example_manufacturer , Expected response code : 4.05 MethodNotAllowed . Under the Action list , select Read from the drop down list and provide data for the following fields: Parameter name : LwM2M Server.1.Binding , Expected value : U , Expected response code : 2.05 Content . Select the Add a new test case button.","title":"Create your first test case"},{"location":"Interoperability_tests_guide/Getting_started.html#run-the-test-case-on-device","text":"In the Device inventory , select a currently registered device and enter its Device Management Center . In Device Management Center , select the Protocol tests tab. Note If the Protocol tests tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Tick the test case you have just created and click Run selected (1) . After a few moments, the execution should end and test case status changes from In progress to Success . Tip The Success status of a test case is a measure of the correctness of the device response against the expected test case parameters. Depending on the device and tester's needs, there may be test cases that are successful when the device responds with a Failure message (similarly to the example presented in this section).","title":"Run the test case on device"},{"location":"Interoperability_tests_guide/Getting_started.html#check-test-execution-details","text":"To see test execution logs for your test case: While in the Protocol tests panel, find your test case and click on its name. Expand the Logs section using the ^ arrow icon to see execution details. 3. Use the Check logs button for each action inside the test case to see the highlighted results for this action.","title":"Check test execution details"},{"location":"Interoperability_tests_guide/Overview.html","text":"Overview # Interoperability tests are a comprehensive and convenient solution for the customization and performance of LwM2M protocol tests on LwM2M devices. Offered as part of the Coiote IoT Device Management platform, it enables you develop test cases from scratch to tailor them to your devices, or use the ready-made test cases (including scenarios described in OMA Enabler Test Specification for Lightweight M2M by OMA SpecWorks and scenarios created by AVSystem ). The following guide will walk you through the basic functionalities of the interoperability tests solution. You will learn how to configure, run and manage your test cases and get to know in detail each possible action that can be defined within a test case.","title":"Overview"},{"location":"Interoperability_tests_guide/Overview.html#overview","text":"Interoperability tests are a comprehensive and convenient solution for the customization and performance of LwM2M protocol tests on LwM2M devices. Offered as part of the Coiote IoT Device Management platform, it enables you develop test cases from scratch to tailor them to your devices, or use the ready-made test cases (including scenarios described in OMA Enabler Test Specification for Lightweight M2M by OMA SpecWorks and scenarios created by AVSystem ). The following guide will walk you through the basic functionalities of the interoperability tests solution. You will learn how to configure, run and manage your test cases and get to know in detail each possible action that can be defined within a test case.","title":"Overview"},{"location":"Interoperability_tests_guide/Running_test_cases.html","text":"Running test cases # If you have test cases configured in the platform, you can run them on your device using the Protocol tests panel. Read this chapter to learn how to display test case descriptions, start and stop test case execution and view test results and logs. Protocol tests panel description # The protocol tests panel is available in the Device Management Center individually for each device. To access it, select a device in Device Inventory to enter its Device Management Center and select Protocol tests from the menu on the left. Tip If the Protocol tests tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Read this section to learn about the main components that it comprises. Test case list \u2013 views all the test cases available for a given device. It is searchable and can be filtered. Info icon \u2013 hover over this icon to see test case description. 'Select all' checkbox \u2013 use this checkbox to select all items visible in the list. Note that if you filter or search the list, the previously made selection you will be kept nonetheless. In such case, the number of selected test cases visible in the Run selected button will be their total count, which may not correspond to the number of selections in your filtered list view. Status \u2013 use this field to filter your list view by test case execution status. Type - use this field to filter your list view by test case type ( Automated or Semi-manual ). Search \u2013 use this field to search among the listed test cases by their name. Start typing to get matching results. Show report - use this button to view a summary of tests commissioned for your devices along with test case success rate. To get the report in the CSV format, select the Download summary file button. 'Run selected (_)' button \u2013 use it to start the execution of previously selected tests. The number of tests to be run is shown in brackets. Displaying test case description # Read this section to learn how to display details of test cases. In Device Inventory , find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Select a test case and click on its name to enter the detailed view. Starting test cases # Read this section to learn how to start the execution of test cases on a device. In Device Inventory , find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Select the test cases you want to run and click Run selected (_) . Note Even if you leave the Protocol tests panel, tests once run will continue until all are finished or stopped. Stopping test cases # Read this section to learn how to stop the execution of test cases on a device. With the tests running, go to Device Inventory . Find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Click the Cancel all tests button located inside the footer bar. Test execution will be stopped. Note Tests completed before you hit the Cancel all tests button will display their execution status. Test case statuses and logs # Test case statuses # Test case statuses are labels attached to test cases that help to identify their state in each stage of their execution. There are eight available test case statuses: New \u2013 a test case that has been recently added and has not been scheduled nor executed. NotScheduled \u2013 a test case that has never been picked for execution. NotTested \u2013 a test case that has been picked for execution, but its execution has not started due to some error or test case execution interruption. Pending \u2013 a test case whose execution is pending. In progress \u2013 a test case whose execution is under way. Halted \u2013 a test case whose execution is under way. Warning \u2013 a test case that has finished with error(s). Success \u2013 a test case that has finished with success. Tip Statuses are available both for test cases after execution as well as for individual actions inside a test case. To view test results for individual actions, enter the finished test case and see the action list. Test case logs # Logs store detailed information on the test case execution and can be displayed after its completion. To display the logs for an individual test case, enter the test case and click Check logs or expand the Logs list. If there are many logs from a selected period of time, use Scroll to the bottom and Scroll to the top links to navigate. If a log entry is long, not all lines are displayed at once. To see more lines, click the Show \u2026 lines/characters more link. To display only particular logs and logs of a higher level, use Show from level list . To wrap words of logs, select the Word wrap checkbox. To format messages in a more readable way, select the Format messages checkbox. To see which messages were received (green color) and which were sent (blue color), select the Color messages checkbox. To download logs from a particular period of time matching with used filters, click the Download button.","title":"Running test cases"},{"location":"Interoperability_tests_guide/Running_test_cases.html#running-test-cases","text":"If you have test cases configured in the platform, you can run them on your device using the Protocol tests panel. Read this chapter to learn how to display test case descriptions, start and stop test case execution and view test results and logs.","title":"Running test cases"},{"location":"Interoperability_tests_guide/Running_test_cases.html#protocol-tests-panel-description","text":"The protocol tests panel is available in the Device Management Center individually for each device. To access it, select a device in Device Inventory to enter its Device Management Center and select Protocol tests from the menu on the left. Tip If the Protocol tests tab is not visible in the menu, use the settings button under the menu to add it: drag it from Available tabs and drop it in Selected tabs and click Confirm . Read this section to learn about the main components that it comprises. Test case list \u2013 views all the test cases available for a given device. It is searchable and can be filtered. Info icon \u2013 hover over this icon to see test case description. 'Select all' checkbox \u2013 use this checkbox to select all items visible in the list. Note that if you filter or search the list, the previously made selection you will be kept nonetheless. In such case, the number of selected test cases visible in the Run selected button will be their total count, which may not correspond to the number of selections in your filtered list view. Status \u2013 use this field to filter your list view by test case execution status. Type - use this field to filter your list view by test case type ( Automated or Semi-manual ). Search \u2013 use this field to search among the listed test cases by their name. Start typing to get matching results. Show report - use this button to view a summary of tests commissioned for your devices along with test case success rate. To get the report in the CSV format, select the Download summary file button. 'Run selected (_)' button \u2013 use it to start the execution of previously selected tests. The number of tests to be run is shown in brackets.","title":"Protocol tests panel description"},{"location":"Interoperability_tests_guide/Running_test_cases.html#displaying-test-case-description","text":"Read this section to learn how to display details of test cases. In Device Inventory , find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Select a test case and click on its name to enter the detailed view.","title":"Displaying test case description"},{"location":"Interoperability_tests_guide/Running_test_cases.html#starting-test-cases","text":"Read this section to learn how to start the execution of test cases on a device. In Device Inventory , find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Select the test cases you want to run and click Run selected (_) . Note Even if you leave the Protocol tests panel, tests once run will continue until all are finished or stopped.","title":"Starting test cases"},{"location":"Interoperability_tests_guide/Running_test_cases.html#stopping-test-cases","text":"Read this section to learn how to stop the execution of test cases on a device. With the tests running, go to Device Inventory . Find your device in the list and click on its name. In Device Management Center , select the Protocol tests tab. Click the Cancel all tests button located inside the footer bar. Test execution will be stopped. Note Tests completed before you hit the Cancel all tests button will display their execution status.","title":"Stopping test cases"},{"location":"Interoperability_tests_guide/Running_test_cases.html#test-case-statuses-and-logs","text":"","title":"Test case statuses and logs"},{"location":"Interoperability_tests_guide/Running_test_cases.html#test-case-statuses","text":"Test case statuses are labels attached to test cases that help to identify their state in each stage of their execution. There are eight available test case statuses: New \u2013 a test case that has been recently added and has not been scheduled nor executed. NotScheduled \u2013 a test case that has never been picked for execution. NotTested \u2013 a test case that has been picked for execution, but its execution has not started due to some error or test case execution interruption. Pending \u2013 a test case whose execution is pending. In progress \u2013 a test case whose execution is under way. Halted \u2013 a test case whose execution is under way. Warning \u2013 a test case that has finished with error(s). Success \u2013 a test case that has finished with success. Tip Statuses are available both for test cases after execution as well as for individual actions inside a test case. To view test results for individual actions, enter the finished test case and see the action list.","title":"Test case statuses"},{"location":"Interoperability_tests_guide/Running_test_cases.html#test-case-logs","text":"Logs store detailed information on the test case execution and can be displayed after its completion. To display the logs for an individual test case, enter the test case and click Check logs or expand the Logs list. If there are many logs from a selected period of time, use Scroll to the bottom and Scroll to the top links to navigate. If a log entry is long, not all lines are displayed at once. To see more lines, click the Show \u2026 lines/characters more link. To display only particular logs and logs of a higher level, use Show from level list . To wrap words of logs, select the Word wrap checkbox. To format messages in a more readable way, select the Format messages checkbox. To see which messages were received (green color) and which were sent (blue color), select the Color messages checkbox. To download logs from a particular period of time matching with used filters, click the Download button.","title":"Test case logs"},{"location":"Interoperability_tests_guide/Test_case_actions.html","text":"Test case actions # Introduction # Based on the LwM2M 1.0 standard protocol operations, Actions are steps that can be defined within a test case. While some are used for the communication between the Server and the LwM2M test device, others help to define the test case logic. Read this chapter to learn how to use Actions in the configuration of customizable interoperability test cases. Action attributes # All the available Actions are defined using a set of configurable attributes that you can specify while adding or editing a test case. The attributes available under each action are determined by the type of given Action. However, to set up a test case, not all attributes are mandatory. The general rule is that if you leave an optional attribute\u2019s field blank, the final test case result won\u2019t be affected in any way. Tip if you would like to make the test device ignore a particular attribute so that it doesn\u2019t answer to the server request, type None in the optional attribute\u2019s field. Description of Actions # Within the Server simulator test cases, the following Actions are available (with mandatory attributes written in bold): READ WRITE EXECUTE DISCOVER DELETE CREATE WRITE ATTRIBUTES CLEAR ATTRIBUTES OBSERVE CANCEL OBSERVE Firmware Update Wait Pause response Wait for uplink request Send paused response Start Notification recording Expect Notification Loop start READ # READ is used to access the value of an object, object instances, a resource and single resource instances. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter you want to read. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected value \u2013 if the value you enter here equals the value read from the device, the test will be passed. If left blank, the value will only show up in the test case log and it will have no impact on the test case result. Note that this READ attribute works only for Resources and Resource Instances. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. LwM2M: Requested content format \u2013 the content format of the device answer that you request for your read operation. If the device doesn\u2019t support the requested format, the test will fail. If left blank, the device can decide what content format to use; any format will be accepted. WRITE # WRITE is used to change the value of a Resource. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter for which you want to set a new value or overwrite the existing one. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Value \u2013 the value you enter here sets a new value or overwrites the existing one. If left blank, the existing value will be kept and the test will be passed. LwM2M: Content format \u2013 the content format in which you send the write request to the device. If the device doesn\u2019t support the specified format, the test will fail. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. EXECUTE # EXECUTE is used to initiate some action and can only be performed on individual Resources. If the device receives an EXECUTE for an Object Instance(s) or Resource Instance(s), it will return an error. You can define it using two attributes: Parameter name \u2013 the name of the data model parameter for which you will issue an execute. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Execute arguments \u2013 the execution arguments passed to the device expressed in Plain Text format. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. DISCOVER # DISCOVER is used to discover LwM2M Attributes attached to an Object, Object Instances, and Resources. You can define it using two attributes: Parameter name \u2013 the name of the data model parameter whose attributes you want to discover. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. DELETE # DELETE is used for the server to delete an Object Instance within the LwM2M Client. Note that an Object Instance to be deleted must be an Object Instance that is announced by the Client to the Server using the Register and Update operations of the Client Registration Interface. Object instance \u2013 the object instance that you want to delete. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0) or the numerical (e.g. 3.0) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. CREATE # CREATE is used by the Server simulator to create Object Instance(s) within the LwM2M Client. You can define the action using three parameters and a set of Object Instance-dependent values: Object ID or name \u2013 the Object that you want to create an Instance for. Note that it can be specified either using the full name in the string (e.g. \u2018Portfolio\u2019) or the numerical (e.g. \u201816\u2019) value of the parameter. LwM2M: Instance number \u2013 the number assigned to the Object Instance to be created. If left blank, the number will be chosen by the device. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Resources \u2013 click the Provide initial values button to view and specify the possible Resources and Resource Instances of the Object Instance to be created. Note that if the values marked as required are left blank, the action will fail for devices that correctly implement LwM2M. WRITE ATTRIBUTES # WRITE ATTRIBUTES is used to attach metadata containing parameters for Notifications to an Object, an Object Instance or a Resource. You can define it using seven attributes: Parameter name \u2013 the name of the data model parameter for which you will write attributes. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Minimum period \u2013 the minimum time in seconds that the device waits between two notifications. Maximum period \u2013 the minimum time in seconds that the device waits between two notifications. Value greater than \u2013 notifications will be sent only when the monitored value crosses the threshold you set here. However, please note that the interpretation of this parameter may differ depending on the specific LwM2M Client implementation. Value less than \u2013 notifications will be sent only when the monitored value crosses the threshold you set here. However, please note that the interpretation of this parameter may differ depending on the specific LwM2M Client implementation. Step \u2013 the minimum change value between two notifications. CLEAR ATTRIBUTES # CLEAR ATTRIBUTES is used to clear the metadata attached to an Object, an Object Instance or a Resource which contain parameters for Notifications. You can define it using seven attributes: Parameter name \u2013 the name of the data model parameter for which you will clear attributes. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Clear minimum period \u2013 if set to true, it clears the minimum time in seconds between two notifications. If set to false, the value is kept. Clear maximum period \u2013 if set to true, it clears the maximum time set between two notifications. If set to false, the value is kept. Clear value greater than \u2013 if set to true, it clears the threshold set for the monitored value. If set to false, the value is kept. Clear value less than \u2013 if set to true, it clears the threshold set for the monitored value. If set to false, the value is kept. Clear step \u2013 if set to true, it clears the minimum change value between two notifications. If set to false, the value is kept. OBSERVE # OBSERVE is used to initiate an observation request for changes of a specific Resource, Resources within an Object Instance or for all the Object Instances of an Object. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter whose value(s) you will observe. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Fail if already observed \u2013 if set to true, the test will fail in case there is an existing observation set on this parameter. In case there is no observation set, your observe request should be accepted and the test won\u2019t fail. If set to false, any existing observations will be cancelled and requested again by this one and the test will be passed. LwM2M: Content format \u2013 the content format in which you send the OBSERVE request to the device. If the device doesn\u2019t support the specified format, the test will fail. CANCEL OBSERVE # CANCEL OBSERVE is used to cancel an observation. You can define it using three attributes: Parameter name \u2013 the name of the data model parameter for which you will cancel an existing observation. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Cancel type \u2013 the mode in which the CANCEL OBSERVE will be sent to the device. o ACTIVE - CANCEL OBSERVE is sent to the device immediately. o PASSIVE - CoAP RESET is sent in response to the next notification message received from the device. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Firmware Update # Firmware Update is used to perform a firmware update operation on the test device. You can define it using five attributes: Firmware \u2013 the ID of the resource used as the firmware source. Update timeout \u2013 the time period in seconds within which the firmware update should be completed. In case the timeout is up and the update process has not finished, the action will fail. Delivery method \u2013 The protocol and transfer method used to deliver the firmware file to the device. Use notifications \u2013 if set to true, an OBSERVE will be issued automatically for the \u2018State\u2019 and \u2018Update result\u2019 parameters while upgrading the device. The notifications returned by the device will be visible in the test case logs. Expected update result \u2013 if the update result you enter here equals the result returned by the device, the test will be passed. If left blank, the server will expect the default result defined by the LwM2M standard. You can choose among the ten update results defined as per the LwM2M protocol specification. WAIT # Wait is used to set the waiting time before executing the next action. You can define it using two attributes: Waiting time \u2013 the interval set before the next action is executed. In progress message \u2013 a custom text that will be displayed as the test case progress message while waiting for the execution of the next action. Pause response # Pause response is used to delay a response to be sent to the device. If set, the server will wait before sending the response until the Send paused response action is executed. Request type \u2013 the kind of request for which you want to pause the response. Wait for uplink request # Wait for uplink request is used to prevent the server from executing any tasks or actions until an uplink request arrives from the device. You can define the action using three attributes: Request type to wait for \u2013 the kind of request you want to wait for. Timeout \u2013 the time period in seconds within which the uplink request should arrive. In case the timeout is up with no request, the action will fail. Waiting message \u2013 the message displayed during the test case execution while waiting for the arrival of the uplink request. Send paused response # Send paused response is used to send the previously paused response to the device. Request type \u2013 the kind of request for which you want to send the previously paused response. Start Notification recording # Start Notification recording is used to make the Server simulator save all notifications received from the device in its memory. The limit of recorded notifications can be configured using the ddscNotificationRecordingLimit setting value. Once the limit is reached, new notifications are not recorded. Execute the Start Notification recording action again in the same test to clear the recording state and to be able to match more notifications than the recording limit. Expect Notification # Expect Notification is used to check if recorded Notifications match the required criteria. You can define it using five attributes: Expected path \u2013 only notifications that were received on this path will be validated. In case of a notification with multiple paths and values, each path and value are treated as separate notifications. Expected value \u2013 use it to check if there is any notification that has a given value and matches all other criteria. Expected arrival order \u2013 use it to limit the validation only to one notification on a given path that arrived in a given order since the last Start Notification recording action. Note that the counting starts from 0 and that the Observe response is also counted if it is executed after the recording action started. Timeout \u2013 if the expected notification does not arrive within this time limit, the action will fail. Waiting message \u2013 a custom text that will be displayed as the test case progress message while waiting for the action execution. Loop start # Loop start is used to repeat an action or a set of actions within a test case. Note that when configuring the first action inside the loop, the Loop end action is added automatically. Repetitions \u2013 the number of iterations of action(s) inside the loop.","title":"Test case actions"},{"location":"Interoperability_tests_guide/Test_case_actions.html#test-case-actions","text":"","title":"Test case actions"},{"location":"Interoperability_tests_guide/Test_case_actions.html#introduction","text":"Based on the LwM2M 1.0 standard protocol operations, Actions are steps that can be defined within a test case. While some are used for the communication between the Server and the LwM2M test device, others help to define the test case logic. Read this chapter to learn how to use Actions in the configuration of customizable interoperability test cases.","title":"Introduction"},{"location":"Interoperability_tests_guide/Test_case_actions.html#action-attributes","text":"All the available Actions are defined using a set of configurable attributes that you can specify while adding or editing a test case. The attributes available under each action are determined by the type of given Action. However, to set up a test case, not all attributes are mandatory. The general rule is that if you leave an optional attribute\u2019s field blank, the final test case result won\u2019t be affected in any way. Tip if you would like to make the test device ignore a particular attribute so that it doesn\u2019t answer to the server request, type None in the optional attribute\u2019s field.","title":"Action attributes"},{"location":"Interoperability_tests_guide/Test_case_actions.html#description-of-actions","text":"Within the Server simulator test cases, the following Actions are available (with mandatory attributes written in bold): READ WRITE EXECUTE DISCOVER DELETE CREATE WRITE ATTRIBUTES CLEAR ATTRIBUTES OBSERVE CANCEL OBSERVE Firmware Update Wait Pause response Wait for uplink request Send paused response Start Notification recording Expect Notification Loop start","title":"Description of Actions"},{"location":"Interoperability_tests_guide/Test_case_actions.html#read","text":"READ is used to access the value of an object, object instances, a resource and single resource instances. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter you want to read. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected value \u2013 if the value you enter here equals the value read from the device, the test will be passed. If left blank, the value will only show up in the test case log and it will have no impact on the test case result. Note that this READ attribute works only for Resources and Resource Instances. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. LwM2M: Requested content format \u2013 the content format of the device answer that you request for your read operation. If the device doesn\u2019t support the requested format, the test will fail. If left blank, the device can decide what content format to use; any format will be accepted.","title":"READ"},{"location":"Interoperability_tests_guide/Test_case_actions.html#write","text":"WRITE is used to change the value of a Resource. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter for which you want to set a new value or overwrite the existing one. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Value \u2013 the value you enter here sets a new value or overwrites the existing one. If left blank, the existing value will be kept and the test will be passed. LwM2M: Content format \u2013 the content format in which you send the write request to the device. If the device doesn\u2019t support the specified format, the test will fail. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard.","title":"WRITE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#execute","text":"EXECUTE is used to initiate some action and can only be performed on individual Resources. If the device receives an EXECUTE for an Object Instance(s) or Resource Instance(s), it will return an error. You can define it using two attributes: Parameter name \u2013 the name of the data model parameter for which you will issue an execute. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Execute arguments \u2013 the execution arguments passed to the device expressed in Plain Text format. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard.","title":"EXECUTE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#discover","text":"DISCOVER is used to discover LwM2M Attributes attached to an Object, Object Instances, and Resources. You can define it using two attributes: Parameter name \u2013 the name of the data model parameter whose attributes you want to discover. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard.","title":"DISCOVER"},{"location":"Interoperability_tests_guide/Test_case_actions.html#delete","text":"DELETE is used for the server to delete an Object Instance within the LwM2M Client. Note that an Object Instance to be deleted must be an Object Instance that is announced by the Client to the Server using the Register and Update operations of the Client Registration Interface. Object instance \u2013 the object instance that you want to delete. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0) or the numerical (e.g. 3.0) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard.","title":"DELETE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#create","text":"CREATE is used by the Server simulator to create Object Instance(s) within the LwM2M Client. You can define the action using three parameters and a set of Object Instance-dependent values: Object ID or name \u2013 the Object that you want to create an Instance for. Note that it can be specified either using the full name in the string (e.g. \u2018Portfolio\u2019) or the numerical (e.g. \u201816\u2019) value of the parameter. LwM2M: Instance number \u2013 the number assigned to the Object Instance to be created. If left blank, the number will be chosen by the device. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Resources \u2013 click the Provide initial values button to view and specify the possible Resources and Resource Instances of the Object Instance to be created. Note that if the values marked as required are left blank, the action will fail for devices that correctly implement LwM2M.","title":"CREATE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#write-attributes","text":"WRITE ATTRIBUTES is used to attach metadata containing parameters for Notifications to an Object, an Object Instance or a Resource. You can define it using seven attributes: Parameter name \u2013 the name of the data model parameter for which you will write attributes. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Minimum period \u2013 the minimum time in seconds that the device waits between two notifications. Maximum period \u2013 the minimum time in seconds that the device waits between two notifications. Value greater than \u2013 notifications will be sent only when the monitored value crosses the threshold you set here. However, please note that the interpretation of this parameter may differ depending on the specific LwM2M Client implementation. Value less than \u2013 notifications will be sent only when the monitored value crosses the threshold you set here. However, please note that the interpretation of this parameter may differ depending on the specific LwM2M Client implementation. Step \u2013 the minimum change value between two notifications.","title":"WRITE ATTRIBUTES"},{"location":"Interoperability_tests_guide/Test_case_actions.html#clear-attributes","text":"CLEAR ATTRIBUTES is used to clear the metadata attached to an Object, an Object Instance or a Resource which contain parameters for Notifications. You can define it using seven attributes: Parameter name \u2013 the name of the data model parameter for which you will clear attributes. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Clear minimum period \u2013 if set to true, it clears the minimum time in seconds between two notifications. If set to false, the value is kept. Clear maximum period \u2013 if set to true, it clears the maximum time set between two notifications. If set to false, the value is kept. Clear value greater than \u2013 if set to true, it clears the threshold set for the monitored value. If set to false, the value is kept. Clear value less than \u2013 if set to true, it clears the threshold set for the monitored value. If set to false, the value is kept. Clear step \u2013 if set to true, it clears the minimum change value between two notifications. If set to false, the value is kept.","title":"CLEAR ATTRIBUTES"},{"location":"Interoperability_tests_guide/Test_case_actions.html#observe","text":"OBSERVE is used to initiate an observation request for changes of a specific Resource, Resources within an Object Instance or for all the Object Instances of an Object. You can define it using four attributes: Parameter name \u2013 the name of the data model parameter whose value(s) you will observe. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard. Fail if already observed \u2013 if set to true, the test will fail in case there is an existing observation set on this parameter. In case there is no observation set, your observe request should be accepted and the test won\u2019t fail. If set to false, any existing observations will be cancelled and requested again by this one and the test will be passed. LwM2M: Content format \u2013 the content format in which you send the OBSERVE request to the device. If the device doesn\u2019t support the specified format, the test will fail.","title":"OBSERVE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#cancel-observe","text":"CANCEL OBSERVE is used to cancel an observation. You can define it using three attributes: Parameter name \u2013 the name of the data model parameter for which you will cancel an existing observation. Note that it can be specified either using the full name in the string (e.g. \u2018Device.0.Manufacturer) or the numerical (e.g. 3.0.1) value of the parameter. Cancel type \u2013 the mode in which the CANCEL OBSERVE will be sent to the device. o ACTIVE - CANCEL OBSERVE is sent to the device immediately. o PASSIVE - CoAP RESET is sent in response to the next notification message received from the device. Expected response code \u2013 if the response code you enter here equals the response code returned by the device, the test will be passed. If left blank, the server will expect the default response code defined by the LwM2M standard.","title":"CANCEL OBSERVE"},{"location":"Interoperability_tests_guide/Test_case_actions.html#firmware-update","text":"Firmware Update is used to perform a firmware update operation on the test device. You can define it using five attributes: Firmware \u2013 the ID of the resource used as the firmware source. Update timeout \u2013 the time period in seconds within which the firmware update should be completed. In case the timeout is up and the update process has not finished, the action will fail. Delivery method \u2013 The protocol and transfer method used to deliver the firmware file to the device. Use notifications \u2013 if set to true, an OBSERVE will be issued automatically for the \u2018State\u2019 and \u2018Update result\u2019 parameters while upgrading the device. The notifications returned by the device will be visible in the test case logs. Expected update result \u2013 if the update result you enter here equals the result returned by the device, the test will be passed. If left blank, the server will expect the default result defined by the LwM2M standard. You can choose among the ten update results defined as per the LwM2M protocol specification.","title":"Firmware Update"},{"location":"Interoperability_tests_guide/Test_case_actions.html#wait","text":"Wait is used to set the waiting time before executing the next action. You can define it using two attributes: Waiting time \u2013 the interval set before the next action is executed. In progress message \u2013 a custom text that will be displayed as the test case progress message while waiting for the execution of the next action.","title":"WAIT"},{"location":"Interoperability_tests_guide/Test_case_actions.html#pause-response","text":"Pause response is used to delay a response to be sent to the device. If set, the server will wait before sending the response until the Send paused response action is executed. Request type \u2013 the kind of request for which you want to pause the response.","title":"Pause response"},{"location":"Interoperability_tests_guide/Test_case_actions.html#wait-for-uplink-request","text":"Wait for uplink request is used to prevent the server from executing any tasks or actions until an uplink request arrives from the device. You can define the action using three attributes: Request type to wait for \u2013 the kind of request you want to wait for. Timeout \u2013 the time period in seconds within which the uplink request should arrive. In case the timeout is up with no request, the action will fail. Waiting message \u2013 the message displayed during the test case execution while waiting for the arrival of the uplink request.","title":"Wait for uplink request"},{"location":"Interoperability_tests_guide/Test_case_actions.html#send-paused-response","text":"Send paused response is used to send the previously paused response to the device. Request type \u2013 the kind of request for which you want to send the previously paused response.","title":"Send paused response"},{"location":"Interoperability_tests_guide/Test_case_actions.html#start-notification-recording","text":"Start Notification recording is used to make the Server simulator save all notifications received from the device in its memory. The limit of recorded notifications can be configured using the ddscNotificationRecordingLimit setting value. Once the limit is reached, new notifications are not recorded. Execute the Start Notification recording action again in the same test to clear the recording state and to be able to match more notifications than the recording limit.","title":"Start Notification recording"},{"location":"Interoperability_tests_guide/Test_case_actions.html#expect-notification","text":"Expect Notification is used to check if recorded Notifications match the required criteria. You can define it using five attributes: Expected path \u2013 only notifications that were received on this path will be validated. In case of a notification with multiple paths and values, each path and value are treated as separate notifications. Expected value \u2013 use it to check if there is any notification that has a given value and matches all other criteria. Expected arrival order \u2013 use it to limit the validation only to one notification on a given path that arrived in a given order since the last Start Notification recording action. Note that the counting starts from 0 and that the Observe response is also counted if it is executed after the recording action started. Timeout \u2013 if the expected notification does not arrive within this time limit, the action will fail. Waiting message \u2013 a custom text that will be displayed as the test case progress message while waiting for the action execution.","title":"Expect Notification"},{"location":"Interoperability_tests_guide/Test_case_actions.html#loop-start","text":"Loop start is used to repeat an action or a set of actions within a test case. Note that when configuring the first action inside the loop, the Loop end action is added automatically. Repetitions \u2013 the number of iterations of action(s) inside the loop.","title":"Loop start"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html","text":"Jenkins/GitLab integration with interop tests API # If you would like to automate your interoperability tests, you can use the Coiote DM API and integrate it with a CI/CD environment like Jenkins or GitLab. Follow the guide below to learn how to configure the integration, run tests and summarize your test execution using these tools. Note The following instruction is based on integration with Jenkins. To integrate with GitLab, you can follow the same steps, but with slight adjustments - for details, please see subsection on GitLab . Prerequisites # An active Jenkins and GitLab account. A Git project repository. A working Coiote DM installation and a port for communication with the installation API. A device registered in the platform (if the tests require the device to be registered). A Coiote DM user with access to the device and the appropriate API permissions. Jenkins - standard pipeline # Set up standard pipeline # Upload a file with python script used to run test cases to your project repository: Edit the following python script where required to adjust it to your environment (remember to select the appropriate tab with script depending on whether you want to run your tests on a single device or a device group). Device #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_NAME = \"test-device\" # type the endpoint name of your device. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the device. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/device/\" + DEVICE_NAME REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/device/\" + DEVICE_NAME PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = result . json ()[ \"waitingForExecution\" ] time . sleep ( 15 ) for test in result . json ()[ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Group #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_GROUP = \"root.mt.embedded.devicetypes.test.demo_client.2_9_0\" # type the name of your device group. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the group. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/group/\" + DEVICE_GROUP REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/group/\" + DEVICE_GROUP PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : still_running = 0 result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) exit ( 1 ) for device in result . json (): if not ( result . json ()[ device ][ \"waitingForExecution\" ] == []): still_running += 1 if ( still_running == 0 ): tests_running = False time . sleep ( 15 ) for device in result . json (): for test in result . json ()[ device ][ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ device ][ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ device ][ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Save the script as a .py file and upload it to your project repository. Create a pipeline for your project: Go to your Jenkins account and in the Dashboard view, select New Item from the menu on the left. Enter a name for your pipeline, select Pipeline , and confirm by clicking OK . Configure your pipeline: Go to your newly created pipeline and select Configure from the menu on the left. In the Source Code Management section, select the Git option and provide the following: Repository URL - enter the URL address of your GitLab repository that hosts the python script file from Step 1 . Credentials - add the user name and password of your git repository account. Branch Specifier - choose the GitLab branch you want to use in the pipeline. In the Build section, select the Execute Shell option from the drop-down list and provide the command to run the python script file from Step 1 : python3 example_filename.py Additionally, in the Post-build Actions section, select the Publish Junit test result report to set up test result report generation: Depending on your preferences, check or uncheck the Allow empty results option. Click Save . Run standard pipeline # Enter pipeline and select Build Now . Note Remember to check if the device you run the tests for is connected and registered in Coiote DM. Once the tests are performed, you will see your build status along with a graph reporting the execution status for each test case. Jenkins multibranch pipeline # Set up multibranch pipeline # Alternatively to the standard pipeline, you may configure a multibranch pipeline to run your test cases. Upload the Jenkinsfile that will define your multibranch pipeline to your project repository: Edit the script where required to adjust it to your environment: Note Remember to change the name example_filename.py to your custom name that you will choose in Step 2 . pipeline { options { disableConcurrentBuilds () } agent any stages { stage ( 'protocol_tests' ) { steps { sh 'python3 example_filename.py' } } } post { always { junit \"report.xml\" archiveArtifacts artifacts : 'report.xml' } cleanup { script { clean () } } } } Save the file as Jenkinsfile and upload it to the chosen branch of your project repository. Upload a file with python script used to run test cases to your project repository: Edit the following python script where required to adjust it to your environment (remember to select the appropriate tab with script depending on whether you want to run your tests on a single device or a device group). Device #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_NAME = \"test-device\" # type the endpoint name of your device. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the device. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/device/\" + DEVICE_NAME REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/device/\" + DEVICE_NAME PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = result . json ()[ \"waitingForExecution\" ] time . sleep ( 15 ) for test in result . json ()[ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Group #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_GROUP = \"root.mt.embedded.devicetypes.test.demo_client.2_9_0\" # type the name of your device group. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the group. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/group/\" + DEVICE_GROUP REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/group/\" + DEVICE_GROUP PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : still_running = 0 result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) exit ( 1 ) for device in result . json (): if not ( result . json ()[ device ][ \"waitingForExecution\" ] == []): still_running += 1 if ( still_running == 0 ): tests_running = False time . sleep ( 15 ) for device in result . json (): for test in result . json ()[ device ][ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ device ][ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ device ][ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Save the script as a .py file (using the filename specified in the Jenkinsfile in the previous step) and upload it to your project repository. Create a pipeline for your project: Go to your Jenkins account and in the Dashboard view, select New Item from the menu on the left. Enter a name for your pipeline, select Multibranch Pipeline and confirm by clicking OK . Configure your pipeline: Go to your newly created pipeline and select Configure from the menu on the left. In the Branch Sources section, select the Git option and provide the following: Project Repository - enter the URL address of your project repository that hosts the Jenkinsfile and the python script file from Step 2 . Credentials - add the user name and password of your GitLab account. In the Build Configuration section, select the by Jenkinsfile mode from the drop-down list and provide the GitLab path to the Jenkinsfile from Step 1 (if the file is located in the GitLab root folder, it is enough to type Jenkinsfile ) Click Save . Run multibranch pipeline # Before running the tests for a chosen branch, you have to perform a scan to detect available branches (those with a Jenkinsfile ): Go to your multibranch pipeline and select Scan Multibranch Pipeline Now option from the menu on the left. Once the scan is completed, you will see a list of available branches. Enter a chosen branch by clicking on its name and select Build Now . Note Remember to check if the device you run the tests for is connected and registered in Coiote DM. Once the tests are performed, you will see your build status along with a graph reporting the execution status for each test case. GitLab - configure and run pipeline # Coiote DM interop tests API can also be integrated with GitLab using the GitLab's CI/CD toolset. Here is how to do it: Upload the gitlab-ci.yml file that will define your GitLab pipeline to your project repository: Edit the script where required to adjust it to your environment: Note Remember to change the name example_filename.py to your custom name that you will choose in the next step. Also, keep in mind that running a pipeline in GitLab requires a docker image of a Linux distribution (or any operating system that can run python script). image : name : example.repository.com/docker-local/linux_image protocol-tests : stage : test script : - python3 example_filename.py artifacts : when : always paths : - report.xml reports : junit : report.xml Save the file as gitlab-ci.yml and upload it to the chosen branch of your project repository. Follow Step 2 from Creating a Jenkins multibranch pipeline (uploading a file with python script to your GitLab repository). Run a created pipeline for your project: Go to your GitLab project and in the Dashboard view, select CI/CD from the menu on the left and click Pipelines . Attention Note that to be able to run a pipeline, you will need to have the GitLab CI/CD toolset configured. For details, please check https://docs.gitlab.com/ee/ci/introduction/index.html . You should be able to see the branch with the uploaded gitlab-ci.yml file. Select the Run pipeline button, then confirm again by clicking Run pipeline . Once the pipeline execution is finished, you should be able to see the results in the Tests tab of your pipeline. Note Viewing graphs with test results is not supported in GitLab by default as it requires additional plugins.","title":"Jenkins/GitLab integration with interop tests API"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#jenkinsgitlab-integration-with-interop-tests-api","text":"If you would like to automate your interoperability tests, you can use the Coiote DM API and integrate it with a CI/CD environment like Jenkins or GitLab. Follow the guide below to learn how to configure the integration, run tests and summarize your test execution using these tools. Note The following instruction is based on integration with Jenkins. To integrate with GitLab, you can follow the same steps, but with slight adjustments - for details, please see subsection on GitLab .","title":"Jenkins/GitLab integration with interop tests API"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#prerequisites","text":"An active Jenkins and GitLab account. A Git project repository. A working Coiote DM installation and a port for communication with the installation API. A device registered in the platform (if the tests require the device to be registered). A Coiote DM user with access to the device and the appropriate API permissions.","title":"Prerequisites"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#jenkins-standard-pipeline","text":"","title":"Jenkins - standard pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#set-up-standard-pipeline","text":"Upload a file with python script used to run test cases to your project repository: Edit the following python script where required to adjust it to your environment (remember to select the appropriate tab with script depending on whether you want to run your tests on a single device or a device group). Device #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_NAME = \"test-device\" # type the endpoint name of your device. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the device. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/device/\" + DEVICE_NAME REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/device/\" + DEVICE_NAME PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = result . json ()[ \"waitingForExecution\" ] time . sleep ( 15 ) for test in result . json ()[ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Group #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_GROUP = \"root.mt.embedded.devicetypes.test.demo_client.2_9_0\" # type the name of your device group. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the group. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/group/\" + DEVICE_GROUP REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/group/\" + DEVICE_GROUP PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : still_running = 0 result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) exit ( 1 ) for device in result . json (): if not ( result . json ()[ device ][ \"waitingForExecution\" ] == []): still_running += 1 if ( still_running == 0 ): tests_running = False time . sleep ( 15 ) for device in result . json (): for test in result . json ()[ device ][ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ device ][ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ device ][ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Save the script as a .py file and upload it to your project repository. Create a pipeline for your project: Go to your Jenkins account and in the Dashboard view, select New Item from the menu on the left. Enter a name for your pipeline, select Pipeline , and confirm by clicking OK . Configure your pipeline: Go to your newly created pipeline and select Configure from the menu on the left. In the Source Code Management section, select the Git option and provide the following: Repository URL - enter the URL address of your GitLab repository that hosts the python script file from Step 1 . Credentials - add the user name and password of your git repository account. Branch Specifier - choose the GitLab branch you want to use in the pipeline. In the Build section, select the Execute Shell option from the drop-down list and provide the command to run the python script file from Step 1 : python3 example_filename.py Additionally, in the Post-build Actions section, select the Publish Junit test result report to set up test result report generation: Depending on your preferences, check or uncheck the Allow empty results option. Click Save .","title":"Set up standard pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#run-standard-pipeline","text":"Enter pipeline and select Build Now . Note Remember to check if the device you run the tests for is connected and registered in Coiote DM. Once the tests are performed, you will see your build status along with a graph reporting the execution status for each test case.","title":"Run standard pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#jenkins-multibranch-pipeline","text":"","title":"Jenkins multibranch pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#set-up-multibranch-pipeline","text":"Alternatively to the standard pipeline, you may configure a multibranch pipeline to run your test cases. Upload the Jenkinsfile that will define your multibranch pipeline to your project repository: Edit the script where required to adjust it to your environment: Note Remember to change the name example_filename.py to your custom name that you will choose in Step 2 . pipeline { options { disableConcurrentBuilds () } agent any stages { stage ( 'protocol_tests' ) { steps { sh 'python3 example_filename.py' } } } post { always { junit \"report.xml\" archiveArtifacts artifacts : 'report.xml' } cleanup { script { clean () } } } } Save the file as Jenkinsfile and upload it to the chosen branch of your project repository. Upload a file with python script used to run test cases to your project repository: Edit the following python script where required to adjust it to your environment (remember to select the appropriate tab with script depending on whether you want to run your tests on a single device or a device group). Device #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_NAME = \"test-device\" # type the endpoint name of your device. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the device. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/device/\" + DEVICE_NAME REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/device/\" + DEVICE_NAME PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = result . json ()[ \"waitingForExecution\" ] time . sleep ( 15 ) for test in result . json ()[ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Group #!/usr/bin/python import requests import json import time import xml.etree.cElementTree as ET # ___Edit below___ # DEVICE_GROUP = \"root.mt.embedded.devicetypes.test.demo_client.2_9_0\" # type the name of your device group. INSTALLATION_URL = \"https://lwm2m-test.avsystem.io\" # provide the URL of your Coiote DM installation. INSTALLATION_API_PORT = \"8087\" # provide the port for communication with the API. The default value is `8087`. CREDENTIALS = ( 'user_login' , 'password' ) # provide user name and password of your Coiote DM user account. TEST_NAMES = { # type the names of the test cases that you want to execute on the group. \"testCases\" :[ \"protocol_test_1\" , \"protocol_test_2\" , \"protocol_test_3\" , \"protocol_test_4\" , \"protocol_test_5\" , ] } # ___Edit above___ # SCHEDULE_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/schedule/group/\" + DEVICE_GROUP REPORT_URL = INSTALLATION_URL + \":\" + INSTALLATION_API_PORT + \"/api/coiotedm/v3/protocolTests/report/group/\" + DEVICE_GROUP PARAMS = { 'accept' : 'application/json' , 'Content-Type' : 'application/json' } root = ET . Element ( \"testsuite\" ) result = requests . post ( url = SCHEDULE_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 201 : print ( 'Could not schedule the tests.' ) print ( 'Server returned: ' + str ( result . status_code )) print ( 'Error message: ' + str ( result . json ()[ 'error' ])) exit ( 1 ) tests_running = True while tests_running : still_running = 0 result = requests . post ( url = REPORT_URL , json = TEST_NAMES , auth = CREDENTIALS , params = PARAMS ) if result . status_code != 200 : print ( 'Could not read the tests status.' ) print ( 'Server returned: ' + str ( result . status_code )) exit ( 1 ) for device in result . json (): if not ( result . json ()[ device ][ \"waitingForExecution\" ] == []): still_running += 1 if ( still_running == 0 ): tests_running = False time . sleep ( 15 ) for device in result . json (): for test in result . json ()[ device ][ 'failed' ]: a = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( a , \"failure\" , type = \"failure\" ) for test in result . json ()[ device ][ 'passedWithWarning' ]: b = ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) ET . SubElement ( b , \"failure\" , type = \"warning\" ) for test in result . json ()[ device ][ 'passedSuccessfully' ]: ET . SubElement ( root , \"testcase\" , classname = \"interop\" , name = test , device = device ) tree = ET . ElementTree ( root ) tree . write ( \"report.xml\" ) Save the script as a .py file (using the filename specified in the Jenkinsfile in the previous step) and upload it to your project repository. Create a pipeline for your project: Go to your Jenkins account and in the Dashboard view, select New Item from the menu on the left. Enter a name for your pipeline, select Multibranch Pipeline and confirm by clicking OK . Configure your pipeline: Go to your newly created pipeline and select Configure from the menu on the left. In the Branch Sources section, select the Git option and provide the following: Project Repository - enter the URL address of your project repository that hosts the Jenkinsfile and the python script file from Step 2 . Credentials - add the user name and password of your GitLab account. In the Build Configuration section, select the by Jenkinsfile mode from the drop-down list and provide the GitLab path to the Jenkinsfile from Step 1 (if the file is located in the GitLab root folder, it is enough to type Jenkinsfile ) Click Save .","title":"Set up multibranch pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#run-multibranch-pipeline","text":"Before running the tests for a chosen branch, you have to perform a scan to detect available branches (those with a Jenkinsfile ): Go to your multibranch pipeline and select Scan Multibranch Pipeline Now option from the menu on the left. Once the scan is completed, you will see a list of available branches. Enter a chosen branch by clicking on its name and select Build Now . Note Remember to check if the device you run the tests for is connected and registered in Coiote DM. Once the tests are performed, you will see your build status along with a graph reporting the execution status for each test case.","title":"Run multibranch pipeline"},{"location":"Interoperability_tests_guide/Using_API_Jenkins_integration.html#gitlab-configure-and-run-pipeline","text":"Coiote DM interop tests API can also be integrated with GitLab using the GitLab's CI/CD toolset. Here is how to do it: Upload the gitlab-ci.yml file that will define your GitLab pipeline to your project repository: Edit the script where required to adjust it to your environment: Note Remember to change the name example_filename.py to your custom name that you will choose in the next step. Also, keep in mind that running a pipeline in GitLab requires a docker image of a Linux distribution (or any operating system that can run python script). image : name : example.repository.com/docker-local/linux_image protocol-tests : stage : test script : - python3 example_filename.py artifacts : when : always paths : - report.xml reports : junit : report.xml Save the file as gitlab-ci.yml and upload it to the chosen branch of your project repository. Follow Step 2 from Creating a Jenkins multibranch pipeline (uploading a file with python script to your GitLab repository). Run a created pipeline for your project: Go to your GitLab project and in the Dashboard view, select CI/CD from the menu on the left and click Pipelines . Attention Note that to be able to run a pipeline, you will need to have the GitLab CI/CD toolset configured. For details, please check https://docs.gitlab.com/ee/ci/introduction/index.html . You should be able to see the branch with the uploaded gitlab-ci.yml file. Select the Run pipeline button, then confirm again by clicking Run pipeline . Once the pipeline execution is finished, you should be able to see the results in the Tests tab of your pipeline. Note Viewing graphs with test results is not supported in GitLab by default as it requires additional plugins.","title":"GitLab - configure and run pipeline"},{"location":"User_Guide/Appendices/Third_party_software.html","text":"Third party software # The below table presents all third party libraries with their licenses. Category License Dependency Notes Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) joda-time # joda-time # 2.8.2 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.objenesis # objenesis # 2.1 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.snmp4j # snmp4j # 2.4.1 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.snmp4j # snmp4j-agent # 2.4.1 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0.html) com.typesafe.scala-logging # scala-logging_2.12 # 3.5.0 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.ftpserver # ftplet-api # 1.0.6 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.ftpserver # ftpserver-core # 1.0.6 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.mina # mina-core # 2.0.7 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.sshd # apache-sshd # 0.13.0 Apache Apache License (http://www.apache.org/licenses/LICENSE-2.0.txt) com.chuusai # shapeless_2.12 # 2.3.2 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin.external.google # guava # 16.0.1.vaadin1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin.external.streamhtmlparser # streamhtmlparser-jsilver # 0.0.10.vaadin1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-annotations # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-core # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-models # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-parser # 1.0.31 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) org.xerial.snappy # snappy-java # 1.1.7.1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) org.jgroups # jgroups # 4.0.15.Final Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-client # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-server # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-shared # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-shared-deps # 1.0.3 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe # config # 1.3.4 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe # ssl-config-core_2.12 # 0.2.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-actor_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-agent_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-slf4j_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-stream_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-testkit_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-cli # commons-cli # 1.3.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-codec # commons-codec # 1.10 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-collections # commons-collections # 3.2.2 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-eval_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-execution_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-reactive_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-types_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix_2.12 # 2.3.0 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) io.netty # netty-all # 4.1.27.Final Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) net.sf.supercsv # super-csv # 2.3.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.commons # commons-lang3 # 3.4 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.commons # commons-math3 # 3.6.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.jctools # jctools-core # 2.0.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.yaml # snakeyaml # 1.17 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-client # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-continuation # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-http # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-io # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-jmx # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-proxy # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-rewrite # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-security # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-server # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-servlet # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-servlets # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-util # 9.3.19.v20170502 Apache Apache Software License, Version 1.1 (http://www.apache.org/licenses/LICENSE-1.1) org.bouncycastle # bcpg-jdk15on # 1.51 Apache Apache Software Licenses (http://www.apache.org/licenses/LICENSE-2.0.txt) org.slf4j # log4j-over-slf4j # 1.7.21 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-macros_2.12 # 0.8.0-RC3 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-rest_2.12 # 0.8.0-RC3 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-utils_2.12 # 0.8.0-RC3 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-http-core_2.12 # 10.0.1 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-http_2.12 # 10.0.1 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-parsing_2.12 # 10.0.1 Apache Similar to Apache License but with the acknowledgment clause removed (https://raw.github.com/hunterhacker/jdom/master/LICENSE.txt) org.jdom # jdom2 # 2.0.6 Apache The Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.github.ghik # silencer-lib_2.12 # 1.4.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-annotations # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-core # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-databind # 2.8.7 Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.dataformat # jackson-dataformat-yaml # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.google.code.findbugs # jsr305 # 3.0.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.google.guava # guava # 21.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-io # commons-io # 2.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-lang # commons-lang # 2.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) io.prometheus.jmx # jmx_prometheus_javaagent # 0.12.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) javax.validation # validation-api # 1.1.0.Final Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.kafka # kafka-clients # 1.1.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.logging.log4j # log4j-api # 2.5 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.logging.log4j # log4j-to-slf4j # 2.5 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi-ooxml # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi-ooxml-schemas # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.velocity # velocity # 1.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.xmlbeans # xmlbeans # 2.3.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.codehaus.jackson # jackson-core-asl # 1.9.13 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.codehaus.jackson # jackson-mapper-asl # 1.9.13 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.jgroups.kubernetes # jgroups-kubernetes # 1.0.8.Final Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.lz4 # lz4-java # 1.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # bson # 3.11.2 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-async # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-core # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-legacy # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-reactivestreams # 1.12.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-sync # 3.11.2 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.quartz-scheduler # quartz # 2.2.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-aop # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-beans # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-context # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-context-support # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-core # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-expression # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-oxm # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-test # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-tx # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-web # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-webmvc # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-ws-core # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-ws-test # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-xml # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.typelevel # macro-compat_2.12 # 1.1.1 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) stax # stax-api # 1.0.1 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) tomcat # tomcat-apr # 5.5.23 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) xerces # xercesImpl # 2.9.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) xml-apis # xml-apis # 1.0.b2 BSD BSD (https://github.com/nbronson/scala-stm/blob/master/LICENSE.txt) org.scala-stm # scala-stm_2.12 # 0.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-compiler # 2.12.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-library # 2.12.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-reflect # 2.12.8 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.owasp.encoder # encoder # 1.2.2 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-java8-compat_2.12 # 1.1.1 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-parser-combinators_2.12 # 1.0.5 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-xml_2.12 # 1.0.6 BSD BSD License (http://xmlunit.svn.sourceforge.net/viewvc/ checkout /xmlunit/trunk/xmlunit/LICENSE.txt) xmlunit # xmlunit # 1.5 BSD BSD License (https://opensource.org/licenses/bsd-license.php) com.yahoo.platform.yui # yuicompressor # 2.4.8 BSD BSD style (http://xstream.codehaus.org/license.html) com.thoughtworks.xstream # xstream # 1.4.8 BSD BSD-style (http://www.opensource.org/licenses/bsd-license.php) org.scalacheck # scalacheck_2.12 # 1.13.4 BSD New BSD License (http://www.opensource.org/licenses/bsd-license.php) org.hamcrest # hamcrest-core # 1.3 BSD Revised BSD (http://www.jcraft.com/jsch/LICENSE.txt) com.jcraft # jsch # 0.1.55 BSD The BSD License (http://www.opensource.org/licenses/bsd-license.php) jline # jline # 2.14.6 BSD Two-clause BSD-style license (http://github.com/sbt/junit-interface/blob/master/LICENSE.txt) com.novocode # junit-interface # 0.11 CC0 CC0 (http://creativecommons.org/publicdomain/zero/1.0/) org.reactivestreams # reactive-streams # 1.0.2 CDDL COMMON DEVELOPMENT AND DISTRIBUTION LICENSE (CDDL) Version 1.1 (https://javaee.github.io/javamail/LICENSE) com.sun.mail # javax.mail # 1.4.5 CDDL COMMON DEVELOPMENT AND DISTRIBUTION LICENSE (CDDL) Version 1.1 (https://javaee.github.io/servlet-spec/LICENSE) javax.servlet # javax.servlet-api # 4.0.1 LGPL GNU LESSER GENERAL PUBLIC LICENSE (http://www.gnu.org/licenses/lgpl.txt) c3p0 # c3p0 # 0.9.1.1 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) ch.qos.logback # logback-classic # 1.1.8 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) ch.qos.logback # logback-core # 1.1.8 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) info.faljse # SDNotify # 1.3 MIT MIT (http://www.opensource.org/licenses/mit-license.html) com.lihaoyi # sourcecode_2.12 # 0.1.4 MIT MIT (https://opensource.org/licenses/MIT) org.scalamock # scalamock-core_2.12 # 3.5.0 MIT MIT (https://opensource.org/licenses/MIT) org.scalamock # scalamock-scalatest-support_2.12 # 3.5.0 MIT MIT (http://opensource.org/licenses/MIT) org.spire-math # jawn-parser_2.12 # 0.10.3 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) ch.qos.cal10n # cal10n-api # 0.7.4 MIT MIT License (http://www.slf4j.org/license.html) net.logstash.logback # logstash-logback-encoder # 4.6 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # jcl-over-slf4j # 1.7.21 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # jul-to-slf4j # 1.7.21 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # slf4j-ext # 1.6.3 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # derive_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # fastparse-utils_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # fastparse_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # scalaparse_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # upickle_2.12 # 0.4.4 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-annotations_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-core_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-jetty_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-macros_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-redis_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-shared_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-spring_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-core_2.12 # 1.20.19 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-macros_2.12 # 1.20.19 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-util_2.12 # 1.20.19 MIT The MIT License (http://jsoup.com/license) org.jsoup # jsoup # 1.8.3 MIT The MIT License (http://github.com/mockito/mockito/blob/master/LICENSE) org.mockito # mockito-core # 1.10.19 Mozilla MPL 1.1 (http://www.mozilla.org/MPL/MPL-1.1.html) org.javassist # javassist # 3.19.0-GA Mozilla MPL 1.1 (http://www.mozilla.org/MPL/MPL-1.1.html) rhino # js # 1.7R2 Public Domain Public Domain aopalliance # aopalliance # 1.0 Public Domain Public Domain (http://www.xmlpull.org/v1/download/unpacked/LICENSE.txt) xmlpull # xmlpull # 1.1.3.1 Public Domain Public Domain (http://creativecommons.org/licenses/publicdomain) xpp3 # xpp3_min # 1.1.4c unrecognized Bouncy Castle Licence (http://www.bouncycastle.org/licence.html) org.bouncycastle # bcpkix-jdk15on # 1.51 unrecognized Bouncy Castle Licence (http://www.bouncycastle.org/licence.html) org.bouncycastle # bcprov-jdk15on # 1.51 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # californium-core # 2.0.0-M18 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # californium-legal # 2.0.0-M18 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # scandium # 2.0.0-M18 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # com.ibm.icu # 50.1.1.v201304230130 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.apache.commons.logging # 1.1.1.v201101211721 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.birt.runtime # 4.3.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.contenttype # 3.4.200.v20130326-1255 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.expressions # 3.4.500.v20130515-1343 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.filesystem # 1.4.0.v20130514-1240 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.jobs # 3.5.300.v20130429-1813 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.resources # 3.8.100.v20130521-2026 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.runtime # 3.9.0.v20130326-1255 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity # 1.2.8.v201305301230 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.apache.derby # 1.0.103.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.apache.derby.dbdefinition # 1.0.2.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.console.profile # 1.0.10.v201109250955 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.db.generic # 1.0.1.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.dbdefinition.genericJDBC # 1.0.1.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda # 3.4.0.v201305170924 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.consumer # 3.2.6.v201305170644 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.design # 3.3.6.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.flatfile # 3.1.5.v201305221644 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.profile # 3.2.8.v201209080429 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.sqm.core # 1.2.6.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.hsqldb # 1.0.0.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.hsqldb.dbdefinition # 1.0.0.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.db2.luw # 1.0.2.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.db2.luw.dbdefinition # 1.0.4.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.informix # 1.0.1.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.informix.dbdefinition # 1.0.4.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.msft.sqlserver # 1.0.2.v201212120617 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.msft.sqlserver.dbdefinition # 1.0.1.v201201240505 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.mysql # 1.0.4.v201212120617 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.mysql.dbdefinition # 1.0.4.v201109022331 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oda.ws # 1.2.5.v201305031101 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oda.xml # 1.2.5.v201305031101 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oracle # 1.0.0.v201107221506 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oracle.dbdefinition # 1.0.103.v201206010214 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.postgresql # 1.1.1.v201205252207 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.postgresql.dbdefinition # 1.0.2.v201110070445 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.dbdefinition # 1.0.2.v201107221519 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.derby # 1.0.0.v201107221519 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.sql # 1.0.6.v201208230744 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.sql.query # 1.1.4.v201212120619 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf # 2.6.0.v20130610-0406 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.common # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore.change # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore.xmi # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.app # 1.3.100.v20130327-1442 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.common # 3.6.200.v20130402-1505 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.preferences # 3.5.100.v20130422-1538 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.registry # 3.5.300.v20130327-1442 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.osgi # 3.9.0.v20130529-1710 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.osgi.services # 3.3.100.v20130513-1956 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.update.configurator # 3.3.200.v20130326-1319 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # Tidy # 1 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # com.lowagie.text # 2.1.7 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # derby # 10.5.1000001 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.bridge # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.css # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.dom # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.dom.svg # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.ext.awt # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.parser # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.svggen # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.transcoder # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.util # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.util.gui # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.xml # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xerces # 2.9.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xml.resolver # 1.2.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xml.serializer # 2.7.1 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.mozilla.javascript # 1.7.2 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.css.sac # 1.3.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.dom.smil # 1.0.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.dom.svg # 1.1.0 unrecognized Eclipse Public License - v 1.0 (https://www.eclipse.org/org/documents/epl-v10.php) org.eclipse.paho:org.eclipse.paho.client.mqttv3:1.2.0 unrecognized Eclipse Public License 1.0 (http://www.eclipse.org/legal/epl-v10.html) junit # junit # 4.12 unrecognized The W3C Software License (http://www.w3.org/Consortium/Legal/copyright-software-19980720) org.w3c.css # sac # 1.3 unrecognized The W3C Software License (http://www.w3.org/Consortium/Legal/copyright-software-19980720) com.vaadin.external.flute # flute # 1.3.0.gg2 unrecognized none specified (none specified) commons-net # commons-net # 3.3 unrecognized none specified (none specified) dom4j # dom4j # 1.6.1 unrecognized none specified (none specified) javax.activation # activation # 1.1.1 unrecognized none specified (none specified) milyn # flute # 1.3 unrecognized none specified (none specified) net.java.dev.jna # jna # 5.1.0 unrecognized none specified (none specified) org.apache.commons # commons-compress # 1.13 unrecognized none specified (none specified) org.codehaus.jettison # jettison # 1.3 unrecognized none specified (none specified) org.eclipse.birt.report.engine.emitter # csv # 1.0.0.201110121016 unrecognized none specified (none specified) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.pdf # 1.6.0 unrecognized none specified (none specified) org.slf4j # slf4j-api # 1.7.21 unrecognized none specified (none specified) org.vaadin.addons # aceeditor # 0.8.14 unrecognized none specified (none specified) org.vaadin.addons # ckeditor-wrapper-for-vaadin # 7.10.8 unrecognized none specified (none specified) org.vaadin.addons # legacycombobox # 0.1.4 unrecognized none specified (none specified) org.vaadin.addons # tokenfield # 7.0.1","title":"Third party software"},{"location":"User_Guide/Appendices/Third_party_software.html#third-party-software","text":"The below table presents all third party libraries with their licenses. Category License Dependency Notes Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) joda-time # joda-time # 2.8.2 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.objenesis # objenesis # 2.1 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.snmp4j # snmp4j # 2.4.1 Apache Apache 2 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.snmp4j # snmp4j-agent # 2.4.1 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0.html) com.typesafe.scala-logging # scala-logging_2.12 # 3.5.0 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.ftpserver # ftplet-api # 1.0.6 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.ftpserver # ftpserver-core # 1.0.6 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.mina # mina-core # 2.0.7 Apache Apache 2.0 License (http://www.apache.org/licenses/LICENSE-2.0) org.apache.sshd # apache-sshd # 0.13.0 Apache Apache License (http://www.apache.org/licenses/LICENSE-2.0.txt) com.chuusai # shapeless_2.12 # 2.3.2 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin.external.google # guava # 16.0.1.vaadin1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin.external.streamhtmlparser # streamhtmlparser-jsilver # 0.0.10.vaadin1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-annotations # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-core # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-models # 1.5.15 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) io.swagger # swagger-parser # 1.0.31 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) org.xerial.snappy # snappy-java # 1.1.7.1 Apache Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) org.jgroups # jgroups # 4.0.15.Final Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-client # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-server # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-shared # 7.6.8 Apache Apache License Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.vaadin # vaadin-shared-deps # 1.0.3 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe # config # 1.3.4 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe # ssl-config-core_2.12 # 0.2.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-actor_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-agent_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-slf4j_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-stream_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) com.typesafe.akka # akka-testkit_2.12 # 2.4.16 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-cli # commons-cli # 1.3.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-codec # commons-codec # 1.10 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-collections # commons-collections # 3.2.2 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-eval_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-execution_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-reactive_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix-types_2.12 # 2.3.0 Apache Apache License, Version 2.0 (https://www.apache.org/licenses/LICENSE-2.0) io.monix # monix_2.12 # 2.3.0 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) io.netty # netty-all # 4.1.27.Final Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.html) net.sf.supercsv # super-csv # 2.3.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.commons # commons-lang3 # 3.4 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.commons # commons-math3 # 3.6.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.jctools # jctools-core # 2.0.1 Apache Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.yaml # snakeyaml # 1.17 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-client # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-continuation # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-http # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-io # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-jmx # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-proxy # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-rewrite # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-security # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-server # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-servlet # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-servlets # 9.3.19.v20170502 Apache Apache Software License - Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0) org.eclipse.jetty # jetty-util # 9.3.19.v20170502 Apache Apache Software License, Version 1.1 (http://www.apache.org/licenses/LICENSE-1.1) org.bouncycastle # bcpg-jdk15on # 1.51 Apache Apache Software Licenses (http://www.apache.org/licenses/LICENSE-2.0.txt) org.slf4j # log4j-over-slf4j # 1.7.21 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-macros_2.12 # 0.8.0-RC3 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-rest_2.12 # 0.8.0-RC3 Apache Apache v.2 License (http://www.apache.org/licenses/LICENSE-2.0.txt) io.udash # udash-utils_2.12 # 0.8.0-RC3 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-http-core_2.12 # 10.0.1 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-http_2.12 # 10.0.1 Apache Apache-2.0 (https://opensource.org/licenses/Apache-2.0) com.typesafe.akka # akka-parsing_2.12 # 10.0.1 Apache Similar to Apache License but with the acknowledgment clause removed (https://raw.github.com/hunterhacker/jdom/master/LICENSE.txt) org.jdom # jdom2 # 2.0.6 Apache The Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.github.ghik # silencer-lib_2.12 # 1.4.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-annotations # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-core # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.core # jackson-databind # 2.8.7 Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.fasterxml.jackson.dataformat # jackson-dataformat-yaml # 2.8.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.google.code.findbugs # jsr305 # 3.0.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) com.google.guava # guava # 21.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-io # commons-io # 2.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) commons-lang # commons-lang # 2.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) io.prometheus.jmx # jmx_prometheus_javaagent # 0.12.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) javax.validation # validation-api # 1.1.0.Final Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.kafka # kafka-clients # 1.1.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.logging.log4j # log4j-api # 2.5 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.logging.log4j # log4j-to-slf4j # 2.5 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi-ooxml # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.poi # poi-ooxml-schemas # 3.9 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.velocity # velocity # 1.7 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.apache.xmlbeans # xmlbeans # 2.3.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.codehaus.jackson # jackson-core-asl # 1.9.13 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.codehaus.jackson # jackson-mapper-asl # 1.9.13 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.jgroups.kubernetes # jgroups-kubernetes # 1.0.8.Final Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.lz4 # lz4-java # 1.4 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # bson # 3.11.2 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-async # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-core # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-legacy # 3.11.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-reactivestreams # 1.12.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.mongodb # mongodb-driver-sync # 3.11.2 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.quartz-scheduler # quartz # 2.2.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-aop # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-beans # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-context # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-context-support # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-core # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-expression # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-oxm # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-test # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-tx # 4.1.4.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-web # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework # spring-webmvc # 4.0.9.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-ws-core # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-ws-test # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.springframework.ws # spring-xml # 2.2.1.RELEASE Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) org.typelevel # macro-compat_2.12 # 1.1.1 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) stax # stax-api # 1.0.1 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) tomcat # tomcat-apr # 5.5.23 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) xerces # xercesImpl # 2.9.0 Apache The Apache Software License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0.txt) xml-apis # xml-apis # 1.0.b2 BSD BSD (https://github.com/nbronson/scala-stm/blob/master/LICENSE.txt) org.scala-stm # scala-stm_2.12 # 0.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-compiler # 2.12.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-library # 2.12.8 BSD BSD 3-Clause (http://www.scala-lang.org/license.html) org.scala-lang # scala-reflect # 2.12.8 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.owasp.encoder # encoder # 1.2.2 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-java8-compat_2.12 # 1.1.1 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-parser-combinators_2.12 # 1.0.5 BSD BSD 3-clause (http://opensource.org/licenses/BSD-3-Clause) org.scala-lang.modules # scala-xml_2.12 # 1.0.6 BSD BSD License (http://xmlunit.svn.sourceforge.net/viewvc/ checkout /xmlunit/trunk/xmlunit/LICENSE.txt) xmlunit # xmlunit # 1.5 BSD BSD License (https://opensource.org/licenses/bsd-license.php) com.yahoo.platform.yui # yuicompressor # 2.4.8 BSD BSD style (http://xstream.codehaus.org/license.html) com.thoughtworks.xstream # xstream # 1.4.8 BSD BSD-style (http://www.opensource.org/licenses/bsd-license.php) org.scalacheck # scalacheck_2.12 # 1.13.4 BSD New BSD License (http://www.opensource.org/licenses/bsd-license.php) org.hamcrest # hamcrest-core # 1.3 BSD Revised BSD (http://www.jcraft.com/jsch/LICENSE.txt) com.jcraft # jsch # 0.1.55 BSD The BSD License (http://www.opensource.org/licenses/bsd-license.php) jline # jline # 2.14.6 BSD Two-clause BSD-style license (http://github.com/sbt/junit-interface/blob/master/LICENSE.txt) com.novocode # junit-interface # 0.11 CC0 CC0 (http://creativecommons.org/publicdomain/zero/1.0/) org.reactivestreams # reactive-streams # 1.0.2 CDDL COMMON DEVELOPMENT AND DISTRIBUTION LICENSE (CDDL) Version 1.1 (https://javaee.github.io/javamail/LICENSE) com.sun.mail # javax.mail # 1.4.5 CDDL COMMON DEVELOPMENT AND DISTRIBUTION LICENSE (CDDL) Version 1.1 (https://javaee.github.io/servlet-spec/LICENSE) javax.servlet # javax.servlet-api # 4.0.1 LGPL GNU LESSER GENERAL PUBLIC LICENSE (http://www.gnu.org/licenses/lgpl.txt) c3p0 # c3p0 # 0.9.1.1 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) ch.qos.logback # logback-classic # 1.1.8 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) ch.qos.logback # logback-core # 1.1.8 LGPL GNU Lesser General Public License (http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html) info.faljse # SDNotify # 1.3 MIT MIT (http://www.opensource.org/licenses/mit-license.html) com.lihaoyi # sourcecode_2.12 # 0.1.4 MIT MIT (https://opensource.org/licenses/MIT) org.scalamock # scalamock-core_2.12 # 3.5.0 MIT MIT (https://opensource.org/licenses/MIT) org.scalamock # scalamock-scalatest-support_2.12 # 3.5.0 MIT MIT (http://opensource.org/licenses/MIT) org.spire-math # jawn-parser_2.12 # 0.10.3 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) ch.qos.cal10n # cal10n-api # 0.7.4 MIT MIT License (http://www.slf4j.org/license.html) net.logstash.logback # logstash-logback-encoder # 4.6 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # jcl-over-slf4j # 1.7.21 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # jul-to-slf4j # 1.7.21 MIT MIT License (http://www.opensource.org/licenses/mit-license.php) org.slf4j # slf4j-ext # 1.6.3 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # derive_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # fastparse-utils_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # fastparse_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # scalaparse_2.12 # 0.4.4 MIT MIT license (http://www.opensource.org/licenses/mit-license.php) com.lihaoyi # upickle_2.12 # 0.4.4 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-annotations_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-core_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-jetty_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-macros_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-redis_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-shared_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.commons # commons-spring_2.12 # 1.40.1 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-core_2.12 # 1.20.19 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-macros_2.12 # 1.20.19 MIT The MIT License (https://opensource.org/licenses/MIT) com.avsystem.scex # scex-util_2.12 # 1.20.19 MIT The MIT License (http://jsoup.com/license) org.jsoup # jsoup # 1.8.3 MIT The MIT License (http://github.com/mockito/mockito/blob/master/LICENSE) org.mockito # mockito-core # 1.10.19 Mozilla MPL 1.1 (http://www.mozilla.org/MPL/MPL-1.1.html) org.javassist # javassist # 3.19.0-GA Mozilla MPL 1.1 (http://www.mozilla.org/MPL/MPL-1.1.html) rhino # js # 1.7R2 Public Domain Public Domain aopalliance # aopalliance # 1.0 Public Domain Public Domain (http://www.xmlpull.org/v1/download/unpacked/LICENSE.txt) xmlpull # xmlpull # 1.1.3.1 Public Domain Public Domain (http://creativecommons.org/licenses/publicdomain) xpp3 # xpp3_min # 1.1.4c unrecognized Bouncy Castle Licence (http://www.bouncycastle.org/licence.html) org.bouncycastle # bcpkix-jdk15on # 1.51 unrecognized Bouncy Castle Licence (http://www.bouncycastle.org/licence.html) org.bouncycastle # bcprov-jdk15on # 1.51 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # californium-core # 2.0.0-M18 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # californium-legal # 2.0.0-M18 unrecognized Eclipse Public License - v 2.0 (https://www.eclipse.org/legal/epl-2.0) org.eclipse.californium # scandium # 2.0.0-M18 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # com.ibm.icu # 50.1.1.v201304230130 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.apache.commons.logging # 1.1.1.v201101211721 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.birt.runtime # 4.3.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.contenttype # 3.4.200.v20130326-1255 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.expressions # 3.4.500.v20130515-1343 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.filesystem # 1.4.0.v20130514-1240 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.jobs # 3.5.300.v20130429-1813 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.resources # 3.8.100.v20130521-2026 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.core.runtime # 3.9.0.v20130326-1255 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity # 1.2.8.v201305301230 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.apache.derby # 1.0.103.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.apache.derby.dbdefinition # 1.0.2.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.console.profile # 1.0.10.v201109250955 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.db.generic # 1.0.1.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.dbdefinition.genericJDBC # 1.0.1.v201107221459 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda # 3.4.0.v201305170924 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.consumer # 3.2.6.v201305170644 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.design # 3.3.6.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.flatfile # 3.1.5.v201305221644 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.oda.profile # 3.2.8.v201209080429 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.connectivity.sqm.core # 1.2.6.v201212070447 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.hsqldb # 1.0.0.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.hsqldb.dbdefinition # 1.0.0.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.db2.luw # 1.0.2.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.db2.luw.dbdefinition # 1.0.4.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.informix # 1.0.1.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.ibm.informix.dbdefinition # 1.0.4.v201107221502 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.msft.sqlserver # 1.0.2.v201212120617 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.msft.sqlserver.dbdefinition # 1.0.1.v201201240505 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.mysql # 1.0.4.v201212120617 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.mysql.dbdefinition # 1.0.4.v201109022331 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oda.ws # 1.2.5.v201305031101 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oda.xml # 1.2.5.v201305031101 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oracle # 1.0.0.v201107221506 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.oracle.dbdefinition # 1.0.103.v201206010214 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.postgresql # 1.1.1.v201205252207 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.enablement.postgresql.dbdefinition # 1.0.2.v201110070445 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.dbdefinition # 1.0.2.v201107221519 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.derby # 1.0.0.v201107221519 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.sql # 1.0.6.v201208230744 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.datatools.modelbase.sql.query # 1.1.4.v201212120619 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf # 2.6.0.v20130610-0406 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.common # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore.change # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.emf.ecore.xmi # 2.9.0.v20130528-0742 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.app # 1.3.100.v20130327-1442 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.common # 3.6.200.v20130402-1505 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.preferences # 3.5.100.v20130422-1538 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.equinox.registry # 3.5.300.v20130327-1442 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.osgi # 3.9.0.v20130529-1710 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.osgi.services # 3.3.100.v20130513-1956 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime # org.eclipse.update.configurator # 3.3.200.v20130326-1319 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # Tidy # 1 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # com.lowagie.text # 2.1.7 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # derby # 10.5.1000001 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.bridge # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.css # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.dom # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.dom.svg # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.ext.awt # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.parser # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.svggen # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.transcoder # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.util # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.util.gui # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.xml # 1.6.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xerces # 2.9.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xml.resolver # 1.2.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.apache.xml.serializer # 2.7.1 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.mozilla.javascript # 1.7.2 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.css.sac # 1.3.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.dom.smil # 1.0.0 unrecognized Eclipse Public License - v 1.0 (http://www.eclipse.org/org/documents/epl-v10.html) org.eclipse.birt.runtime.3_7_1 # org.w3c.dom.svg # 1.1.0 unrecognized Eclipse Public License - v 1.0 (https://www.eclipse.org/org/documents/epl-v10.php) org.eclipse.paho:org.eclipse.paho.client.mqttv3:1.2.0 unrecognized Eclipse Public License 1.0 (http://www.eclipse.org/legal/epl-v10.html) junit # junit # 4.12 unrecognized The W3C Software License (http://www.w3.org/Consortium/Legal/copyright-software-19980720) org.w3c.css # sac # 1.3 unrecognized The W3C Software License (http://www.w3.org/Consortium/Legal/copyright-software-19980720) com.vaadin.external.flute # flute # 1.3.0.gg2 unrecognized none specified (none specified) commons-net # commons-net # 3.3 unrecognized none specified (none specified) dom4j # dom4j # 1.6.1 unrecognized none specified (none specified) javax.activation # activation # 1.1.1 unrecognized none specified (none specified) milyn # flute # 1.3 unrecognized none specified (none specified) net.java.dev.jna # jna # 5.1.0 unrecognized none specified (none specified) org.apache.commons # commons-compress # 1.13 unrecognized none specified (none specified) org.codehaus.jettison # jettison # 1.3 unrecognized none specified (none specified) org.eclipse.birt.report.engine.emitter # csv # 1.0.0.201110121016 unrecognized none specified (none specified) org.eclipse.birt.runtime.3_7_1 # org.apache.batik.pdf # 1.6.0 unrecognized none specified (none specified) org.slf4j # slf4j-api # 1.7.21 unrecognized none specified (none specified) org.vaadin.addons # aceeditor # 0.8.14 unrecognized none specified (none specified) org.vaadin.addons # ckeditor-wrapper-for-vaadin # 7.10.8 unrecognized none specified (none specified) org.vaadin.addons # legacycombobox # 0.1.4 unrecognized none specified (none specified) org.vaadin.addons # tokenfield # 7.0.1","title":"Third party software"},{"location":"User_Guide/Extensions/Forwarding_notifications.html","text":"Forwarding notifications to a REST endpoint # Read this chapter to learn how to forward a message to a REST endpoint. To forward a notification: Go to Administration \u2014> Extensions . In the My custom REST template panel, click the Setup button. Configure your message: From a list of groups, select a group to which you want to forward a message. If you want to add a new group, click the click here link. Into the URL field, type an URL to which the message will be sent. You can use expressions inside the URL. From the HTTP method list, select a method you want to use. If you want to use basic authentication, into proper fields, type a username and a password. Into the Message content field, type the message that you want to forward in a JSON format. If you leave this field blank; then a default message (displayed in gray) will be forwarded. You can use Expressions : ${#path} - a placeholder for a path of a resource, instance or object that is observed. ${#value} - a placeholder for an observed value sent in the notification. Note ${#path} and ${#value} are valid JSONs so due to the format they cannot be in additional quotation marks (if they will, the format of the entire message will be invalid). Other expressions need to be inside quotation marks. Click the Confirm button. The properly configured task executes on a selected group of devices.","title":"Forwarding notifications to a REST endpoint"},{"location":"User_Guide/Extensions/Forwarding_notifications.html#forwarding-notifications-to-a-rest-endpoint","text":"Read this chapter to learn how to forward a message to a REST endpoint. To forward a notification: Go to Administration \u2014> Extensions . In the My custom REST template panel, click the Setup button. Configure your message: From a list of groups, select a group to which you want to forward a message. If you want to add a new group, click the click here link. Into the URL field, type an URL to which the message will be sent. You can use expressions inside the URL. From the HTTP method list, select a method you want to use. If you want to use basic authentication, into proper fields, type a username and a password. Into the Message content field, type the message that you want to forward in a JSON format. If you leave this field blank; then a default message (displayed in gray) will be forwarded. You can use Expressions : ${#path} - a placeholder for a path of a resource, instance or object that is observed. ${#value} - a placeholder for an observed value sent in the notification. Note ${#path} and ${#value} are valid JSONs so due to the format they cannot be in additional quotation marks (if they will, the format of the entire message will be invalid). Other expressions need to be inside quotation marks. Click the Confirm button. The properly configured task executes on a selected group of devices.","title":"Forwarding notifications to a REST endpoint"},{"location":"User_Guide/Extensions/Integrating_with_Coiote_IoT_Data_Orchestration.html","text":"Integrating with Coiote IoT Data Orchestration # Read this chapter to learn how to integrate with Coiote IoT Data Orchestration to manage data retrieved from devices and telemetry channels. To integrate with Coiote IoT Data Orchestration: Go to Administration \u2014> Extensions . In the Coiote IoT Data Orchestration panel, click the Setup button. Copy all data found on the pop-up because you will need it later. Paste copied data to the Coiote IoT Data Orchestration platform and click the Connect button. The integration process will be done by the Coiote IoT Data Orchestration platform.","title":"Integrating with Coiote IoT Data Orchestration"},{"location":"User_Guide/Extensions/Integrating_with_Coiote_IoT_Data_Orchestration.html#integrating-with-coiote-iot-data-orchestration","text":"Read this chapter to learn how to integrate with Coiote IoT Data Orchestration to manage data retrieved from devices and telemetry channels. To integrate with Coiote IoT Data Orchestration: Go to Administration \u2014> Extensions . In the Coiote IoT Data Orchestration panel, click the Setup button. Copy all data found on the pop-up because you will need it later. Paste copied data to the Coiote IoT Data Orchestration platform and click the Connect button. The integration process will be done by the Coiote IoT Data Orchestration platform.","title":"Integrating with Coiote IoT Data Orchestration"},{"location":"User_Guide/Extensions/Integrating_with_the_ThingWorx_platform.html","text":"Integrating with the ThingWorx platform # To integrate with ThingWorx, read the attached instruction: the LwM2M ThingWorx extension user guide .","title":"Integrating with the ThingWorx platform"},{"location":"User_Guide/Extensions/Integrating_with_the_ThingWorx_platform.html#integrating-with-the-thingworx-platform","text":"To integrate with ThingWorx, read the attached instruction: the LwM2M ThingWorx extension user guide .","title":"Integrating with the ThingWorx platform"},{"location":"User_Guide/Extensions/Registration_status_action.html","text":"Setting up registration status action # The registration status action extension lets you configure actions performed on the lists of registered and deregistered devices. Read the instructions below to learn how to set them up. To configure the registration status action extension: Go to Administration \u2014> Extensions . In the Devices registration status action panel, click the Setup button. In the window that appears, configure your action: In the Edit tab, define your action logic. The lists of registered and deregistered devices are available in the ${args.registeredDevices} and ${args.deregisteredDevices} expression contexts. Note Each newly executed action is performed on the list of devices that have registered/deregistered within the defined interval. Note that if the action execution fails, it will be retried within the subsequent time interval. You can also specify how often the status of registered/deregistered devices should be checked and updated using the time interval and time unit dropdowns. After you have configured your registration status action, click Save . Action execution will start immediately. If you want to check the status of execution of your configured action, go to the Execution logs tab. Example setup # Assuming that your config directory is called my-config : Create file my-config/entities/carp.conf : entities { \"com.avsystem.ump.core.db.entities.carp.Carp\" { \"/DevicesRegistrationStatus\" = { \"hook\" : \"DevicesRegistrationStatus\" \"definition\" : \"\"\"<config><log message=\"Hello!\" /></config>\"\"\" domain: \"/\" logLevel = 3 properties { jobIntervalTimeSeconds : \"60\" } } } } Add the following to my-config/beans.conf: commonEntitiesList += ${abstractDataTransceiverEntry}{ importOption = ADD_NEW_AND_UPDATE_EXISTING map.\"com.avsystem.ump.core.db.entities.carp.Carp\" = /my-config/entities/carp.conf } Warning Note that you need to adjust my-config inside! Optionally, you can adjust the following entries in my-config/cdm.conf to your liking: smg.mod.dataTransceiver { carpRegistrationStatusPostImportHook { # After a CARP is imported, the fist execution of the CARP job # will be delayed by a random duration between the two provided # This is meant as a form of preventing many computation- and I/O- # intensive tasks from executing at once during system startup # You can set both to the same value to eliminate randomness # Or set both to \"0s\" to disable delay minimalInitialDelay = 20s maximalInitialDelay = 2min } }","title":"Setting up registration status action"},{"location":"User_Guide/Extensions/Registration_status_action.html#setting-up-registration-status-action","text":"The registration status action extension lets you configure actions performed on the lists of registered and deregistered devices. Read the instructions below to learn how to set them up. To configure the registration status action extension: Go to Administration \u2014> Extensions . In the Devices registration status action panel, click the Setup button. In the window that appears, configure your action: In the Edit tab, define your action logic. The lists of registered and deregistered devices are available in the ${args.registeredDevices} and ${args.deregisteredDevices} expression contexts. Note Each newly executed action is performed on the list of devices that have registered/deregistered within the defined interval. Note that if the action execution fails, it will be retried within the subsequent time interval. You can also specify how often the status of registered/deregistered devices should be checked and updated using the time interval and time unit dropdowns. After you have configured your registration status action, click Save . Action execution will start immediately. If you want to check the status of execution of your configured action, go to the Execution logs tab.","title":"Setting up registration status action"},{"location":"User_Guide/Extensions/Registration_status_action.html#example-setup","text":"Assuming that your config directory is called my-config : Create file my-config/entities/carp.conf : entities { \"com.avsystem.ump.core.db.entities.carp.Carp\" { \"/DevicesRegistrationStatus\" = { \"hook\" : \"DevicesRegistrationStatus\" \"definition\" : \"\"\"<config><log message=\"Hello!\" /></config>\"\"\" domain: \"/\" logLevel = 3 properties { jobIntervalTimeSeconds : \"60\" } } } } Add the following to my-config/beans.conf: commonEntitiesList += ${abstractDataTransceiverEntry}{ importOption = ADD_NEW_AND_UPDATE_EXISTING map.\"com.avsystem.ump.core.db.entities.carp.Carp\" = /my-config/entities/carp.conf } Warning Note that you need to adjust my-config inside! Optionally, you can adjust the following entries in my-config/cdm.conf to your liking: smg.mod.dataTransceiver { carpRegistrationStatusPostImportHook { # After a CARP is imported, the fist execution of the CARP job # will be delayed by a random duration between the two provided # This is meant as a form of preventing many computation- and I/O- # intensive tasks from executing at once during system startup # You can set both to the same value to eliminate randomness # Or set both to \"0s\" to disable delay minimalInitialDelay = 20s maximalInitialDelay = 2min } }","title":"Example setup"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module.html","text":"Monitoring # The Monitoring module is responsible for collecting historical data about devices' state as well as providing rich user interface for browsing such information. Device's state is usually expressed by a subset of its data model parameters values, which are selected either if they expresses devices performance or their usability for analysis. There are separate sets of specific properties suitable for DSL or WiMAX devices as well as common ones, such as link consumption and connection latency. Composing those areas you can get a full picture. Sampling interval is the most often expressed by devices periodic interval - as a result, state is logged every periodic session. The module is able to aggregate data from multiple devices. For every group of devices, which has monitoring enabled, samples from all devices, which belong to it are aggregated providing high-level statistics. In contrast to device's state history, which provides exact information about properties value, associated with event time, aggregates provide accumulated values disjointed from exact event time, but available at different levels of granularity. Every property being under monitoring is called a monitoring resource. Depending on its content it can have a numerical or textual type: Numerical resources are used when values such as signal strength, transferred bytes or packet loss come into consideration. Aggregated provides such metrics as an average value and standard deviation. Textual resources, besides obvious usage for tracing, for example, PPP username, can be used for enumerable values, for example, enabled, disabled or beacon type. During aggregation, for each encountered value, hit count is available. Another type of resources are alerts, which are used for signaling occurrences of interesting events or classifying devices state. They introduce some added logic in order to help you detect abnormal situations. They are divided into: One shot alerts - an event occurrence is logged, this type relates to, for example, PPP username, modulation type, Wi-Fi SSID change. Stateful alerts - they have two states: raised and hidden. They express state persistence, for example, noise margin exceeded alert is raised all the time connection noise margin exceeds a configured threshold. Data collection frequency # In order to provide statistics with desired granularity, monitoring introduces a concept of a sampling interval - a time period during which one sample should be collected. On the other hand, it prevents excessive storage usage - only one sample per sampling interval is stored. As samples collection usually occurs during a device's periodic visit, monitoring ensures the sampling interval by lowering, if it is required, the device's periodic interval too meet mentioned requirements. Giving examples: Monitoring interval: 180s, periodic interval: 60s - during 180s 3 periodic visits occur, only one monitoring sample is collected, a periodic interval is not modified. Monitoring interval: 180s, periodic interval: 600s - periodic interval is lowered to 180s in order to ensure at least one sample is collected every 180s. Aggregates storage manages samples collection differently. There is always a constant number of aggregates as they should be pre-allocated in order to store events that may occur on devices. They are broken down into multiple levels: minute, hour, day; values from a finery-grained level applies to a coarser-level aggregate. Finer level aggregates are available only for the most recent time frame, the rationale for this is to provide detailed information only for the latest data, optimizing storage space simultaneously. Retention time is: Minute - for the last 24 hours Hour - for the last week. Example: Group contains Device 1 (D1, periodic 20 min) and Device 2 (D2, periodic 30 min), the sampling interval is equal to 30 minutes. Numerical values reported by devices are v1 & v2. Through an hour following events occur: 14 Periodic Samples collection Minute aggregated value hour Aggregate value :00 -- collection window 0 0 :01 D1, D2 periodic D1, D2 v1 + v2 v1 + v2 :16 D1 periodic -- 0 v1 + v2 :21 D2 periodic -- 0 v1 + v2 :30 -- collection window 0 v1 + v2 :31 D1 periodic D1 v1 2 * v1 + v2 :41 D2 periodic D2 v2 2 * v1 + 2 * v2 :46 D1 periodic -- 0 2 * v1 + 2 * v2 :60 -- collection window 0 2 * v1 + 2 * v2 Summary: Device 1 - 2 samples - 14:01, 14:31, Device 2 - 2 samples - 14:01, 14:41, Minute aggregates - there are 60 aggregates per each minute, from which 3 have non-zero value: 14:01. 14:31, 14:41, Hour aggregate - there is 1, which has accumulated value: 2 * v1 + 2 * v2. Target selection # You have to choose, which devices you want to monitor by selecting monitoring groups. Every device, which belongs to any of selected groups or their sub-groups is under monitoring. The same applies to aggregate storage, group scoped statistics are available for all selected groups and their sub-groups. Given such a hierarchy: root |-- lwm2m | |-- dsl | | |-- firmware v1 (D1) | | |-- firmware v2 (D2) | +-- adsl | |-- firmware v4 (D3) | |-- firmware v5 +-- devicetypes |-- manufacturer 1 |-- manufacturer 2 (D1, D2) |-- manufacturer 3 (D3) Selection of root.lwm2m.dsl and root.lwm2m.adsl groups as monitoring groups results in device samples collection for all devices (D1, D2, D3) and aggregates storage for all groups in the hierarchy. Samples will be collected in all groups including devices D1, D2, D3. Determining a group set where aggregates are available might be a resource consuming task, as every monitored devices group set should be checked. Enter a monitoring group view to see available monitoring types for which data is available. They are divided into two groups: Group monitoring - presented for groups (and their sub-groups) directly chosen as monitoring groups, taken into consideration when calculating monitored devices set. Other monitoring - all other monitoring types configured in the system, for which aggregates might exist. Target exclusion # As aggregates are stored separately for every group under monitoring, in case there exist multi-level, wide hierarchy it may lead to excessive storage consumption. Let us consider a situation where devices are grouped by their location into country - region - city - area hierarchy. In such case, area level may not be very useful as it aggregates data from a few devices can be excluded from monitored groups in order to reduce required storage space. It is accomplished by usage of exclusion \ufeffpatterns expressed as a Java programming language regular expression. If a group name matches any of configured expressions, it will be excluded from monitoring. For hierarchy from previous paragraph, selection of root.lwm2m results in device samples collection for devices and aggregates storage for: root.lwm2m root.lwm2m.dsl root.lwm2m.dsl.firmware v1 root.lwm2m.dsl.firmware v2 root.lwm2m.adsl root.lwm2m.adsl.firmware v4 root.lwm2m.adsl.firmware v5 Application of exclusion pattern: root\\.lwm2m\\..* reduces the monitored group set to group root.lwm2m. See also: Monitoring configuration Specific settings for monitoring Adding monitoring Browsing monitoring results Monitoring map","title":"Monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module.html#monitoring","text":"The Monitoring module is responsible for collecting historical data about devices' state as well as providing rich user interface for browsing such information. Device's state is usually expressed by a subset of its data model parameters values, which are selected either if they expresses devices performance or their usability for analysis. There are separate sets of specific properties suitable for DSL or WiMAX devices as well as common ones, such as link consumption and connection latency. Composing those areas you can get a full picture. Sampling interval is the most often expressed by devices periodic interval - as a result, state is logged every periodic session. The module is able to aggregate data from multiple devices. For every group of devices, which has monitoring enabled, samples from all devices, which belong to it are aggregated providing high-level statistics. In contrast to device's state history, which provides exact information about properties value, associated with event time, aggregates provide accumulated values disjointed from exact event time, but available at different levels of granularity. Every property being under monitoring is called a monitoring resource. Depending on its content it can have a numerical or textual type: Numerical resources are used when values such as signal strength, transferred bytes or packet loss come into consideration. Aggregated provides such metrics as an average value and standard deviation. Textual resources, besides obvious usage for tracing, for example, PPP username, can be used for enumerable values, for example, enabled, disabled or beacon type. During aggregation, for each encountered value, hit count is available. Another type of resources are alerts, which are used for signaling occurrences of interesting events or classifying devices state. They introduce some added logic in order to help you detect abnormal situations. They are divided into: One shot alerts - an event occurrence is logged, this type relates to, for example, PPP username, modulation type, Wi-Fi SSID change. Stateful alerts - they have two states: raised and hidden. They express state persistence, for example, noise margin exceeded alert is raised all the time connection noise margin exceeds a configured threshold.","title":"Monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module.html#data-collection-frequency","text":"In order to provide statistics with desired granularity, monitoring introduces a concept of a sampling interval - a time period during which one sample should be collected. On the other hand, it prevents excessive storage usage - only one sample per sampling interval is stored. As samples collection usually occurs during a device's periodic visit, monitoring ensures the sampling interval by lowering, if it is required, the device's periodic interval too meet mentioned requirements. Giving examples: Monitoring interval: 180s, periodic interval: 60s - during 180s 3 periodic visits occur, only one monitoring sample is collected, a periodic interval is not modified. Monitoring interval: 180s, periodic interval: 600s - periodic interval is lowered to 180s in order to ensure at least one sample is collected every 180s. Aggregates storage manages samples collection differently. There is always a constant number of aggregates as they should be pre-allocated in order to store events that may occur on devices. They are broken down into multiple levels: minute, hour, day; values from a finery-grained level applies to a coarser-level aggregate. Finer level aggregates are available only for the most recent time frame, the rationale for this is to provide detailed information only for the latest data, optimizing storage space simultaneously. Retention time is: Minute - for the last 24 hours Hour - for the last week. Example: Group contains Device 1 (D1, periodic 20 min) and Device 2 (D2, periodic 30 min), the sampling interval is equal to 30 minutes. Numerical values reported by devices are v1 & v2. Through an hour following events occur: 14 Periodic Samples collection Minute aggregated value hour Aggregate value :00 -- collection window 0 0 :01 D1, D2 periodic D1, D2 v1 + v2 v1 + v2 :16 D1 periodic -- 0 v1 + v2 :21 D2 periodic -- 0 v1 + v2 :30 -- collection window 0 v1 + v2 :31 D1 periodic D1 v1 2 * v1 + v2 :41 D2 periodic D2 v2 2 * v1 + 2 * v2 :46 D1 periodic -- 0 2 * v1 + 2 * v2 :60 -- collection window 0 2 * v1 + 2 * v2 Summary: Device 1 - 2 samples - 14:01, 14:31, Device 2 - 2 samples - 14:01, 14:41, Minute aggregates - there are 60 aggregates per each minute, from which 3 have non-zero value: 14:01. 14:31, 14:41, Hour aggregate - there is 1, which has accumulated value: 2 * v1 + 2 * v2.","title":"Data collection frequency"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module.html#target-selection","text":"You have to choose, which devices you want to monitor by selecting monitoring groups. Every device, which belongs to any of selected groups or their sub-groups is under monitoring. The same applies to aggregate storage, group scoped statistics are available for all selected groups and their sub-groups. Given such a hierarchy: root |-- lwm2m | |-- dsl | | |-- firmware v1 (D1) | | |-- firmware v2 (D2) | +-- adsl | |-- firmware v4 (D3) | |-- firmware v5 +-- devicetypes |-- manufacturer 1 |-- manufacturer 2 (D1, D2) |-- manufacturer 3 (D3) Selection of root.lwm2m.dsl and root.lwm2m.adsl groups as monitoring groups results in device samples collection for all devices (D1, D2, D3) and aggregates storage for all groups in the hierarchy. Samples will be collected in all groups including devices D1, D2, D3. Determining a group set where aggregates are available might be a resource consuming task, as every monitored devices group set should be checked. Enter a monitoring group view to see available monitoring types for which data is available. They are divided into two groups: Group monitoring - presented for groups (and their sub-groups) directly chosen as monitoring groups, taken into consideration when calculating monitored devices set. Other monitoring - all other monitoring types configured in the system, for which aggregates might exist.","title":"Target selection"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module.html#target-exclusion","text":"As aggregates are stored separately for every group under monitoring, in case there exist multi-level, wide hierarchy it may lead to excessive storage consumption. Let us consider a situation where devices are grouped by their location into country - region - city - area hierarchy. In such case, area level may not be very useful as it aggregates data from a few devices can be excluded from monitored groups in order to reduce required storage space. It is accomplished by usage of exclusion \ufeffpatterns expressed as a Java programming language regular expression. If a group name matches any of configured expressions, it will be excluded from monitoring. For hierarchy from previous paragraph, selection of root.lwm2m results in device samples collection for devices and aggregates storage for: root.lwm2m root.lwm2m.dsl root.lwm2m.dsl.firmware v1 root.lwm2m.dsl.firmware v2 root.lwm2m.adsl root.lwm2m.adsl.firmware v4 root.lwm2m.adsl.firmware v5 Application of exclusion pattern: root\\.lwm2m\\..* reduces the monitored group set to group root.lwm2m. See also: Monitoring configuration Specific settings for monitoring Adding monitoring Browsing monitoring results Monitoring map","title":"Target exclusion"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_a_single_parameter_on_a_device.html","text":"Monitoring a single parameter on a device # Read this chapter to learn how to monitor a single parameter on one device. To monitor a parameter: Go to Device inventory . From the list of devices, select a proper device. Go to the Objects tab. Find a parameter you want to monitor, and click the Value tracking button. From the Select mode list, select Monitoring (collect data) . To limit data usage, click the Limit data usage link and select proper check boxes. Click the Set tracking button. As a result, the Observe request is sent to the device and notifications (results) are saved in the database and their history is visible on the chart. Tip To view results of monitoring , click the Value tracking button. To stop monitoring, click the Value tracking button, go to the Settings tab, and click the Delete tracking link. Keep in mind, that if you stop monitoring then its results will not be saved and visible on the chart anymore.","title":"Monitoring a single parameter on a device"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_a_single_parameter_on_a_device.html#monitoring-a-single-parameter-on-a-device","text":"Read this chapter to learn how to monitor a single parameter on one device. To monitor a parameter: Go to Device inventory . From the list of devices, select a proper device. Go to the Objects tab. Find a parameter you want to monitor, and click the Value tracking button. From the Select mode list, select Monitoring (collect data) . To limit data usage, click the Limit data usage link and select proper check boxes. Click the Set tracking button. As a result, the Observe request is sent to the device and notifications (results) are saved in the database and their history is visible on the chart. Tip To view results of monitoring , click the Value tracking button. To stop monitoring, click the Value tracking button, go to the Settings tab, and click the Delete tracking link. Keep in mind, that if you stop monitoring then its results will not be saved and visible on the chart anymore.","title":"Monitoring a single parameter on a device"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html","text":"Reporting # This document describes the reporting module. In this module you can find information about: Viewing and scheduling reports Managing reports templates Configuring reports Reports # In this tab you can view all scheduled reports and their results. Reports search input - you can filter reports by a column from a table. You can select a filtering column by clicking the icon in the table header. The table contains most important information about scheduled reports: - a report was generated successfully - a generation process is not finished yet - there were some problems with the report generation Configuration - you can read more about a configuration in the Reporting Configuration Details section. Buttons: Delete - use it to delete a report. Warning Reports are deleted without confirmation. If you click the Delete button, then the report will be deleted immediately. Remove all results - use it to delete all files generated by report executions. Warning Results are deleted without confirmation. If you click the Remove all results button, then report results will be deleted immediately. Modify - use it to modify a report. Create similar - use it to quickly create a new report on the basis of the report you view. Results - use it to find all results files and to download them. Schedule report # Reports can be customized in many ways. Read a short description of a layout and a detailed description of a configuration with examples. Layout # Title - use it to name a report. Template selection - use it to select a template of a report. You can find more about templates in the Templates section. Schedule - use it to select when the report will be created: Immediate - use it to generate a report as soon as possible. Single execution - use it to generate a report once on selected date. Periodic execution - use it to generate a report periodically. Time interval - use it to select a period from which data will be used to generate the report. Output - use it to select a format of the report, for example, PDF, HTML or CSV. Transfers - use it to select how the generated report will be sent, for example, by email or uploaded to a remote server using FTP, SFTP or SCP. Parameters - use it to set detailed parameters of the report. Retention policy - use it to set rules of cleaning up old report files. Schedule - use this button to schedule a report. Reporting configuration details # This part describes the report configuration in details. Template selection # There is a lot of templates you can select to generate the report. All templates are grouped in categories, for example: General Report - reports connected with general information about users and devices. Hosted - a report for clients of the Coiote DM Cloud installation. Monitoring reports - all reports based on monitoring. Inactivity reports . The selected template can impact possible options in other sections of configuration. Schedule # There are three types of a report execution schedule: Immediate - a report will be generated only once as soon as possible. Single execution - the report will be generated once on a selected date, you can select any future date. Periodic execution - the report will be generated every selected time period: Monthly - on a selected day of a month and time of the day. Be careful with selecting the last day of a month, for example, February has only 28/29 days. Weekly - on a selected day of a week and time of the day. Daily - everyday on selected time. Time interval # This part defines a time period that will be taken to the report. There are two ways of selecting it: Sliding window - this option is useful for periodic reports, you can select interval relatively to generation time, for example, last 6 hours, last month. Custom - you can select custom time, for example, 8 days 2 hours and 15 minutes. Start and End date - a fixed time period, useful for a single execution. Output # You can select an output type for the report. Possible formats may differ between report templates. Usually you can use: CSV, DOC, HTML, PDF, PPT or XLS. Transfers # Beside downloading report files, you can use four transport mechanisms (you need to select the Use check box to activate this option): Email - after every execution, results will be sent to added emails. FTP - results will be uploaded to a provided server using the FTP protocol. SFTP - results will be uploaded to the provided server using the SFTP protocol. SCP - results will be uploaded to the provided server using the SCP protocol. In FTP/SFTP/SCP you can select Add date to generated file name check box, than every transferred file will have a generation date added at a beginning of a file name. If you do not select this option, then newer files will be overridden by older ones. To eliminate any problems with file names, since the 16.01 version an additional setting was added in cdm.conf : reports.replaceForbiddenChars=true By default it is set to true , and it replaces all forbidden characters with proper ones. For example, a report title is FAP Node H CPE and its file name was generated in versions previous to 16.01 as FAP Node H CPE and now it will be FAP_Node_H_Group . Tip Remember that a user password provided in this form is not encrypted. Parameters # Content of this part depends on a selected report template. Usually you can find device or group selection, monitoring ID selection for monitoring based reports. Retention policy # You can set two parameters: Remove reports older than - all report files older than a provided number of days will be removed (default: 14 days). Number of files to retain - if report executions will generate more files than a provided number (default: 30), then the system will remove all beside the newest number. Note This rules concern only local report files, they do not affect files uploaded to a remote server using the Transfers feature. Templates # Here you can read more about report templates and a panel to manage them. Layout # Report templates - use it to browse through all report templates. Additionally, you can download, delete or check their details. If a report template has an invalid file format, then you will see information Invalid file in the `Structure column. What is more, you will not be able to use this template while scheduling a report. Add new template - use it to open a creation form. Check Custom templates section for more details. When you select the report template from a table, an edition form will open. It looks exactly the same as the creation form. Custom templates creation # Look at the list below to find information about creating custom report templates. Save - use it to save changes. Cancel - use it to discard all changes. Template title - use it to set a name of a template. Template category - use it to set a category from which the template will be accessible. File name - use it to set a name of a file with the template. Required permission - use it to select a permission that will be required to use the template. This field is optional. Monitoring report - use it to indicate if the template is based on monitoring. Monitoring type - if the template is based on monitoring, then you should select which one. Upload - use this button to upload the report template file. A template file must be in a .rptdesign or .cft format. If you try to upload the file in another format, then you will see information that a structure is invalid and you will not be able to save this template. There is a limit regarding a size of the report template, information about it is displayed when you try to upload the bigger file than allowed. If needed, you can change the limit in the configuration file. To learn how to do this, please refer to the Admin Guide, Changing the size of a report template section. Reports configuration # This panel allows you to configure default reports properties and make scheduling of new reports faster. Preferences target - use it to select if this settings should be visible only for you ( Current user ) or for everyone in UMP. Output - use it to select default output formats. You can use CSV, DOC, HTML, PDF, PPT or XLS. Email address - use it to add email addresses to which reports will be sent. Default retention policy - look at the Retention policy section for details. Save - click it to save changes in default reports settings.","title":"Reporting"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#reporting","text":"This document describes the reporting module. In this module you can find information about: Viewing and scheduling reports Managing reports templates Configuring reports","title":"Reporting"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#reports","text":"In this tab you can view all scheduled reports and their results. Reports search input - you can filter reports by a column from a table. You can select a filtering column by clicking the icon in the table header. The table contains most important information about scheduled reports: - a report was generated successfully - a generation process is not finished yet - there were some problems with the report generation Configuration - you can read more about a configuration in the Reporting Configuration Details section. Buttons: Delete - use it to delete a report. Warning Reports are deleted without confirmation. If you click the Delete button, then the report will be deleted immediately. Remove all results - use it to delete all files generated by report executions. Warning Results are deleted without confirmation. If you click the Remove all results button, then report results will be deleted immediately. Modify - use it to modify a report. Create similar - use it to quickly create a new report on the basis of the report you view. Results - use it to find all results files and to download them.","title":"Reports"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#schedule-report","text":"Reports can be customized in many ways. Read a short description of a layout and a detailed description of a configuration with examples.","title":"Schedule report"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#layout","text":"Title - use it to name a report. Template selection - use it to select a template of a report. You can find more about templates in the Templates section. Schedule - use it to select when the report will be created: Immediate - use it to generate a report as soon as possible. Single execution - use it to generate a report once on selected date. Periodic execution - use it to generate a report periodically. Time interval - use it to select a period from which data will be used to generate the report. Output - use it to select a format of the report, for example, PDF, HTML or CSV. Transfers - use it to select how the generated report will be sent, for example, by email or uploaded to a remote server using FTP, SFTP or SCP. Parameters - use it to set detailed parameters of the report. Retention policy - use it to set rules of cleaning up old report files. Schedule - use this button to schedule a report.","title":"Layout"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#reporting-configuration-details","text":"This part describes the report configuration in details.","title":"Reporting configuration details"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#template-selection","text":"There is a lot of templates you can select to generate the report. All templates are grouped in categories, for example: General Report - reports connected with general information about users and devices. Hosted - a report for clients of the Coiote DM Cloud installation. Monitoring reports - all reports based on monitoring. Inactivity reports . The selected template can impact possible options in other sections of configuration.","title":"Template selection"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#schedule","text":"There are three types of a report execution schedule: Immediate - a report will be generated only once as soon as possible. Single execution - the report will be generated once on a selected date, you can select any future date. Periodic execution - the report will be generated every selected time period: Monthly - on a selected day of a month and time of the day. Be careful with selecting the last day of a month, for example, February has only 28/29 days. Weekly - on a selected day of a week and time of the day. Daily - everyday on selected time.","title":"Schedule"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#time-interval","text":"This part defines a time period that will be taken to the report. There are two ways of selecting it: Sliding window - this option is useful for periodic reports, you can select interval relatively to generation time, for example, last 6 hours, last month. Custom - you can select custom time, for example, 8 days 2 hours and 15 minutes. Start and End date - a fixed time period, useful for a single execution.","title":"Time interval"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#output","text":"You can select an output type for the report. Possible formats may differ between report templates. Usually you can use: CSV, DOC, HTML, PDF, PPT or XLS.","title":"Output"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#transfers","text":"Beside downloading report files, you can use four transport mechanisms (you need to select the Use check box to activate this option): Email - after every execution, results will be sent to added emails. FTP - results will be uploaded to a provided server using the FTP protocol. SFTP - results will be uploaded to the provided server using the SFTP protocol. SCP - results will be uploaded to the provided server using the SCP protocol. In FTP/SFTP/SCP you can select Add date to generated file name check box, than every transferred file will have a generation date added at a beginning of a file name. If you do not select this option, then newer files will be overridden by older ones. To eliminate any problems with file names, since the 16.01 version an additional setting was added in cdm.conf : reports.replaceForbiddenChars=true By default it is set to true , and it replaces all forbidden characters with proper ones. For example, a report title is FAP Node H CPE and its file name was generated in versions previous to 16.01 as FAP Node H CPE and now it will be FAP_Node_H_Group . Tip Remember that a user password provided in this form is not encrypted.","title":"Transfers"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#parameters","text":"Content of this part depends on a selected report template. Usually you can find device or group selection, monitoring ID selection for monitoring based reports.","title":"Parameters"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#retention-policy","text":"You can set two parameters: Remove reports older than - all report files older than a provided number of days will be removed (default: 14 days). Number of files to retain - if report executions will generate more files than a provided number (default: 30), then the system will remove all beside the newest number. Note This rules concern only local report files, they do not affect files uploaded to a remote server using the Transfers feature.","title":"Retention policy"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#templates","text":"Here you can read more about report templates and a panel to manage them.","title":"Templates"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#layout_1","text":"Report templates - use it to browse through all report templates. Additionally, you can download, delete or check their details. If a report template has an invalid file format, then you will see information Invalid file in the `Structure column. What is more, you will not be able to use this template while scheduling a report. Add new template - use it to open a creation form. Check Custom templates section for more details. When you select the report template from a table, an edition form will open. It looks exactly the same as the creation form.","title":"Layout"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#custom-templates-creation","text":"Look at the list below to find information about creating custom report templates. Save - use it to save changes. Cancel - use it to discard all changes. Template title - use it to set a name of a template. Template category - use it to set a category from which the template will be accessible. File name - use it to set a name of a file with the template. Required permission - use it to select a permission that will be required to use the template. This field is optional. Monitoring report - use it to indicate if the template is based on monitoring. Monitoring type - if the template is based on monitoring, then you should select which one. Upload - use this button to upload the report template file. A template file must be in a .rptdesign or .cft format. If you try to upload the file in another format, then you will see information that a structure is invalid and you will not be able to save this template. There is a limit regarding a size of the report template, information about it is displayed when you try to upload the bigger file than allowed. If needed, you can change the limit in the configuration file. To learn how to do this, please refer to the Admin Guide, Changing the size of a report template section.","title":"Custom templates creation"},{"location":"User_Guide/Monitoring_and_Reporting/Reporting.html#reports-configuration","text":"This panel allows you to configure default reports properties and make scheduling of new reports faster. Preferences target - use it to select if this settings should be visible only for you ( Current user ) or for everyone in UMP. Output - use it to select default output formats. You can use CSV, DOC, HTML, PDF, PPT or XLS. Email address - use it to add email addresses to which reports will be sent. Default retention policy - look at the Retention policy section for details. Save - click it to save changes in default reports settings.","title":"Reports configuration"},{"location":"User_Guide/Monitoring_and_Reporting/Reports_descriptions.html","text":"Reports descriptions # Read this section to learn what reports are available in the system and what they display. Look at the table below to find out more. You can access all reports from Monitoring & Reporting \u2014> Reports . To generate a report go to the Schedule report tab. Name Category Description IP CSV Report General reports The report shows a history of IP changes of devices in a selected group and a period of time. Advanced CSV Report Monitoring reports The report shows selected monitoring data prepared by you in Administration \u2014> CSV Import/Export templates .","title":"Reports descriptions"},{"location":"User_Guide/Monitoring_and_Reporting/Reports_descriptions.html#reports-descriptions","text":"Read this section to learn what reports are available in the system and what they display. Look at the table below to find out more. You can access all reports from Monitoring & Reporting \u2014> Reports . To generate a report go to the Schedule report tab. Name Category Description IP CSV Report General reports The report shows a history of IP changes of devices in a selected group and a period of time. Advanced CSV Report Monitoring reports The report shows selected monitoring data prepared by you in Administration \u2014> CSV Import/Export templates .","title":"Reports descriptions"},{"location":"User_Guide/Monitoring_and_Reporting/Scheduling_Advanced_CSV_Report.html","text":"Scheduling advanced CSV Report # Read this section to learn how to schedule the report using the monitoring data export configuration prepared in Administration \u2014> CSV Import/Export templates . Prerequisites: In order to control report execution parallelism, the used thread pool size can be set in the cdm.conf file in the smg.mod.gui.reportPoolSize=4 setting. Warning Use of many threads speeds up report execution but at the same time it can cause database write contention for regular provisioning. That is why you should balance properly execution and operational performance. To schedule the report: Go to Monitoring & Reporting \u2014> Reports . Go to the Schedule report tab. In the Template selection panel: From the Category list, select Monitoring reports . From the Report template list, select Advanced CSV Report . Configure settings such as a schedule, time interval, transfer and retention policy. Read how to configure these settings in the Reporting chapter. In the Parameters panel: Click the Select group link and from the list select a group on which you want to schedule the report. Note Keep in mind, that the system will include only the devices that are in the selected group when next scheduled generation starts. Even if you delete a device from the group while the report is in progress, it will be included. Optional: Type an expression to schedule the report only on devices that fulfill the specified condition. Select one of export types: Raw Aggregated From the list select a monitoring data export configuration. Click the Schedule button. Tip Apart from having proper data in the generated report, you can also come across the below cases: An empty space instead of some data because there was no data to present. The - sign instead of data because there was no aggregation to present. See also: DEA_Adding_monitoring_data_export_configurations","title":"Scheduling advanced CSV Report"},{"location":"User_Guide/Monitoring_and_Reporting/Scheduling_Advanced_CSV_Report.html#scheduling-advanced-csv-report","text":"Read this section to learn how to schedule the report using the monitoring data export configuration prepared in Administration \u2014> CSV Import/Export templates . Prerequisites: In order to control report execution parallelism, the used thread pool size can be set in the cdm.conf file in the smg.mod.gui.reportPoolSize=4 setting. Warning Use of many threads speeds up report execution but at the same time it can cause database write contention for regular provisioning. That is why you should balance properly execution and operational performance. To schedule the report: Go to Monitoring & Reporting \u2014> Reports . Go to the Schedule report tab. In the Template selection panel: From the Category list, select Monitoring reports . From the Report template list, select Advanced CSV Report . Configure settings such as a schedule, time interval, transfer and retention policy. Read how to configure these settings in the Reporting chapter. In the Parameters panel: Click the Select group link and from the list select a group on which you want to schedule the report. Note Keep in mind, that the system will include only the devices that are in the selected group when next scheduled generation starts. Even if you delete a device from the group while the report is in progress, it will be included. Optional: Type an expression to schedule the report only on devices that fulfill the specified condition. Select one of export types: Raw Aggregated From the list select a monitoring data export configuration. Click the Schedule button. Tip Apart from having proper data in the generated report, you can also come across the below cases: An empty space instead of some data because there was no data to present. The - sign instead of data because there was no aggregation to present. See also: DEA_Adding_monitoring_data_export_configurations","title":"Scheduling advanced CSV Report"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Adding_monitoring.html","text":"Adding monitoring # Read this chapter to learn how to add a new monitoring. To add a monitoring: Go to Monitoring & Reporting \u2014> Monitoring . From the Available monitoring list, select a type of monitoring by clicking it. Configure basic settings. To learn about basic configuration, read the Monitoring configuration chapter. From the Monitoring target groups list, select groups you want to monitor. To learn more about adding groups, read the step 6 in the Monitoring configuration chapter. Configure advanced settings. To learn about configuration of an individual monitoring, read the Specific settings for monitoring chapter. Optional: Add additional resources. To learn about configuration of additional resources, read the Adding custom monitoring chapter. Select check boxes next to alerts you want to enable. To learn about alerts of an individual monitoring, read the Specific settings for monitoring chapter. Click the Save button. Tip To edit the monitoring, select it from the list and make necessary changes. Do not forget to save them. To delete the monitoring, select it from the list and click the Delete button. If you do not want to delete the monitoring but you do not want it to collect samples, clear the Enabled check box. Adding custom monitoring # Read this chapter to learn how to add custom monitoring that enables you to decide which resources you want to monitor. To add custom monitoring: Go to Monitoring & Reporting \u2014> Monitoring . From the Available monitoring list, select a Custom monitoring by clicking it. Configure basic settings. In this example, a name is defined, a sampling interval is set to Manual and its value is 300 , a domain is set to / , and the Enabled check box is selected. In the Monitoring target groups panel, click the Add link and select proper groups. In the Advanced configuration panel, click the Add resource link to select a representative device. The representative device will be used to validate a configuration of monitoring. You will be warned if resources created by you are not available on the device. Each monitoring may monitor one or more resources, and for each resource an alert can be configured and a separate chart will be created. Configure particular fields: From the Source list, select whether this resource will be based on a data model or on a setting value, and into the Data model field, type a proper path. In this example, the data model will be selected. The system prompts available objects which are marked in bold. If the device has any instances then the system displays their number on the list. If there are no instances on the selected device, the system cannot prompt them and you need to type object instances values manually (in the place marked as {i} ). From the Its type list, select a proper type. From the Collect for list, select if you want to collect data only for a group, device or for both group and device. Configure other related options: Into the Display name field, type a name that will be displayed above a chart with results. From the Device presentation / Group presentation lists, select how results will be presented, for example as a histogram or timeline. Click the Options link to configure additional options. Fields available for configuration vary depending on your selection in the Source field: X axis label - a name of the X axis, it will be visible on a chart. Y axis label - a name of the Y axis, it will be visible on the chart. Aggregation mode - a way in which data will be presented, if it is a sum or an average of results. To create an alert for this resource, select the Create alert check box. Specify its name and define when it will be raised. In the Actions panel, click the Save button. After saving the additional panel Enable/disable alert status collection will appear where you can enable group alerts (informing you for how many devices (in %) a particular alert occurred). For each defined alert: In the Enable/disable alert status collection , click the enable group alert link next to the alert. Define severity levels using lists and define a number above which the particular severity occurs. To disable the particular severity, select not used instead of above . In the Actions panel, click the Save button. All resources and alerts will be visible in Device inventory \u2014> Monitoring . If you hover over a monitored resource\u2019s graph in any place, you will see its value which was available at the corresponding time. If you hover over an alert\u2019s graph, you will see periods of time the alert was raised/hidden. See also: Monitoring configuration Specific settings for monitoring","title":"Adding monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Adding_monitoring.html#adding-monitoring","text":"Read this chapter to learn how to add a new monitoring. To add a monitoring: Go to Monitoring & Reporting \u2014> Monitoring . From the Available monitoring list, select a type of monitoring by clicking it. Configure basic settings. To learn about basic configuration, read the Monitoring configuration chapter. From the Monitoring target groups list, select groups you want to monitor. To learn more about adding groups, read the step 6 in the Monitoring configuration chapter. Configure advanced settings. To learn about configuration of an individual monitoring, read the Specific settings for monitoring chapter. Optional: Add additional resources. To learn about configuration of additional resources, read the Adding custom monitoring chapter. Select check boxes next to alerts you want to enable. To learn about alerts of an individual monitoring, read the Specific settings for monitoring chapter. Click the Save button. Tip To edit the monitoring, select it from the list and make necessary changes. Do not forget to save them. To delete the monitoring, select it from the list and click the Delete button. If you do not want to delete the monitoring but you do not want it to collect samples, clear the Enabled check box.","title":"Adding monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Adding_monitoring.html#adding-custom-monitoring","text":"Read this chapter to learn how to add custom monitoring that enables you to decide which resources you want to monitor. To add custom monitoring: Go to Monitoring & Reporting \u2014> Monitoring . From the Available monitoring list, select a Custom monitoring by clicking it. Configure basic settings. In this example, a name is defined, a sampling interval is set to Manual and its value is 300 , a domain is set to / , and the Enabled check box is selected. In the Monitoring target groups panel, click the Add link and select proper groups. In the Advanced configuration panel, click the Add resource link to select a representative device. The representative device will be used to validate a configuration of monitoring. You will be warned if resources created by you are not available on the device. Each monitoring may monitor one or more resources, and for each resource an alert can be configured and a separate chart will be created. Configure particular fields: From the Source list, select whether this resource will be based on a data model or on a setting value, and into the Data model field, type a proper path. In this example, the data model will be selected. The system prompts available objects which are marked in bold. If the device has any instances then the system displays their number on the list. If there are no instances on the selected device, the system cannot prompt them and you need to type object instances values manually (in the place marked as {i} ). From the Its type list, select a proper type. From the Collect for list, select if you want to collect data only for a group, device or for both group and device. Configure other related options: Into the Display name field, type a name that will be displayed above a chart with results. From the Device presentation / Group presentation lists, select how results will be presented, for example as a histogram or timeline. Click the Options link to configure additional options. Fields available for configuration vary depending on your selection in the Source field: X axis label - a name of the X axis, it will be visible on a chart. Y axis label - a name of the Y axis, it will be visible on the chart. Aggregation mode - a way in which data will be presented, if it is a sum or an average of results. To create an alert for this resource, select the Create alert check box. Specify its name and define when it will be raised. In the Actions panel, click the Save button. After saving the additional panel Enable/disable alert status collection will appear where you can enable group alerts (informing you for how many devices (in %) a particular alert occurred). For each defined alert: In the Enable/disable alert status collection , click the enable group alert link next to the alert. Define severity levels using lists and define a number above which the particular severity occurs. To disable the particular severity, select not used instead of above . In the Actions panel, click the Save button. All resources and alerts will be visible in Device inventory \u2014> Monitoring . If you hover over a monitored resource\u2019s graph in any place, you will see its value which was available at the corresponding time. If you hover over an alert\u2019s graph, you will see periods of time the alert was raised/hidden. See also: Monitoring configuration Specific settings for monitoring","title":"Adding custom monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Browsing_Monitoring_Results.html","text":"Browsing monitoring results # As mentioned in Monitoring , monitoring is applicable for two scopes - devices and groups. Consequently it is reflected by user interface structure for: Groups in Device groups A single device in Devices management center . Those views are similar for all types of monitoring. Typically they look like that: Predefined time ranges: hour/day/week . Custom time range beginning and end. Type your requested date or click the Date icon and select it from a calendar view. Result comparison. You can compare in a graphical way results with single device(s) ( Add device ) or group(s) ( Add group ). You can remove devices or groups of devices from comparison by clicking the number of selected elements. A typical results chart looks like this: It contains the following useful options: Show statistics - use it to show statistics for a particular chart. Hide legend - use it to hide a legend. Image - use it to export a graph as an image file. CSV - use it to export data from the graph as raw data in a CSV file format. Full screen - use it to expand the graph to the full screen to see details. Close the full screen mode by clicking x in right upper corner. You can also compare two devices on a single chart. This is useful when you need to compare monitoring results of a single device with another one or a group of devices. Comparison between device types shows which of them grant customers better service. To learn how to do this, look at the Basic filters screen.","title":"Browsing monitoring results"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Browsing_Monitoring_Results.html#browsing-monitoring-results","text":"As mentioned in Monitoring , monitoring is applicable for two scopes - devices and groups. Consequently it is reflected by user interface structure for: Groups in Device groups A single device in Devices management center . Those views are similar for all types of monitoring. Typically they look like that: Predefined time ranges: hour/day/week . Custom time range beginning and end. Type your requested date or click the Date icon and select it from a calendar view. Result comparison. You can compare in a graphical way results with single device(s) ( Add device ) or group(s) ( Add group ). You can remove devices or groups of devices from comparison by clicking the number of selected elements. A typical results chart looks like this: It contains the following useful options: Show statistics - use it to show statistics for a particular chart. Hide legend - use it to hide a legend. Image - use it to export a graph as an image file. CSV - use it to export data from the graph as raw data in a CSV file format. Full screen - use it to expand the graph to the full screen to see details. Close the full screen mode by clicking x in right upper corner. You can also compare two devices on a single chart. This is useful when you need to compare monitoring results of a single device with another one or a group of devices. Comparison between device types shows which of them grant customers better service. To learn how to do this, look at the Basic filters screen.","title":"Browsing monitoring results"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Configuration.html","text":"Monitoring configuration # Enabling monitoring requires preparation of monitoring configuration. Monitoring manager is available in the Monitoring & Reporting menu. Monitoring type - information showing you which monitoring you selected. A list of available monitoring types. Basic configuration : Name - a unique name of monitoring configuration. Description - an optional description of monitoring configuration. Execution condition - an additional condition that needs to be met to start the monitoring. You should use Expressions in this field. Type ${ to get a hint. Sampling interval - a time period (expressed in seconds) during which one sample should be collected. You can select the sampling interval from the list - Optimal (a predefined value) or Manual (you can set a value). Health index metric - a selection of KPIs. To learn about KPIs of an individual monitoring, read the Specific settings for monitoring chapter. Domain - a list of available domains. Select it if you want to restrict access only to particular users. To learn about domains, read the Managing multitenancy chapter. Enabled - a check box that allows you to enable or disable a monitoring. Samples are not collected for inactive monitoring, but already collected results can be still browsed. Group exclusion patterns - a list of regular expression patterns that are used to exclude groups from group aggregate collection. Actions Save - a button to save a new monitoring. Delete - a button to delete the monitoring. Advanced configuration - specific configuration for each monitoring. To learn about configuration of an individual monitoring, read the Specific settings for monitoring chapter. Import and Export buttons to export to or import from a XML file monitoring type specific configuration. The Advanced configuration can be divided into: A panel with configuration fields specific for a particular monitoring. Configure monitoring of custom resources with the Add resource icon - additional resources that you can add to be monitored. To learn how to configure additional resources, read the Custom monitoring chapter. Enable/disable alert status collection - a list of alerts that you can enable (click the check box next to the alert) or disable (clear the check box). Legend settings for monitoring map - for almost all monitoring types you can define legend settings for resources that are visible on a monitoring map . You can select: Color schema - how values should be colored. You can select Red - Green - lower values will have a red color and higher will have a green color, or Green - Red - lower values will have a green color and higher will have a red color. Range adjustment - how values will be computed. You can select Automatic - minimum and maximum values will be computed on the basis of monitoring values, or Manual - minimum and maximum values will be defined by a user. Unit - which unit will be used, for example, %, kbps, or ms. Monitoring target groups - a monitoring groups selection option. Select monitoring groups by clicking Add and selecting particular groups from the list. You can select more than one group at the same time, just keep the window open. To stop adding groups, close the window. To delete a group from monitoring, click the icon next to it. Tip When a group is selected its descendants are not accessible as they are also monitoring groups by definition. When the root group is selected, then no more groups can be selected.","title":"Monitoring configuration"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Configuration.html#monitoring-configuration","text":"Enabling monitoring requires preparation of monitoring configuration. Monitoring manager is available in the Monitoring & Reporting menu. Monitoring type - information showing you which monitoring you selected. A list of available monitoring types. Basic configuration : Name - a unique name of monitoring configuration. Description - an optional description of monitoring configuration. Execution condition - an additional condition that needs to be met to start the monitoring. You should use Expressions in this field. Type ${ to get a hint. Sampling interval - a time period (expressed in seconds) during which one sample should be collected. You can select the sampling interval from the list - Optimal (a predefined value) or Manual (you can set a value). Health index metric - a selection of KPIs. To learn about KPIs of an individual monitoring, read the Specific settings for monitoring chapter. Domain - a list of available domains. Select it if you want to restrict access only to particular users. To learn about domains, read the Managing multitenancy chapter. Enabled - a check box that allows you to enable or disable a monitoring. Samples are not collected for inactive monitoring, but already collected results can be still browsed. Group exclusion patterns - a list of regular expression patterns that are used to exclude groups from group aggregate collection. Actions Save - a button to save a new monitoring. Delete - a button to delete the monitoring. Advanced configuration - specific configuration for each monitoring. To learn about configuration of an individual monitoring, read the Specific settings for monitoring chapter. Import and Export buttons to export to or import from a XML file monitoring type specific configuration. The Advanced configuration can be divided into: A panel with configuration fields specific for a particular monitoring. Configure monitoring of custom resources with the Add resource icon - additional resources that you can add to be monitored. To learn how to configure additional resources, read the Custom monitoring chapter. Enable/disable alert status collection - a list of alerts that you can enable (click the check box next to the alert) or disable (clear the check box). Legend settings for monitoring map - for almost all monitoring types you can define legend settings for resources that are visible on a monitoring map . You can select: Color schema - how values should be colored. You can select Red - Green - lower values will have a red color and higher will have a green color, or Green - Red - lower values will have a green color and higher will have a red color. Range adjustment - how values will be computed. You can select Automatic - minimum and maximum values will be computed on the basis of monitoring values, or Manual - minimum and maximum values will be defined by a user. Unit - which unit will be used, for example, %, kbps, or ms. Monitoring target groups - a monitoring groups selection option. Select monitoring groups by clicking Add and selecting particular groups from the list. You can select more than one group at the same time, just keep the window open. To stop adding groups, close the window. To delete a group from monitoring, click the icon next to it. Tip When a group is selected its descendants are not accessible as they are also monitoring groups by definition. When the root group is selected, then no more groups can be selected.","title":"Monitoring configuration"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings.html","text":"Specific settings for monitoring # Go through below sections to learn how to configure a monitoring. Custom Inactive devices","title":"Specific settings for monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings.html#specific-settings-for-monitoring","text":"Go through below sections to learn how to configure a monitoring. Custom Inactive devices","title":"Specific settings for monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map_toctree.html","text":"Monitoring map # Monitoring map Overriding a default zooming feature using SV Example Procedure","title":"Monitoring map"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map_toctree.html#monitoring-map","text":"Monitoring map Overriding a default zooming feature using SV Example Procedure","title":"Monitoring map"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings/Custom_monitoring.html","text":"Custom # Use the Custom monitoring to create a fully customized monitoring to satisfy your needs. The monitoring is based on data model parameters and on setting values, you decide what you want to use. Advanced configuration consists of the following fields: Add resource - click it to add a new resource, then you will be able to select which parameter or setting value you want to monitor on the basis of a device. Representative of monitored devices - a device representative that you selected after clicking the Add resource link. The device representative will be used to validate a configuration of Custom monitoring. You will be warned if resources created by you are not available on the representative device. Click the Preview icon to see a current value of resources on the representative device. Click the name of the device to change it to another one. Save your configuration first, otherwise it will be lost. Click the blue arrow to go to Device inventory and see the device details. Source - defines if the resource is taken from the data model or from setting values. Select: Data model - to take the resource from the data model. The system prompts available resources, which are marked in bold. If a device has any instances then the system displays their number on the list. If there are no instances on the selected device, the system cannot prompt them and you need to type object instances values manually (type them in the place marked as {i} ). Read more in Data model key prompts . Setting value - to take the resource from the setting values. Its type - defines if a resource is expressed as text or as a number. Data interpretation - a list of available ways of presenting your data, if it should be expressed, for example, as a percentage or sample count. Preview - the icon shows if your configuration is correct. Green means correct and red means incorrect configuration. Click the icon to see a hint. If the configuration is correct, a value of a resource for the representative device is shown. Collect for - click it to decide if you want to collect data only for a group, device or for both group and device. Display name - a name that will be displayed above a chart with results. Device presentation / Group presentation - defines how results will be presented, for example as a histogram or timeline. Options - additional options that you can configure. Fields available for configuration vary depending on your selection in the Source field: X axis label - a name of the X axis, it will be visible on a chart. Y axis label - a name of the Y axis, it will be visible on the chart. Aggregation mode - a way in which data will be presented, if it is a sum or an average of results. Create alert - select it to create an alert for a particular resource. Alert name - a name of the alert. Raise it when monitored resource value - a list of conditions from which you select one for the resource. If the defined condition is met, then the alert is raised. Conditions vary depending on the configuration set in the Its type field. If you select, for example, is absent from the following list , type a value and press Enter . To remove the value, click it. Passive - select it to indicate that the resource is passive. Tip You can add as many resources as you want. For each of them a separate chart will be created.","title":"Custom"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings/Custom_monitoring.html#custom","text":"Use the Custom monitoring to create a fully customized monitoring to satisfy your needs. The monitoring is based on data model parameters and on setting values, you decide what you want to use. Advanced configuration consists of the following fields: Add resource - click it to add a new resource, then you will be able to select which parameter or setting value you want to monitor on the basis of a device. Representative of monitored devices - a device representative that you selected after clicking the Add resource link. The device representative will be used to validate a configuration of Custom monitoring. You will be warned if resources created by you are not available on the representative device. Click the Preview icon to see a current value of resources on the representative device. Click the name of the device to change it to another one. Save your configuration first, otherwise it will be lost. Click the blue arrow to go to Device inventory and see the device details. Source - defines if the resource is taken from the data model or from setting values. Select: Data model - to take the resource from the data model. The system prompts available resources, which are marked in bold. If a device has any instances then the system displays their number on the list. If there are no instances on the selected device, the system cannot prompt them and you need to type object instances values manually (type them in the place marked as {i} ). Read more in Data model key prompts . Setting value - to take the resource from the setting values. Its type - defines if a resource is expressed as text or as a number. Data interpretation - a list of available ways of presenting your data, if it should be expressed, for example, as a percentage or sample count. Preview - the icon shows if your configuration is correct. Green means correct and red means incorrect configuration. Click the icon to see a hint. If the configuration is correct, a value of a resource for the representative device is shown. Collect for - click it to decide if you want to collect data only for a group, device or for both group and device. Display name - a name that will be displayed above a chart with results. Device presentation / Group presentation - defines how results will be presented, for example as a histogram or timeline. Options - additional options that you can configure. Fields available for configuration vary depending on your selection in the Source field: X axis label - a name of the X axis, it will be visible on a chart. Y axis label - a name of the Y axis, it will be visible on the chart. Aggregation mode - a way in which data will be presented, if it is a sum or an average of results. Create alert - select it to create an alert for a particular resource. Alert name - a name of the alert. Raise it when monitored resource value - a list of conditions from which you select one for the resource. If the defined condition is met, then the alert is raised. Conditions vary depending on the configuration set in the Its type field. If you select, for example, is absent from the following list , type a value and press Enter . To remove the value, click it. Passive - select it to indicate that the resource is passive. Tip You can add as many resources as you want. For each of them a separate chart will be created.","title":"Custom"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings/Inactive_devices.html","text":"Inactive devices # Use the Inactive devices monitoring to identify devices which last visit in the system is older than expected. It is calculated with this formula: last visit time + expectedSessionRatio * periodicInformInterval . This monitoring does not have any contact with devices, it only inspects the system for devices that were supposed to connect. Prerequisites: To execute the monitoring, the expectedSessionRatio (in %) and periodicInformInterval (in seconds) SVs must be set on a device or a group of devices. Alerts that can be triggered by this monitoring: Inactive device - the alert is triggered when a device does not visit the system in the expected time period. The following KPI is available: Active devices : For a device - KPI shows the last value and when it displays 0% this means that the device is inactive, and when it displays 100% this means that the device is active. For a group of devices - KPI shows a percentage of active devices in the last hour. The higher value the better.","title":"Inactive devices"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_Type_Specific_Settings/Inactive_devices.html#inactive-devices","text":"Use the Inactive devices monitoring to identify devices which last visit in the system is older than expected. It is calculated with this formula: last visit time + expectedSessionRatio * periodicInformInterval . This monitoring does not have any contact with devices, it only inspects the system for devices that were supposed to connect. Prerequisites: To execute the monitoring, the expectedSessionRatio (in %) and periodicInformInterval (in seconds) SVs must be set on a device or a group of devices. Alerts that can be triggered by this monitoring: Inactive device - the alert is triggered when a device does not visit the system in the expected time period. The following KPI is available: Active devices : For a device - KPI shows the last value and when it displays 0% this means that the device is inactive, and when it displays 100% this means that the device is active. For a group of devices - KPI shows a percentage of active devices in the last hour. The higher value the better.","title":"Inactive devices"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html","text":"Monitoring map # To visualize monitoring that you configured in your system on a map, go to Monitoring & Reporting \u2014> Monitoring map . Interface # The Monitoring map view is divided into three main panels: Time range - use it to set a time period for which you want to see visualization. To set a date, use the button or the calendar. Tabs - use the tabs to decide which monitoring and options you can see on the map: Monitoring Options Filters Search Map - use it to see monitoring data location. On the map you can click a group or a subgroup to see more details in a pop-up window. When the pop-up window opens, depending on displayed data, you can save it as an image or a CSV file. What is more, you can click the group name to go to Device groups . If there is any data collected for a selected resource, then a proper legend is displayed above the map. For some monitoring resources you will be able to edit the legend by clicking the Edit icon. To learn more about legend settings, read the Monitoring configuration chapter. Changes you make on the monitoring map will be also implemented in monitoring configuration. Groups circles displayed on the map will be highlighted with colors depending on the collected value and according to the scale. To zoom the map, use the zoom slider or your mouse scroll wheel. A level in a group hierarchy depends on zoom on the map (thus when zoom is closer, you are able to see smaller groups or even devices). The default association between zoom and depth in the group hierarchy can be overridden by setting a proper SV. Learn how to do it in the Overriding a default zooming feature using SV chapter. Monitoring # Use the Monitoring section to select a group and monitoring that you want to display on the map. Root group - select a group from which you want to display monitoring. Groups added in Administration \u2014> Import monitoring groups are available on the Root group list automatically. To add other groups use the Edit link (you can also use it to remove any groups). The group selected from the list will be used as a root of a hierarchy displayed below as a tree and as groups circles on the map. If you do not want to show all subgroups, hover over the subgroup and clear the check box next to it. Monitoring - click a monitoring name to display it on the map. Resource - select what resource you want to display. Aggregation - select a proper aggregation of values from the list. Next - click it to go to another tab. Options # Use the Options section to display additional information on the map. Mark min value - select it to mark groups or devices for which a value of a selected resource (in the Monitoring section from the Resource list) is the lowest. Show values - select it to show values of the selected resource. Show names - select it to show names of groups, subgroups, or devices. Voronoi diagram - select it to display the Voronoi diagram on the map. Saturation - move the slider to select proper saturation of the Voronoi diagram. Show in group circle - use this list to display additional information on the map, such as a number of subgroups or devices in the particular group. The number also influences the color of the particular group circle, this helps you to visually compare the size of groups when the map is zoomed out. Mark max value - select it to mark groups or devices for which a value of the selected resource is the highest. Show locations - select it to display a geographical location on the map. Draw beams (BTS) - select it to display a direction of emission of base transceiver stations (BTS). Next - click it to go to another tab. Filters # Use the Filters section to display only specified information. You can add more than one filter. Add filter - click the icon to add a filter. Configure the filter by selecting from lists proper configuration and providing values. Data that you can select for each monitoring type differs. To add another filter, click the icon again. Apply filters - click it to execute the filter on the map. Delete - click the icon to delete the filter. Next - click it to go to another tab. Search # Use the Search section to find a particular device on the map. Type a device identity and click the Search icon. When the device is displayed on the map, you can click it to see more details. See also: Overriding a default zooming feature using SV Importing monitoring groups from CSV","title":"Monitoring map"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#monitoring-map","text":"To visualize monitoring that you configured in your system on a map, go to Monitoring & Reporting \u2014> Monitoring map .","title":"Monitoring map"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#interface","text":"The Monitoring map view is divided into three main panels: Time range - use it to set a time period for which you want to see visualization. To set a date, use the button or the calendar. Tabs - use the tabs to decide which monitoring and options you can see on the map: Monitoring Options Filters Search Map - use it to see monitoring data location. On the map you can click a group or a subgroup to see more details in a pop-up window. When the pop-up window opens, depending on displayed data, you can save it as an image or a CSV file. What is more, you can click the group name to go to Device groups . If there is any data collected for a selected resource, then a proper legend is displayed above the map. For some monitoring resources you will be able to edit the legend by clicking the Edit icon. To learn more about legend settings, read the Monitoring configuration chapter. Changes you make on the monitoring map will be also implemented in monitoring configuration. Groups circles displayed on the map will be highlighted with colors depending on the collected value and according to the scale. To zoom the map, use the zoom slider or your mouse scroll wheel. A level in a group hierarchy depends on zoom on the map (thus when zoom is closer, you are able to see smaller groups or even devices). The default association between zoom and depth in the group hierarchy can be overridden by setting a proper SV. Learn how to do it in the Overriding a default zooming feature using SV chapter.","title":"Interface"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#monitoring","text":"Use the Monitoring section to select a group and monitoring that you want to display on the map. Root group - select a group from which you want to display monitoring. Groups added in Administration \u2014> Import monitoring groups are available on the Root group list automatically. To add other groups use the Edit link (you can also use it to remove any groups). The group selected from the list will be used as a root of a hierarchy displayed below as a tree and as groups circles on the map. If you do not want to show all subgroups, hover over the subgroup and clear the check box next to it. Monitoring - click a monitoring name to display it on the map. Resource - select what resource you want to display. Aggregation - select a proper aggregation of values from the list. Next - click it to go to another tab.","title":"Monitoring"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#options","text":"Use the Options section to display additional information on the map. Mark min value - select it to mark groups or devices for which a value of a selected resource (in the Monitoring section from the Resource list) is the lowest. Show values - select it to show values of the selected resource. Show names - select it to show names of groups, subgroups, or devices. Voronoi diagram - select it to display the Voronoi diagram on the map. Saturation - move the slider to select proper saturation of the Voronoi diagram. Show in group circle - use this list to display additional information on the map, such as a number of subgroups or devices in the particular group. The number also influences the color of the particular group circle, this helps you to visually compare the size of groups when the map is zoomed out. Mark max value - select it to mark groups or devices for which a value of the selected resource is the highest. Show locations - select it to display a geographical location on the map. Draw beams (BTS) - select it to display a direction of emission of base transceiver stations (BTS). Next - click it to go to another tab.","title":"Options"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#filters","text":"Use the Filters section to display only specified information. You can add more than one filter. Add filter - click the icon to add a filter. Configure the filter by selecting from lists proper configuration and providing values. Data that you can select for each monitoring type differs. To add another filter, click the icon again. Apply filters - click it to execute the filter on the map. Delete - click the icon to delete the filter. Next - click it to go to another tab.","title":"Filters"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Monitoring_map.html#search","text":"Use the Search section to find a particular device on the map. Type a device identity and click the Search icon. When the device is displayed on the map, you can click it to see more details. See also: Overriding a default zooming feature using SV Importing monitoring groups from CSV","title":"Search"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Overriding_a_default_zooming_feature_using_SV.html","text":"Overriding a default zooming feature using SV # The default association between zoom and a depth in the group hierarchy can be overridden by setting a proper SV. Example # To better understand the format of the SV you will need to type, read the below example. Let's assume that your groups hierarchy looks like the one below: monitoring-root |----- country-1-subgroup | |------ city-1-subgroup <- each group contain devices, no more subgroups | |------ city-2-subgroup | \\------ city-3-subgroup \\----- country-2-subgroup |------ city-4-subgroup \\------ city-5-subgroup Each value from SV corresponds to a level in your group hierarchy: 0 is interpreted as a monitoring group root (in the example - monitoring-root ). 1 is interpreted as a monitoring root's direct children (in the example - country-1-subgroup and country-2-subgroup ). 2 is interpreted as the second level children (in the example - all cities subgroups ). And so on if you have more levels. In the example, you have only three levels in the group hierarchy, that is 0 , 1 and 2 but you can always use one more to display devices. Thus in this case, you can use 3 to denote devices. SV is composed of 16 non-decreasing numbers because this is the number of available zoom levels on the map. The first number indicates the most zoomed out view (the farthest view), the second indicates a slightly closer view and the last one indicates the most zoomed in view (that is the closest one). Let's analyze this SV: 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2 in the context of the above sample group hierarchy: Through the most 5 farthest zooms, only monitoring-root will be shown (5 because there are 5 zeros at the beginning). Through the next 4 map zooms, country-1-subgroup and country-2-subgroup will be shown (4 because there are four 1). Through the last 7 closest map zooms, all cities subgroups will be shown. If you change last four 2 to 3 then you will get 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3 and in this case, for last four most close zooms you will see devices. Procedure # To override the default zooming feature using SV: Go to Device groups . From the group tree, select a group. Go to Profiles and add into: The Name field, type monitoringZoomLevelMapping . The Value field, type a comma separated list of 16 non-decreasing values. Click the Save link. To check if your configuration works, go to Monitoring & Reporting \u2014> Monitoring map . See also: Monitoring_map","title":"Overriding a default zooming feature using SV"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Overriding_a_default_zooming_feature_using_SV.html#overriding-a-default-zooming-feature-using-sv","text":"The default association between zoom and a depth in the group hierarchy can be overridden by setting a proper SV.","title":"Overriding a default zooming feature using SV"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Overriding_a_default_zooming_feature_using_SV.html#example","text":"To better understand the format of the SV you will need to type, read the below example. Let's assume that your groups hierarchy looks like the one below: monitoring-root |----- country-1-subgroup | |------ city-1-subgroup <- each group contain devices, no more subgroups | |------ city-2-subgroup | \\------ city-3-subgroup \\----- country-2-subgroup |------ city-4-subgroup \\------ city-5-subgroup Each value from SV corresponds to a level in your group hierarchy: 0 is interpreted as a monitoring group root (in the example - monitoring-root ). 1 is interpreted as a monitoring root's direct children (in the example - country-1-subgroup and country-2-subgroup ). 2 is interpreted as the second level children (in the example - all cities subgroups ). And so on if you have more levels. In the example, you have only three levels in the group hierarchy, that is 0 , 1 and 2 but you can always use one more to display devices. Thus in this case, you can use 3 to denote devices. SV is composed of 16 non-decreasing numbers because this is the number of available zoom levels on the map. The first number indicates the most zoomed out view (the farthest view), the second indicates a slightly closer view and the last one indicates the most zoomed in view (that is the closest one). Let's analyze this SV: 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2 in the context of the above sample group hierarchy: Through the most 5 farthest zooms, only monitoring-root will be shown (5 because there are 5 zeros at the beginning). Through the next 4 map zooms, country-1-subgroup and country-2-subgroup will be shown (4 because there are four 1). Through the last 7 closest map zooms, all cities subgroups will be shown. If you change last four 2 to 3 then you will get 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3 and in this case, for last four most close zooms you will see devices.","title":"Example"},{"location":"User_Guide/Monitoring_and_Reporting/Monitoring_Module/Monitoring_map/Overriding_a_default_zooming_feature_using_SV.html#procedure","text":"To override the default zooming feature using SV: Go to Device groups . From the group tree, select a group. Go to Profiles and add into: The Name field, type monitoringZoomLevelMapping . The Value field, type a comma separated list of 16 non-decreasing values. Click the Save link. To check if your configuration works, go to Monitoring & Reporting \u2014> Monitoring map . See also: Monitoring_map","title":"Procedure"}]}